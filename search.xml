<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[风(二)]]></title>
    <url>%2F2017%2F09%2F03%2F%E9%A3%8E(%E4%BA%8C)%2F</url>
    <content type="text"><![CDATA[我们有一句没一句的说着些什么， 现在都不大记得清了，在说话间，你顺势牵起了我的手， 走过大街穿过小巷，我就这样跟在你的身后，心跳加速地跳动着，手心都出汗了。 你带我来到一间店里，点了一笼包子和饺子，我一点都不饿，看着你狼吞虎咽的样子， 那时的我都没对你翻脸，说明对你是真的很喜欢了。 说到我们的第一次约会，不得不提七星公园，那里有太多记忆里的美好，当然不是所有美好都是单纯的。 记得你为了抱我，故意骗我说有毛毛虫，现在想来，你是很有心机的嘛。 当然也不是每一次约会，我们都能愉快的玩耍，期间也有过争执，每一次的情况都愈演愈烈，谁都不愿意妥协，这里就不一一阐述了，反正都是你的错就对了٩( •̀㉨•́ )و get！哈哈哈哈哈⁽˙³˙⁾◟(๑•́ ₃ •̀๑)◞⁽˙³˙⁾ 其实我最开心的，是你每次见到我都会夸我，不善言辞的你，说的话都是发自内心的，我都信了。 我们第一次旅游，去的北海，记得当时你计划了好久，可是还是没买到票， 你说，你是不是很笨(´▽｀)ノ♪！当时只剩下无座了，你说要不我们坐汽车吧，我去买票。 我说，我不喜欢坐汽车还是坐火车吧。 然后你知道的，两个人傻傻的站了九个小时，可是那时候一点也不觉得累，心里还是乐开了花。 那时候，我感受得到，你是想把好的都给我，是真的想要对我好。 那时候的我们什么都不想，在一起就是最开心的事情。 有点小怀念呢。 言归正传，到达北海已经下午了，白痴的你加上笨拙的我，放着车子不坐，硬是从火车站走到了市区，浪漫吧？ 我们最不缺的就是浪漫的压马路，一条又一条，一段路接着一段路，一处又一处的风景，都把我给晒黑了。 你说，怎么办。]]></content>
      <categories>
        <category>飘</category>
      </categories>
      <tags>
        <tag>风</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[风(一)]]></title>
    <url>%2F2017%2F09%2F01%2F%E9%A3%8E(%E4%B8%80)%2F</url>
    <content type="text"><![CDATA[应该是论我们走了多少公里的路(ಡωಡ)hiahiahia 写给你的。 不知从何时开始已经不再喜欢用书写文字的方式来表达自己的心情了，或多或少是因为年纪的关系，不过想一下，应该不是，只是太懒罢了，给自己找的借口。 记得你以前总说，我写的文字里找不到关于你的任何影子，你总是告诉我，写点什么吧。 而我只是笑而不应。 很多时候，不是不想写，更多的是不知道从何写起，笨拙如我，写出的文字太过局限，怕是写不出个所以然来。 那些关于我们的美好，怕被我写得乱七八糟，无从下笔。 而那些关于我们不开心的事情，我根本不想提及。 所以，每次下笔却变得不知道要写些什么。 这次要是再不写点什么，怕是要真的写不出什么了。 哈哈哈哈哈哈哈(ಡωಡ)hiahiahia 先说明，此篇凌乱毫无章法，看不懂我也没有办法了。 请往下看， 从2017追溯到2005，这中间我们共享了彼此12年的光阴。 从见字如”面”到”信”手拈来，好奇到了解，始终还是差了点什么，却又说不上来。 那时的我，还是懵懂无知的初中生，你亦只是写字好看的白痴罢了。 与你的相识，只不过是缘于同学之间的书信往来。 而你写在别人信笺背面的字，只一眼，就注定了开始，以至现在的万劫不复。 故事的开始，我只是希望你是一个明媚而不忧伤的美少女，无奈你却是情商负值二百五的白痴少年，而我也只不过是中二病晚期的笨蛋罢了。 虽然开始得并不顺利，磕磕碰碰总算是让姐姐给成功拿下了，虽然那时姐姐还不是姐姐，姐姐还是个男生。 嗯，在下李叶涛，不知有何贵干？ 容我笑一下，哈哈哈哈哈哈哈 好了，回归正题，这不是你想要的文艺篇，所以别一副生无可恋的样子，好不啦？ 冥冥中的相遇，注定了之后的种种，通过书信，我们走进了彼此想象的世界，却走不进彼此现实的生活。 从此的每天，都盼着你的来信，忐忑的，开心的心情，不言而喻。 字里行间都是简单纯真的童趣，而我每次读你的信，都会一个人傻笑好久，好久。 那是一种课堂上想起你，嘴角就不自觉上扬的开心。 初中生活，承载了美好的你我，却留不住短暂的时光，回头发现剩下来的只有往来的书信，厚厚一沓，之后了无音讯。 高中生活，不紧不慢，却还是让我不经意会想起你来，原来，有些人，不管在哪，都是会有人惦记的呢。 只是你不知道罢了。 我尝试着盲目写信，却不想真的得到了回应，现在想来当时太过开心，以至于忘记了对你提出控诉，为什么，你只字未提？ 之后，我们还是像中学那般好。 可你的点到为止，让我以为只是朋友的那种好，后来的发展，是我始料未及的，慢慢我们开始了疏远，到最后，渐渐的没有了联系。 大学的生活，枯燥无味，让人提不起半点兴趣，而命运之轮又开始在我们之间运转。 当我问出那句，你喜欢我吗？仿佛用尽了我所有的运气，才得来了心中想要的回应。 那一晚辗转反侧，兴奋得不能入眠，心里的涟漪泛起一层又一层，情不自禁，不能自已。 你看，你总说我学不会主动，可是我们之间最重要的三次都是我握有的主动权。 第一次，初中相识，第二次，高中再见，第三次，大学在一起。 我们开启了肆无忌惮的恋爱模式，毫无顾忌的样子，简直令人发指。 虽然有言于过实的成分。 那时的我们，开心并快乐着，不会去想太多，却还是会争吵，我们的争吵就像小孩子之间前一秒还在闹，后一秒转身就要和好。 你看你，多笨啊。 我们第一次的约会你还记得吗？我一下车就看见一个特别二的人对着我傻笑半天然后说他饿了要去吃东西，这剧情展开，仿佛我走错了片场。]]></content>
      <categories>
        <category>飘</category>
      </categories>
      <tags>
        <tag>风</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一个简单的游戏服务器框架demo(源码已经放在GitHub)]]></title>
    <url>%2F2017%2F08%2F27%2F%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E6%B8%B8%E6%88%8F%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%A1%86%E6%9E%B6demo(%E6%BA%90%E7%A0%81%E5%B7%B2%E7%BB%8F%E6%94%BE%E5%9C%A8GitHub)%2F</url>
    <content type="text"><![CDATA[GitHubGitHub地址 框架简介一个简单的游戏服务器框架demo 框架概要采用C++开发，依赖 : boost库 MySQL数据库 google-glog日志记录框架 curl库 主要处理游戏客户端和游戏数据库的数据交换。通信采用socket发送协议包的方式，服务器根据协议包命令码去做相应的逻辑处理，并将处理结果返回给游戏客户端，即完成了前后端的数据交换。 框架处理流程：客户端连接→ 服务器分配线程池中的线程处理→ 线程将协议数据递交给Worker → Worker调用统一协议处理逻辑Process开始处理→ Process对协议命令码分类，并将协议包内容递交给相应的业务类→ 业务类处理完成后调用统一处理逻辑Process处理完成→ Worker将返回数据递交给线程并返回给客户端 协议处理流程：客户端初次连接服务器，发送心跳→ 服务器返回连接成功状态→ 客户端发起本次协议→ 业务类处理数据库操作并将数据返回给客户端 他日将改进之处 降低模块间耦合度 新业务协议的添加略显繁琐, business模块可以遵循开闭原则来适当重构 编写维护工具 数据传输协议待优化 编写测试工具]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>boost</tag>
        <tag>mysql</tag>
        <tag>glog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kbe服务端笔记(二)]]></title>
    <url>%2F2017%2F07%2F29%2Fkbe%E6%9C%8D%E5%8A%A1%E7%AB%AF%E7%AC%94%E8%AE%B0(%E4%BA%8C)%2F</url>
    <content type="text"><![CDATA[FixedMessages：FixedMessages存储所有固定消息（有显示制定id的消息，当然，这并不表示非固定消息就没有id，也是有的，只是不是显示制定的）。 它的构造地方如下（lib/network/message_handler.cpp）：123456789101112MessageHandlers::MessageHandlers():msgHandlers_(),msgID_(1),exposedMessages_()&#123; g_fm = Network::FixedMessages::getSingletonPtr(); if(g_fm == NULL) g_fm = newNetwork::FixedMessages; Network::FixedMessages::getSingleton().loadConfig(&quot;server/messages_fixed.xml&quot;); messageHandlers().push_back(this);&#125; 意即MessageHandlers构造的时候，如果它还没构造，那就构造。它的初始化（配置）是由loadConfig接口来完成的，代码见上。 loginapp Loginapp组件主要用来处理账户登录/注册的业务 消息与handler映射的建立：两次包含xxx_interface.h，实现声明和定义：每个app组件的接口定义都在xxxapp_interface.cpp中开始，代码如下：123456789#include&quot;loginapp_interface.h&quot;#defineDEFINE_IN_INTERFACE#defineLOGINAPP#include&quot;loginapp_interface.h&quot;namespaceKBEngine&#123;namespaceLoginappInterface&#123;&#125;&#125; 所有的戏法都是通过包含loginapp_interface.h前后定义了DEFINE_IN_INTERFACE和LOGINAPP来完成的。第一次的包含就是各种变量，类的声明（当然也有一些类是声明类时使用类inline函数定义完成了，比如MESSAGE_ARGS0/1/2……）。我们看看loginapp_interface.h中的代码： 消息与handlers的存储首先是这一句：NETWORK_INTERFACE_DECLARE_BEGIN(LoginappInterface)此句展开的话声明和定义了Network::MessageHandlers messageHandlers（记住它们都在LoginappInterface命名空间内），展开宏之后的代码看起来像这样（是的，你的眼睛是好的，没有}闭合）：声明：12345namespaceLoginappInterface &#123;extern Network::MessageHandlers messageHandlers;定义：namespaceLoginappInterface &#123; Network::MessageHandlers messageHandlers; 消息与handle建立映射然后是这一句：LOGINAPP_MESSAGE_DECLARE_ARGS0(importClientMessages, NETWORK_FIXED_MESSAGE)此句展开的话分明声明和定义了一个importClientMessagesLoginappMessagehandler0的类，这个类继承自Network::MessageHandler，这里就是实现了handle的虚函数接口；声明和定义了importClientMessagesLoginappMessagehandler0的一个名为importClientMessages的全局变量；声明和定义了importClientMessagesArgs0的类，这个类继承自Network::MessageArgs。我们一个个地分析一下：首先展开下面的宏：1LOGINAPP_MESSAGE_DECLARE_ARGS0(importClientMessages, NETWORK_FIXED_MESSAGE) 之后是这样：12345678910111213141516#defineLOGINAPP_MESSAGE_DECLARE_ARGS0(NAME, MSG_LENGTH) \LOGINAPP_MESSAGE_HANDLER_ARGS0(NAME) \NETWORK_MESSAGE_DECLARE_ARGS0(Loginapp, NAME, \ NAME##LoginappMessagehandler0, MSG_LENGTH)展开LOGINAPP_MESSAGE_HANDLER_ARGS0(NAME)之后分别得到importClientMessagesLoginappMessagehandler0的声明和定义：声明：classimportClientMessagesLoginappMessagehandler0 : public Network::MessageHandler&#123;public:virtualvoidhandle(Network::Channel* pChannel, KBEngine::MemoryStream&amp;s);&#125;;定义：voidimportClientMessagesLoginappMessagehandler0::handle(Network::Channel* pChannel, KBEngine::MemoryStream&amp;s)&#123; KBEngine::Loginapp::getSingleton().importClientMessages(pChannel);&#125; （handle/handler，傻傻分不清楚。。。这里的handle是xxxApp中真正用来处理这个消息的接口，而这里的handler提供一个中间层的作用，集中处理一些通用的工作，可以将耦合减少一点）上面完成了相当于是importClientMessages消息的handler的声明和定义，下面则将这个类实例化之后添加到messageHandlers：12345#defineNETWORK_MESSAGE_DECLARE_ARGS0(DOMAIN, NAME, MSGHANDLER, \ MSG_LENGTH) \ NETWORK_MESSAGE_HANDLER(DOMAIN, NAME, MSGHANDLER, MSG_LENGTH, 0)\ MESSAGE_ARGS0(NAME) \ 展开NETWORK_MESSAGE_HANDLER(DOMAIN, NAME, MSGHANDLER, MSG_LENGTH, 0)之后得到importClientMessages的handler类（importClientMessagesLoginappMessagehandler0）的名为importClientMessages的全局变量（不过欣慰的是他们都在各自的XXXInterface命名空间内）。声明：externconstimportClientMessagesLoginappMessagehandler0&amp;importClientMessages; 定义：12importClientMessagesLoginappMessagehandler0* pimportClientMessages = static_cast&lt;importClientMessagesLoginappMessagehandler0*&gt;(messageHandlers.add(&quot;Loginapp::importClientMessages&quot;,new importClientMessagesArgs0, NETWORK_FIXED_MESSAGE, newimportClientMessagesLoginappMessagehandler0);constimportClientMessagesLoginappMessagehandler0&amp;importClientMessages = *pimportClientMessages; 下面的MESSAGE_ARGS0(NAME)展开后对importClientMessagesArgs0进行了声明和定义（其他它声明的时候就已经完成了全部的定义），声明的时候就是个空语句：声明兼定义：1234567891011121314151617181920212223classimportClientMessagesArgs0 : public Network::MessageArgs&#123;public:importClientMessagesArgs0() :Network::MessageArgs() &#123;&#125; ~importClientMessagesArgs0() &#123;&#125;staticvoidstaticAddToBundle(Network::Bundle&amp;s) &#123; &#125;staticvoidstaticAddToStream(MemoryStream&amp;s) &#123; &#125;virtual int32 dataSize(void) &#123;return 0; &#125;virtualvoidaddToStream(MemoryStream&amp;s) &#123; &#125;virtualvoidcreateFromStream(MemoryStream&amp;s) &#123; &#125;&#125;; 唯一需要小注意一下的就是importClientMessagesArgs0的声明（兼定义）是和importClientMessagesLoginappMessagehandler0的实例的声明和定义是错开的，因为后者实例化添加到messageHandlers的时候需要new一个importClientMessagesArgs0的实例。 流程的伪代码稍微整理一下之后，使用LOGINAPP_MESSAGE_HANDLER_ARGSn建立一个消息到handler的映射的代码很像是这样： 声明：（第一次包含loginapp_interface.h产生的代码） 12345678910111213141516171819202122232425262728293031classimportClientMessagesLoginappMessagehandler0 : public Network::MessageHandler&#123;public:virtualvoidhandle(Network::Channel* pChannel, KBEngine::MemoryStream&amp;s);&#125;;externconstimportClientMessagesLoginappMessagehandler0&amp;importClientMessages;classimportClientMessagesArgs0 : public Network::MessageArgs&#123;public:importClientMessagesArgs0() :Network::MessageArgs() &#123;&#125; ~importClientMessagesArgs0() &#123;&#125;staticvoidstaticAddToBundle(Network::Bundle&amp;s) &#123; &#125;staticvoidstaticAddToStream(MemoryStream&amp;s) &#123; &#125;virtual int32 dataSize(void) &#123;return 0; &#125;virtualvoidaddToStream(MemoryStream&amp;s) &#123; &#125;virtualvoidcreateFromStream(MemoryStream&amp;s) &#123; &#125;&#125;; 定义：（定义DEFINE_IN_INTERFACE和LOGINAPP之后第二次包含loginapp_interface.h产生的代码） 1234567891011voidimportClientMessagesLoginappMessagehandler0::handle(Network::Channel* pChannel, KBEngine::MemoryStream&amp;s)&#123; KBEngine::Loginapp::getSingleton().importClientMessages(pChannel);&#125;importClientMessagesLoginappMessagehandler0* pimportClientMessages = static_cast&lt;importClientMessagesLoginappMessagehandler0*&gt;(messageHandlers.add(&quot;Loginapp::importClientMessages&quot;,newimportClientMessagesArgs0, NETWORK_FIXED_MESSAGE,newimportClientMessagesLoginappMessagehandler0);constimportClientMessagesLoginappMessagehandler0&amp;importClientMessages = *pimportClientMessages; 消息id：固定消息与非固定消息要接着v0.0.3的分析继续写，回过头来要看之前写的东西说实话自己都有点难以理解。。。不过出于幸运或者努力，总算是看懂了;-(，读源代码（感觉特别是C++）本来就不是件容易的事，所以读源代码一定要做好长期战斗的准备。上面我们分析到了，其实一个消息，就是由这样一个宏来和它的handle建立链接的：LOGINAPP_MESSAGE_DECLARE_ARGS0(importClientMessages, NETWORK_FIXED_MESSAGE)通过上面的分析，我们得知，实际上建立消息和handle映射，起到核心作用的接口是messageHandlers.add(xxx, xxxx)，所以我们跟进去看看（lib/network/message_handler.cpp）：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869MessageHandler* MessageHandlers::add(std::stringihName, MessageArgs* args, int32msgLen, MessageHandler* msgHandler)&#123; if(msgID_ == 1) &#123; //printf(&quot;\n------------------------------------------------------------------\n&quot;); //printf(&quot;KBEMessage_handlers begin:\n&quot;); &#125; //bool isfixedMsg = false; FixedMessages::MSGInfo* msgInfo = FixedMessages::getSingleton().isFixed(ihName.c_str()); if(msgInfo == NULL) &#123; while(true) &#123; if(FixedMessages::getSingleton().isFixed(msgID_)) &#123; msgID_++; //isfixedMsg = true; &#125; else &#123; break; &#125; &#125;; msgHandler-&gt;msgID = msgID_++; &#125; else &#123; msgHandler-&gt;msgID = msgInfo-&gt;msgid; &#125; msgHandler-&gt;name = ihName; msgHandler-&gt;pArgs = args; msgHandler-&gt;msgLen = msgLen; msgHandler-&gt;exposed = false; msgHandler-&gt;pMessageHandlers = this; msgHandler-&gt;onInstall(); msgHandlers_[msgHandler-&gt;msgID] = msgHandler; if(msgLen == NETWORK_VARIABLE_MESSAGE) &#123; //printf(&quot;\tMessageHandlers::add(%d): name=%s, msgID=%d, size=Variable.\n&quot;, // (int32)msgHandlers_.size(), ihName.c_str(), msgHandler-&gt;msgID); &#125; else &#123; if(msgLen == 0) &#123; msgHandler-&gt;msgLen = args-&gt;dataSize(); if(msgHandler-&gt;type() == NETWORK_MESSAGE_TYPE_ENTITY) &#123; msgHandler-&gt;msgLen += sizeof(ENTITY_ID); &#125; &#125; //printf(&quot;\tMessageHandlers::add(%d): name=%s, msgID=%d, size=Fixed(%d).\n&quot;, // (int32)msgHandlers_.size(), ihName.c_str(), msgHandler-&gt;msgID, msgHandler-&gt;msgLen); &#125; //if(isfixedMsg) // printf(&quot;\t\t!!!message is fixed.!!!\n&quot;); returnmsgHandler;&#125; 大意可以理解为，首先看看消息名称是不是一个固定消息，我们跟进去看看（lib/network/fixed_messages.cpp）：123456789101112131415161718192021222324252627FixedMessages::MSGInfo* FixedMessages::isFixed(constchar* msgName)&#123; MSGINFO_MAP::iteratoriter = _infomap.find(msgName); if(iter != _infomap.end()) &#123; MSGInfo* infos = &amp;iter-&gt;second; returninfos; &#125; returnNULL;&#125;//-------------------------------------------------------------------------------------boolFixedMessages::isFixed(MessageIDmsgid)&#123; MSGINFO_MAP::iteratoriter = _infomap.begin(); while (iter != _infomap.end()) &#123; FixedMessages::MSGInfo&amp;infos = iter-&gt;second; if(infos.msgid == msgid) returntrue; ++iter; &#125; returnfalse;&#125; 固定消息通过通读FixedMessages（fixed_message.h/.cpp）可以看到这个_infomap是在loadConfig中建立的，这个_infomap就是所谓的固定消息（fixed message）与其id的映射表。loadConfig就是检视server/messages_fixed.xml，将其中的消息名称与其id关联建立这个映射表。我们继续接着看MessageHandlers::add接口。 非固定消息对于isFixed为假的消息（非固定消息），则为其生成一个id（随着调用add的次序依次递增），这个id是在MessageHandlers类中唯一的，而每个组件的MessageHandlers又是处于自己的命名空间内，所以当出现某个组件的非固定消息时，则会为其生成单一组件内唯一的id（但这个id并不是所有组件内唯一的）。于是可能出现这种情况，Loginapp::xxxx与Dbmgr::yyyy都是非固定消息，但他们却有着同样的消息id，此时若有其他组件发送其中任一消息给其他组件，接受消息的组件将无法识别到底是Loginapp::xxxx或者是Dbmgr::yyyy。当然，只要我们将非固定消息发送给所属的组件，则不会有问题（上例中任何组件将Loginapp::xxxx发送给loginapp都是不会出乱子的）。 dbmgr dbmgr组件主要负责数据库相关的事务，比如：账户登录/注册事务；账户充值]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>kbe</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重读UNP（UNIX网络编程）13章到31章笔记整理（结合TLPI和APUE两书的笔记整理）(二)]]></title>
    <url>%2F2017%2F07%2F29%2F%E9%87%8D%E8%AF%BBUNP%EF%BC%88UNIX%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%EF%BC%8913%E7%AB%A0%E5%88%B031%E7%AB%A0%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86%EF%BC%88%E7%BB%93%E5%90%88TLPI%E5%92%8CAPUE%E4%B8%A4%E4%B9%A6%E7%9A%84%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86%EF%BC%89(%E4%BA%8C)%2F</url>
    <content type="text"><![CDATA[16章 16.3节 ： 非阻塞connect 有三个用途： 我们想在connect的时候处理其他事情 可以同时建立多个连接 可以通过select设置一个更短一点的超时时间 实现步骤： 用fcntl把套接字设置为非阻塞 处理客户端和服务器都在同一主机上的情况 使用select设置超时，并处理超时情况 处理当连接建立的时候，描述符变为可写；以及当连接建立遇到错误的时候， 描述符变为可写并可读的情况 16.6节 ： 非阻塞accept， 用于解决下面问题： “用select检测socket状态，如果有连接就调用accept，这样如果在select检测到由连接请求，在调用accept之前，这个请求断开了，然后调用accept的时候就会阻塞在哪里，除非这时有另外一个连接请求，如果没有，则一直被阻塞在那里。” 解决方案： 使用select在一个监听套接字准备好要被accept时总是把套接字设置为非阻塞 26章和30章介绍了线程和并发/并行的服务器设计范式，等下篇TLPI/APUE的笔记一起整理吧]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>UNP</tag>
        <tag>TLPI</tag>
        <tag>APUE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重读UNP（UNIX网络编程）13章到31章笔记整理（结合TLPI和APUE两书的笔记整理）(一)]]></title>
    <url>%2F2017%2F07%2F28%2F%E9%87%8D%E8%AF%BBUNP%EF%BC%88UNIX%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%EF%BC%8913%E7%AB%A0%E5%88%B031%E7%AB%A0%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86%EF%BC%88%E7%BB%93%E5%90%88TLPI%E5%92%8CAPUE%E4%B8%A4%E4%B9%A6%E7%9A%84%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86%EF%BC%89(%E4%B8%80)%2F</url>
    <content type="text"><![CDATA[因为UNP第三部分（第三版13-31章）的内容结合APUE（UNIX环境高级编程）和TLPI（The Linux Programming Interface）来看才能比较清晰，所以笔记整理会穿插很多这两本书的内容 13章引申知识，作业控制以及相关命令： 另注： 注：但是如上方到后台执行的进程，其父进程还是当前终端shell的进程，而一旦父进程退出，则会发送hangup信号给所有子进程，子进程收到hangup以后也会退出。 13.4节：自定义一个daemon_init函数，涉及到知识点为“如何创建一个daemon（守护进程）”，实现步骤如下： fork之后杀掉父进程（此时子进程被init收养）这是为了为下一步setsid做准备，因为只有不是进程组首进程的进程才能调用setsid， setsid，创建一个新的会话并断开与之前的控制终端的关系， 再次fork并杀掉首进程， 这样就确保了子进程不是一个会话首进程， 根据linux中获取终端的规则（只有会话首进程才能请求一个控制终端）， 这样进程永远不会重新请求一个控制终端 清楚进程的umask，确保daemon创建文件和目录时拥有相应的权限 修改进程的当前工作目录， 通常修改到/目录 关闭进程所有不再需要的文件描述符 打开/dev/null使文件描述符0、1、2指向这个设备， 以防止daemon调用在这些描述符上做I/O操作的库函数而不会意外的失败 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include &quot;unp.h&quot;#include &lt;syslog.h&gt;#define MAXFD 64extern int daemon_proc; /* defined in error.c */intdaemon_init(const char *pname, int facility)&#123; int i; pid_t pid; if ( (pid = Fork()) &lt; 0) return (-1); else if (pid) _exit(0); /* parent terminates */ /* child 1 continues... */ if (setsid() &lt; 0) /* become session leader */ return (-1); Signal(SIGHUP, SIG_IGN); if ( (pid = Fork()) &lt; 0) return (-1); else if (pid) _exit(0); /* child 1 terminates */ /* child 2 continues... */ daemon_proc = 1; /* for err_XXX() functions */ chdir(&quot;/&quot;); /* change working directory */ /* close off file descriptors */ for (i = 0; i &lt; MAXFD; i++) close(i); /* redirect stdin, stdout, and stderr to /dev/null */ open(&quot;/dev/null&quot;, O_RDONLY); open(&quot;/dev/null&quot;, O_RDWR); open(&quot;/dev/null&quot;, O_RDWR); openlog(pname, LOG_PID, facility); return (0); /* success */&#125; nohup和setsid用法 如果我们要在退出shell的时候继续运行进程，则需要使用nohup忽略hangup信号，或者setsid将父进程设为init进程；1234567891011121314151617181920212223242526272829303132333435363738394041b@b-VirtualBox:~/my_temp_test$ nohup ./o_multi_thread_process &amp;[1] 3487b@b-VirtualBox:~/my_temp_test$ nohup: ignoring input and appending output to ‘nohup.out’^Cb@b-VirtualBox:~/my_temp_test$ jobs[1]+ Running nohup ./o_multi_thread_process &amp;b@b-VirtualBox:~/my_temp_test$ ps -ef | grep multib 3487 3004 0 20:05 pts/3 00:00:00 ./o_multi_thread_processb 3488 3487 0 20:05 pts/3 00:00:00 ./o_multi_thread_processb 3491 3004 0 20:05 pts/3 00:00:00 grep --color=auto multib@b-VirtualBox:~/my_temp_test$ bg %1bash: bg: job 1 already in backgroundb@b-VirtualBox:~/my_temp_test$ fg %1nohup ./o_multi_thread_process^Z[1]+ Stopped nohup ./o_multi_thread_processb@b-VirtualBox:~/my_temp_test$ bg %1[1]+ nohup ./o_multi_thread_process &amp;b@b-VirtualBox:~/my_temp_test$ jobs -l[1]+ 3487 Running nohup ./o_multi_thread_process &amp;b@b-VirtualBox:~/my_temp_test$ fg %1nohup ./o_multi_thread_process^Cb@b-VirtualBox:~/my_temp_test$ jobsb@b-VirtualBox:~/my_temp_test$ ps -ef | grep multib 3499 3004 0 20:11 pts/3 00:00:00 grep --color=auto multib@b-VirtualBox:~/my_temp_test$ setsid ./o_multi_thread_process &amp;[1] 3502b@b-VirtualBox:~/my_temp_test$ ProcessA: 3503 step1ProcessA: 3503 thread 139947724490496 step2ProcessA: 3503 thread 139947724490496 step3ProcessB: 3504 step1ProcessB: 3504 step2ProcessB: 3504 step3^C[1]+ Done setsid ./o_multi_thread_processb@b-VirtualBox:~/my_temp_test$ ps -ef | grep multib 3503 1256 0 20:12 ? 00:00:00 ./o_multi_thread_processb 3504 3503 0 20:12 ? 00:00:00 ./o_multi_thread_processb 3507 3004 0 20:12 pts/3 00:00:00 grep --color=auto multib@b-VirtualBox:~/my_temp_test$ jobs disown用法 那么对于已经在后台运行的进程，该怎么办呢？可以使用disown命令1234567891011121314b@b-VirtualBox:~/my_temp_test$ ./o_multi_thread_process &amp;[1] 3523b@b-VirtualBox:~/my_temp_test$ ProcessA: 3523 step1ProcessA: 3523 thread 140501901821696 step2ProcessA: 3523 thread 140501901821696 step3ProcessB: 3524 step1ProcessB: 3524 step2ProcessB: 3524 step3^Cb@b-VirtualBox:~/my_temp_test$ jobs -l[1]+ 3523 Running ./o_multi_thread_process &amp;b@b-VirtualBox:~/my_temp_test$ disown -h %1b@b-VirtualBox:~/my_temp_test$ jobs[1]+ Running ./o_multi_thread_process &amp;]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>UNP</tag>
        <tag>TLPI</tag>
        <tag>APUE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[crontab笔记整理]]></title>
    <url>%2F2017%2F07%2F09%2Fcrontab%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86%2F</url>
    <content type="text"><![CDATA[crontab命令被用来提交和管理用户的需要周期性执行的任务，与windows下的计划任务类似，当安装完成操作系统后，默认会安装此服务工具，并且会自动启动crond进程，crond进程每分钟会定期检查是否有要执行的任务，如果有要执行的任务，则自动执行该任务。 -e：编辑该用户的计时器设置； -l：列出该用户的计时器设置； -r：删除该用户的计时器设置； -u&lt;用户名称&gt;：指定要设定计时器的用户名称 m h dom mon dow command分 时 日 月 周 命令 星号（*）：代表所有可能的值，例如month字段如果是星号，则表示在满足其它字段的制约条件后每月都执行该命令操作 逗号（,）：可以用逗号隔开的值指定一个列表范围，例如，“1,2,5,7,8,9” 中杠（-）：可以用整数之间的中杠表示一个整数范围，例如“2-6”表示“2,3,4,5,6” 正斜线（/）：可以用正斜线指定时间的间隔频率，例如“0-23/2”表示每两小时执行一次。同时正斜线可以和星号一起使用，例如*/10，如果用在minute字段，表示每十分钟执行一次。 例子 */1 * * * * sed -i &#39;$a\nani&#39; /home/b/my_temp_test/practice.cpp每隔一分钟就在practice.cpp文件的最后一行插入字符串“nani” 3,15 8-11/2 * 12 0 sed -i &#39;$a\nani&#39; /home/b/my_temp_test/practice.cpp12月的周日的8-11时的时间段每隔两个小时就在第3分钟和第15分钟的时候，在practice.cpp文件的最后一行插入字符串“nani”]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>crontab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重读UNIX网络编程第三章到第十一章笔记整理(二)]]></title>
    <url>%2F2017%2F07%2F03%2F%E9%87%8D%E8%AF%BBUNIX%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%AC%AC%E4%B8%89%E7%AB%A0%E5%88%B0%E7%AC%AC%E5%8D%81%E4%B8%80%E7%AB%A0%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86(%E4%BA%8C)%2F</url>
    <content type="text"><![CDATA[第七章 7.5节 ： 通用套接字选项， 常用的有 SO_KEEPALIVE SO_REVBUF SO_SNDBUF SO_REUSEADDR 7.9节 ： tcp套接字选项， 常用的有 TCP_NODELAY TCP_MAXSEG 7.11节 ：fcntl函数，常用的用法是使用F_SETFL命令设置O_NOBLOCK文件状态标志， 我们可以把一个套接字设置为非阻塞型。 第八章 8.11节 ： UDP的connect函数，可以获得性能提升，因为未连接的udp每次sendto发送数据报的时候都要连接然后发送然后断开， 之后第二个数据报又要重复上述步骤，而连接后的udp套接字只需要连接然后发送第一个数据报然后发送第二个、第三个就行了]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>UNP</tag>
        <tag>TLPI</tag>
        <tag>APUE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重读UNIX网络编程第三章到第十一章笔记整理(一)]]></title>
    <url>%2F2017%2F07%2F02%2F%E9%87%8D%E8%AF%BBUNIX%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%AC%AC%E4%B8%89%E7%AB%A0%E5%88%B0%E7%AC%AC%E5%8D%81%E4%B8%80%E7%AB%A0%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86(%E4%B8%80)%2F</url>
    <content type="text"><![CDATA[因为第二章之后基本都是纯Socket API的内容， 第三章到第十一章的笔记整理合并到一起。 第三章 3.4 ：字节排序函数，涉及到大小端，处理网络字节序和主机字节序的转换 3.6 ： 地址转换函数，吹在ASCII字符串与网络字节序的二进制值之间转换网际地址第四章 4.9节：close函数， 涉及到描述符引用计数，所以多进程并发服务器才可以共享已连接套接字，因为父进程调用close函数知识把该套接字标记成已关闭并导致该套接字描述符减1。只要引用计数的值仍大于0，就不会引发tcp的四分组连接终止序列 第五章 5.9节：处理SIGCHLD信号， 涉及到僵死进程（子进程终止时给父进程发送了一个SIGCHLD信号，若父进程未加处理，则子进程进入僵死状态），所以要建立该信号处理函数，并在函数中调用waitpid来处理 5.10节 ：使用wait或者waitpid来处理已终止的子进程，通常是使用waitpid并指定WNOHANG选项，来告知waitpid在有尚未终止的子进程在运行时不要阻塞。 第六章 同步I/O操作：导致请求进程阻塞，知道I/O操作完成 异步I/O操作：不导致请求进程阻塞 6.3节 ： select函数，必须得清楚select跟linux特有的epoll的区别， 有三点： 数量限制 ： select默认只支持1024个；epoll并没有最大数目限制 内存拷贝 ： select需要把fd_set数据结构从用户态到内核态来回拷贝； 而epoll是基于mmap技术用同一块内存实现的 效率 ： select每次都要遍历所有文件描述符， 集合越大速度越慢；而epoll维护着一个就绪列表， 每次只需要简单的从列表里取出就行了，只有活跃的socket才会触发相关callback 6.6节 ： shutdown函数，shutdown可以不用管引用计数就激发tcp的正常连接终止序列。当关闭连接的写这一半，对于tcp连接， 这称为半关闭（half-close）]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>UNP</tag>
        <tag>TLPI</tag>
        <tag>APUE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重读UNIX网络编程第二章笔记修正（结合TLPI和APUE两书的笔记整理）]]></title>
    <url>%2F2017%2F06%2F05%2F%E9%87%8D%E8%AF%BBUNIX%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%AC%AC%E4%BA%8C%E7%AB%A0%E7%AC%94%E8%AE%B0%E4%BF%AE%E6%AD%A3%EF%BC%88%E7%BB%93%E5%90%88TLPI%E5%92%8CAPUE%E4%B8%A4%E4%B9%A6%E7%9A%84%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86%EF%BC%89%2F</url>
    <content type="text"><![CDATA[为加深理解, 故本章老笔记内容大幅删减重写.第二章重点如下 : TCP (Transmission Control Protocol)传输控制协议. 特性如下 : 面向连接 全双工 可靠, 关心确认/超时/重传等, 保证顺序 流量控制 字节流, 没有任何记录边界 UDP (User Datagram Protocol)用户数据报协议. 特性如下 : 无连接 不可靠, 不保证顺序/是否到达/是否重复 每个数据报都有一个长度 TCP三路握手(three-way handshake) TCP选项 : MSS选项 发送SYN的TCP一端使用本选项通告对端他的最大分节大小(maximum segment size) 窗口规模选项 时间戳选项, 对于高速网络连接是必要的. TCP连接终止 : TCP状态转换图 TCP连接的分组交换 TIME_WAIT状态存在的理由 : 可靠地实现TCP全双工连接的终止 允许老的重复分节在网络中消逝 分节是TCP传递给IP的数据单元 Linux下面一共有65535个端口 其中1–1023是系统保留的， 1024–65535是供用户使用的。 0到1024是众所周知的端口（知名端口，常用于系统服务等，例如http服务的端口号是80)。个人写的应用程序，尽量不要使用0到1024之间的端口号。 套接字对是一个定义该连接的两个端点的四元组: 本地IP地址 本地TCP端口号 外地IP地址 外地TCP端口号 缓冲区大小及限制 IPv4数据报的最大大小为65535字节, 因为其总长度字段占据16位 以太网的MTU是1500字节, IPv4要求的最小链路MTU是68字节, 这允许最大的IPv4首部(包括20字节的固定长度部分和最多40字节的选项部分)拼接最小的片段 在两个主机之间的路径中最小的MTU成为路径MTU 当一个IP数据报将从某个接口送出时, 如果他的大小超过相应链路的MTU, IPv4和IPv6都将执行分片 IPv4首部的”不分片(don’t fragment)”位(即DF位)若被设置, 那么不管是发送这些数据报的主机还是转发他们的路由器, 都不允许对他们分片 IPv4和IPv6都定义了最小重组缓冲区大小(minimum reassembly buffersize), IPv4的主机要求不能超过576字节的数据， 所以很多使用UDP的IPv4应用（如DNS）都避免产生大于这个大小的数据报 MSS : TCP最大分节大小， 在以太网中使用IPv4的MSS值为1460（以太网的MTU - IPv4首部 - TCP首部 = 1500 - 20 - 20） TCP输出示意图 : UDP输出示意图 (因为UDP是不可靠的, 他不必保存应用进程数据的一个副本, 因此无需一个真正的发送缓冲区, 所以为虚线框): 常见因特网应用所使用的协议 ping ： ICMP DNS ： UDP、TCP DHCP : UDP SSH : TCP FTP : TCP HTTP : TCP]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>UNP</tag>
        <tag>TLPI</tag>
        <tag>APUE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重读UNIX网络编程第一章笔记修正]]></title>
    <url>%2F2017%2F06%2F02%2F%E9%87%8D%E8%AF%BBUNIX%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%AC%94%E8%AE%B0%E4%BF%AE%E6%AD%A3%2F</url>
    <content type="text"><![CDATA[又准备从头看一遍unp, 把一些老笔记放到博客里来就当网盘吧, 顺便修正以及删减一些之前不够精炼的老笔记内容. 第一章重点如下 : OSI (open systems interconnection), 即计算机通信开放系统互联模型 OSI分为七层, 从上到下依次为 应用层 表现层 会话层 传输层 网络层 数据链路层 物理层 对于网际网协议族, OSI顶上三层合并为一层, 称为应用层. 传输层对应着tcp/udp等, 网络层对应着IPv4/IPv6, OSI的数据链路层和物理层是随系统提供的设备驱动程序和网络硬件 套接字编程接口是从OSI顶上三层(网际协议的应用层)进入传输层的接口. 为何套接字要设计为顶上三层进入传输层的接口??因为OSI顶上三层处理具体网络应用的所有细节却对通信细节了解很少;底下四层对具体网络应用了解不多, 却处理所有的通信细节.]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>UNP</tag>
        <tag>TLPI</tag>
        <tag>APUE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kbe服务端笔记(一)]]></title>
    <url>%2F2017%2F04%2F01%2Fkbe%E6%9C%8D%E5%8A%A1%E7%AB%AF%E7%AC%94%E8%AE%B0(%E4%B8%80)%2F</url>
    <content type="text"><![CDATA[main看起来似乎所有的组件都有一个这样的宏(KBENGINE_MAIN)来包裹main函数123456intKBENGINE_MAIN(intargc, char* argv[])&#123; ENGINE_COMPONENT_INFO&amp;info = g_kbeSrvConfig.getXXX(); returnkbeMainT&lt;XXX&gt;(argc, argv, YYY, info.externalPorts_min, info.externalPorts_max, info.externalInterface, 0, info.internalInterface);&#125; 这个宏展开是这样子：123456789101112131415kbeMain(intargc, char* argv[]); \intmain(intargc, char* argv[]) \&#123; \ loadConfig(); \ g_componentID = genUUID64(); \ parseMainCommandArgs(argc, argv); \ char dumpname[MAX_BUF] = &#123;0&#125;; \ kbe_snprintf(dumpname, MAX_BUF, &quot;%&quot;PRAppID, g_componentID); \ KBEngine::exception::installCrashHandler(1, dumpname); \ intretcode = -1; \ THREAD_TRY_EXECUTION; \ retcode = kbeMain(argc, argv); \ THREAD_HANDLE_CRASH; \ returnretcode; \&#125; \ 稍微整理一下之后main函数看起来很像是这个样子：1234567891011121314151617181920intkbeMain(intargc, char* argv[]);intmain(intargc, char* argv[])&#123; loadConfig(); g_componentID = genUUID64(); parseMainCommandArgs(argc, argv);chardumpname[MAX_BUF] = &#123;0&#125;; kbe_snprintf(dumpname, MAX_BUF, &quot;%&quot;PRAppID, g_componentID); KBEngine::exception::installCrashHandler(1, dumpname);intretcode = -1; THREAD_TRY_EXECUTION;retcode = kbeMain(argc, argv); THREAD_HANDLE_CRASH;return (retcode);&#125;intkbeMain(intargc, char* argv[])&#123; ENGINE_COMPONENT_INFO&amp;info = g_kbeSrvConfig.getXXX(); return kbeMainT&lt;XXX&gt;(argc, argv, YYY, info.externalPorts_min, info.externalPorts_max, info.externalInterface, 0, info.internalInterface);&#125; 基本可以理解为每个组件的main函数流程都是一样的，只是在特化kbeMainT时所给参数不一样。 ServerConfig：ServerConfig涉及到服务端每个组件的各种配置选项，比如数据库访问。它的构造在组件名.cpp中，比如loginapp就在loginapp.cpp，machine就在machine.cpp中，loginapp的如下（server/loginapp/loginapp.cpp）：12ServerConfigg_serverConfig;KBE_SINGLETON_INIT(Loginapp); 它的初始化（配置）工作主要由loadConfig接口完成，如下（lib/server/kbemain.h）：12345678910inlinevoidloadConfig()&#123; Resmgr::getSingleton().initialize(); // &quot;../../res/server/kbengine_defs.xml&quot; g_kbeSrvConfig.loadConfig(&quot;server/kbengine_defs.xml&quot;); // &quot;../../../assets/res/server/kbengine.xml&quot; g_kbeSrvConfig.loadConfig(&quot;server/kbengine.xml&quot;);&#125; Resmgr：Resmgr负责管理kbe的所有资源管理，比如资源路径，环境变量。Resmgr的构造地方如下（lib/network/fixed_messages.cpp）：1234567FixedMessages::FixedMessages():_infomap(),_loaded(false)&#123; newResmgr(); Resmgr::getSingleton().initialize();&#125; 我们可以理解为FixedMessages构造的时候Resmgr就构造了。 Resmgr的初始化（配置）工作主要由initialize接口完成，代码如上。]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>kbe</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kbe的UE4的demo大体解读]]></title>
    <url>%2F2017%2F03%2F11%2Fkbe%E7%9A%84UE4%E7%9A%84demo%E5%A4%A7%E4%BD%93%E8%A7%A3%E8%AF%BB%2F</url>
    <content type="text"><![CDATA[写到一半发现论坛的热门帖子里官方写了个u3d的demo源码解析, 内容几乎重复, u3d跟ue4的demo框架流程几乎都是差不多的, 直接给出官方帖子的链接好了, 尴尬:http://bbs.kbengine.org/forum.php?mod=viewthread&amp;tid=166]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>kbe</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kbe之ubuntu下的编译]]></title>
    <url>%2F2017%2F02%2F10%2Fkbe%E4%B9%8Bubuntu%E4%B8%8B%E7%9A%84%E7%BC%96%E8%AF%91%2F</url>
    <content type="text"><![CDATA[感觉之前的博客已经整理了大多数之前的关于基础的私人笔记, 现在应该可以讨论一下实操的东西了.先来一发之前的kbe在ubuntu下的编译笔记吧, 因为官方对于ubuntu下的kbe编译文档是有问题的. 编译步骤 安装openssl : sudo apt-get install libssl-dev 安装mysql : sudo apt-get install libmysqld-dev sudo apt-get install mysql-server 编译kbe : cd kbengine/kbe/src chmod -R 755 . make]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>kbe</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kbe之1分钟完成安装]]></title>
    <url>%2F2017%2F02%2F09%2Fkbe%E4%B9%8B1%E5%88%86%E9%92%9F%E5%AE%8C%E6%88%90%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[官方是有自动化的安装py脚本的, 不过还是有很多小坑的.不过其实脚本主要也就是只做两件事, 其他都是可选的: 配置环境变量 安装mysql 安装步骤 安装kbe之前请提前在mysql里 建一个数据库(比如建一个数据库kbe_database) 一个至少拥有select,insert,update,delete,create,drop权限的用户(比如这个用户是kbe_user) (具体详情请谷歌, 本篇文章是讲kbe的安装的, 不讨论mysql, 弄完mysql之后就可以开始下面的1分钟kbe安装教程啦) 找到你的kbe根目录, 然后进入根目录, 比如你的kbe根目录是kbengine, 则 : cd kbengine sudo python kbengine/kbe/tools/server/install/installer.py install 然后它就会问你 :Install KBEngine to Linux-account(No input is kbe): 为了简单起见, 建议直接填写你当前的linux用户名称, 比如我的是”b” 然后就是开始配置环境变量了, 它就会显示 12345678Check the dependences:- kbe_environment: checking...ERROR: KBE_ROOT: is error! The directory or file not found:KBE_ROOT//kbeKBE_ROOT=KBE_ROOT current: reset KBE_ROOT(No input is [/home/b/kbengine-0.9.18/]): 直接敲回车 他之后显示的都直接敲回车, 用默认的就可以, 直到他开始问你mysql的东西, 到mysql他会问 12- mysql: checking...- MySQL is installed on the remote machine?[yes/no] 这里我们直接填yes, 然后就直接填我们之前建立好的数据库kbe_database和用户kbe_user即可, 它会显示 : 12345678- Enter mysql ip-address:127.0.0.1- Enter mysql ip-port:3306- Enter mysql-account:kbe_user- Enter mysql-password:123456- Enter mysql-databaseName:kbe_database- mysql: yesModified: /home/b/kbengine-0.9.18//kbe/res/server/kbengine_defs.xmlKBEngine has been successfully installed! 是否安装成功 找到你的kbe根目录, 然后进入根目录, 比如你的kbe根目录是kbengine, 则1. 进入kbe根目录下的assets目录 : cd kbengine/assets 2. 运行启动脚本 : sh ./start_server.sh 用ps检查一下是否有以下进程再跑 : 12345678910b@b-VirtualBox:~/kbengine-0.9.18/assets$ ps -ef | grep -v grep | grep -i kbeb 15504 1372 0 04:28 pts/1 00:00:01 /home/b/kbengine-0.9.18/kbe/bin/server//machine --cid=2129652375332859700 --gus=1b 15505 1372 0 04:28 pts/1 00:00:05 /home/b/kbengine-0.9.18/kbe/bin/server//logger --cid=1129653375331859700 --gus=2b 15506 1372 0 04:28 pts/1 00:00:02 /home/b/kbengine-0.9.18/kbe/bin/server//interfaces --cid=1129652375332859700 --gus=3b 15507 1372 0 04:28 pts/1 00:00:06 /home/b/kbengine-0.9.18/kbe/bin/server//dbmgr --cid=3129652375332859700 --gus=4b 15508 1372 0 04:28 pts/1 00:00:07 /home/b/kbengine-0.9.18/kbe/bin/server//baseappmgr --cid=4129652375332859700 --gus=5b 15509 1372 0 04:28 pts/1 00:00:07 /home/b/kbengine-0.9.18/kbe/bin/server//cellappmgr --cid=5129652375332859700 --gus=6b 15510 1372 0 04:28 pts/1 00:00:03 /home/b/kbengine-0.9.18/kbe/bin/server//baseapp --cid=6129652375332859700 --gus=7b 15511 1372 0 04:28 pts/1 00:00:03 /home/b/kbengine-0.9.18/kbe/bin/server//cellapp --cid=7129652375332859700 --gus=8b 15512 1372 0 04:28 pts/1 00:00:06 /home/b/kbengine-0.9.18/kbe/bin/server//loginapp --cid=8129652375332859700 --gus=9 检查我们mysql中的kbe_database数据库里是否多了几个表 : 1234567891011mysql&gt; show tables;+---------------------------+| Tables_in_b_test_database |+---------------------------+| kbe_accountinfos || kbe_email_verification || kbe_entitylog || kbe_serverlog || tbl_Account |+---------------------------+5 rows in set (0.00 sec) 好, 如果都有基本安装完成!]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>kbe</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IPC进程间通信]]></title>
    <url>%2F2017%2F01%2F27%2FIPC%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1%2F</url>
    <content type="text"><![CDATA[IPC进程间通信 1.匿名管道( pipe )：匿名管道是一种半双工的通信方式，通常是在父子进程间使用。 2.命名管道 (named pipe) ：命名管道也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。 3.信号量( semophore ) ：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。 4.消息队列( message queue ) ：消息队列是消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。 5.信号 ( sinal ) ：信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。 6.共享内存( shared memory ) ：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号量，配合使用，来实现进程间的同步和通信。 7.套接字( socket ) ：套接字也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同进程间的进程通信。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>IPC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5分钟上手boost.asio]]></title>
    <url>%2F2017%2F01%2F12%2F5%E5%88%86%E9%92%9F%E4%B8%8A%E6%89%8Bboost.asio%2F</url>
    <content type="text"><![CDATA[Boost.Asio入门首先，让我们先来了解一下什么是Boost.Asio？怎么编译它？ linux下直接 : sudo apt-get install libboost-all-dev 什么是Boost.Asio简单来说，Boost.Asio是一个跨平台的、主要用于网络和其他一些底层输入/输出编程的C++库。 异步VS同步 首先，异步编程和同步编程是非常不同的。 在同步编程中，所有的操作都是顺序执行的，比如从socket中读取（请求），然后写入（回应）到socket中。 每一个操作都是阻塞的。 因为操作是阻塞的，所以为了不影响主程序，当在socket上读写时，通常会创建一个或多个线程来处理socket的输入/输出。 因此，同步的服务端/客户端通常是多线程的。 相反的，异步编程是事件驱动的。 虽然启动了一个操作，但是你不知道它何时会结束；它只是提供一个回调给你，当操作结束时，它会调用这个API，并返回操作结果。 对于有着丰富经验的QT（诺基亚用来创建跨平台图形用户界面应用程序的库）程序员来说，这就是他们的第二天性。 因此，在异步编程中，你只需要一个线程。 因为中途做改变会非常困难而且容易出错，所以你在项目初期（最好是一开始）就得决定用同步还是异步的方式实现网络通信。 不仅API有极大的不同，你程序的语意也会完全改变（异步网络通信通常比同步网络通信更加难以测试和调试）。 你需要考虑是采用阻塞调用和多线程的方式（同步，通常比较简单），或者是更少的线程和事件驱动（异步，通常更复杂）。 同步例子同步客户端下面是一个基础的同步客户端例子： 12345using boost::asio;io_service service;ip::tcp::endpoint ep( ip::address::from_string(&quot;127.0.0.1&quot;), 2001);ip::tcp::socket sock(service);sock.connect(ep); 首先，你的程序至少需要一个io_service实例。 Boost.Asio使用io_service同操作系统的输入/输出服务进行交互。 通常一个io_service的实例就足够了。 然后，创建你想要连接的地址和端口，再建立socket。 把socket连接到你创建的地址和端口。 同步服务端下面是一个简单的同步Boost.Asio的服务端：1234567891011121314151617typedef boost::shared_ptr&lt;ip::tcp::socket&gt; socket_ptr;io_service service;ip::tcp::endpoint ep( ip::tcp::v4(), 2001)); // listen on 2001ip::tcp::acceptor acc(service, ep);while ( true) &#123; socket_ptr sock(new ip::tcp::socket(service)); acc.accept(*sock); boost::thread( boost::bind(client_session, sock));&#125;void client_session(socket_ptr sock) &#123; while ( true) &#123; char data[512]; size_t len = sock-&gt;read_some(buffer(data)); if ( len &gt; 0) write(*sock, buffer(&quot;ok&quot;, 2)); &#125;&#125; 首先，同样是至少需要一个io_service实例。 然后你指定你想要监听的端口，再创建一个接收器——一个用来接收客户端连接的对象。 在接下来的循环中，你创建一个虚拟的socket来等待客户端的连接。 然后当一个连接被建立时，你创建一个线程来处理这个连接。 在client_session线程中来读取一个客户端的请求，进行解析，然后返回结果。 异步例子异步客户端而创建一个异步的客户端，你需要做如下的事情： 123456789using boost::asio;io_service service;ip::tcp::endpoint ep( ip::address::from_string(&quot;127.0.0.1&quot;), 2001);ip::tcp::socket sock(service);sock.async_connect(ep, connect_handler);service.run();void connect_handler(const boost::system::error_code &amp; ec) &#123; // 如果ec返回成功我们就可以知道连接成功了&#125; 在程序中你需要创建至少一个io_service实例。 你需要指定连接的地址以及创建socket。 当连接完成时（其完成处理程序）你就异步地连接到了指定的地址和端口，也就是说，connect_handler被调用了。 当connect_handler被调用时，检查错误代码（ec），如果成功，你就可以向服务端进行异步的写入。 注意：只要还有待处理的异步操作，servece.run()循环就会一直运行。 在上述例子中，只执行了一个这样的操作，就是socket的async_connect。 在这之后，service.run()就退出了。 每一个异步操作都有一个完成处理程序——一个操作完成之后被调用的函数。 异步服务端 下面的代码是一个基本的异步服务端 123456789101112131415161718using boost::asio;typedef boost::shared_ptr&lt;ip::tcp::socket&gt; socket_ptr;io_service service;ip::tcp::endpoint ep( ip::tcp::v4(), 2001)); // 监听端口2001ip::tcp::acceptor acc(service, ep);socket_ptr sock(new ip::tcp::socket(service));start_accept(sock);service.run();void start_accept(socket_ptr sock) &#123; acc.async_accept(*sock, boost::bind( handle_accept, sock, _1) );&#125;void handle_accept(socket_ptr sock, const boost::system::error_code &amp;err) &#123; if ( err) return; // 从这里开始, 你可以从socket读取或者写入 socket_ptr sock(new ip::tcp::socket(service)); start_accept(sock);&#125; 在上述代码片段中，首先，你创建一个io_service实例，指定监听的端口。 然后，你创建接收器acc——一个接受客户端连接，创建虚拟的socket，异步等待客户端连接的对象。 最后，运行异步service.run()循环。 当接收到客户端连接时，handle_accept被调用（调用async_accept的完成处理程序）。 如果没有错误，这个socket就可以用来做读写操作。 在使用这个socket之后，你创建了一个新的socket，然后再次调用start_accept()，用来创建另外一个“等待客户端连接”的异步操作，从而使service.run()循环一直保持忙碌状态。]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>boost</tag>
        <tag>asio</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[快速编译技巧]]></title>
    <url>%2F2016%2F11%2F01%2F%E5%BF%AB%E9%80%9F%E7%BC%96%E8%AF%91%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[项目越来越大，每次需要重新编译整个项目都是一件很浪费时间的事情。Research了一下，找到以下可以帮助提高速度的方法，总结一下。 tmpfs 有人说在Windows下用了RAMDisk把一个项目编译时间从4. 5小时减少到了5分钟，也许这个数字是有点夸张了，不过粗想想，把文件放到内存上做编译应该是比在磁盘 上快多了吧，尤其如果编译器需要生成很多临时文件的话。 这个做法的实现成本最低，在Linux中，直接mount一个tmpfs就可以了。而且对所编译的工程没有任何要求，也不用改动编译环境。 mount -t tmpfs tmpfs ~/build -o size=1G 用2.6.32.2的Linux Kernel来测试一下编译速度： 用物理磁盘：40分16秒 用tmpfs：39分56秒 呃……没什么变化。看来编译慢很大程度上瓶颈并不在IO上面。但对于一个实际项目来说， 编译过程中可能还会有打包等IO密集的操作，所以只要可能，用tmpfs是有 益无害的。 当然对于大项目来说，你需要有足够的内存才能负担得起这个tmpfs的开销。 make -j 既然IO不是瓶颈，那CPU就应该是一个影响编译速度的重要因素了。 用make -j带一个参数，可以把项目在进行并行编译，比如在一台双核的机器上，完全可以用make -j4，让make最多允许4个编译命令同时执行，这样可以更有效的利用CPU资源。 还是用Kernel来测试： 用make： 40分16秒 用make -j4：23分16秒 用make -j8：22分59秒 由此看来，在多核CPU上，适当的进行并行编译还是可以明显提高编译速度的。但并行的任务不宜太多，一般是以CPU的核心数目的两倍为宜。 不过这个方案不是完全没有cost的，如果项目的Makefile不规范，没有正确的设置好依赖关系，并行编译的结果就是编译不能正常进行。如果依赖关系设置过于保守，则可能本身编译的可并行度就下降了，也不能取得最佳的效果。 ccache ccache用于把编译的中间结果进行缓存，以便在再次编译的时候可以节省时间。这对于玩Kernel来说实在是再好不过了，因为经常需要修改一些Kernel的代码，然后再重新编译，而这两次编译大部分东西可能都没有发生变化。对于平时开发项目来说，也是一样。为什么不是直接用make所支持的增量编译呢？还是因为现实中，因为Makefile的不规范，很可能这种“聪明”的方案根本不能正常工作，只有每次make clean再make才行。 安装完ccache后，可以在/usr/local/bin下建立gcc，g++，c++，cc的symboliclink，链到/usr/bin/ccache上。总之确认系统在调用gcc等命令时会调用到ccache就可以了（通常情况下/usr/local/bin会在PATH中排在/usr/bin前面）。 继续测试： 用ccache的第一次编译(make -j4)：23分38秒 用ccache的第二次编译(make -j4)：8分48秒 用ccache的第三次编译(修改若干配置，make -j4)：23分48秒 看来修改配置（我改了CPU类型…）对ccache的影响是很大的，因为基本头文件发生变化后，就导致所有缓存数据都无效了，必须重头来做。但如果只是修改一些.c文件的代码，ccache的效果还是相当明显的。而且使用ccache对项目没有特别的依赖，布署成本很低，这在日常工作中很实用。 可以用ccache -s来查看cache的使用和命中情况： cache directory /home/lifanxi/.ccache cache hit 7165 cache miss 14283 called for link 71 not a C/C++ file 120 no input file 3045 files in cache 28566 cache size 81.7 Mbytes max cache size 976.6 Mbytes 可以看到，显然只有第二编次译时cache命中了，cache miss是第一次和第三次编译带来的。两次cache占用了81.7M的磁盘，还是完全可以接受的。 distcc 一台机器的能力有限，可以联合多台电脑一起来编译。这在公司的日常开发中也是可行的，因为可能每个开发人员都有自己的开发编译环境，它们的编译器版本一般是一致的，公司的网络也通常具有较好的性能。这时就是distcc大显身手的时候了。 使用distcc，并不像想象中那样要求每台电脑都具有完全一致的环境，它只要求源代码可以用make -j并行编译，并且参与分布式编译的电脑系统中具有相同的编译器。因为它的原理只是把预处理好的源文件分发到多台计算机上，预处理、编译后的目标文件的链接和其它除编译以外的工作仍然是在发起编译的主控电脑上完成，所以只要求发起编译的那台机器具备一套完整的编译环境就可以了。 distcc安装后，可以启动一下它的服务： /usr/bin/distccd –daemon –allow 10.64.0.0/16 默认的3632端口允许来自同一个网络的distcc连接。 然后设置一下DISTCC_HOSTS环境变量，设置可以参与编译的机器列表。 通常localhost也参与编译，但如果可以参与编译的机器很多，则可以把localhost从这个列表 中去掉，这样本机就完全只是进行预处理、分发和链接了，编译都在别的机器上完成。 因为机器很多时，localhost的处理负担很重，所以它就不再“兼职”编译了。 export DISTCC_HOSTS=&quot;localhost 10.64.25.1 10.64.25.2 10.64.25.3&quot; 然后与ccache类似把g++，gcc等常用的命令链接到/usr/bin/distcc上就可以了。 在make的时候，也必须用-j参数，一般是参数可以用所有参用编译的计算机CPU内核总数的两倍做为并行的任务数。 同样测试一下： 一台双核计算机，make -j4：23分16秒 两台双核计算机，make -j4：16分40秒 两台双核计算机，make -j8：15分49秒 跟最开始用一台双核时的23分钟相比，还是快了不少的。如果有更多的计算机加入，也可以得到更好的效果。 在编译过程中可以用distccmon-text来查看编译任务的分配情况。distcc也可以与ccache同时使用，通过设置一个环境变量就可以做到，非常方便。 总结 tmpfs： 解决IO瓶颈，充分利用本机内存资源 make -j： 充分利用本机计算资源 distcc： 利用多台计算机资源 ccache： 减少重复编译相同代码的时间 这些工具的好处都在于布署的成本相对较低，综合利用这些工具，就可以轻轻松松的节省相当可观的时间。 上面介绍的都是这些工具最基本的用法，更多的用法可以参考它们各自的man page。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>编译</tag>
        <tag>make</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一个群聚(鱼群)AI插件基于虚幻4(有现成打包好的试玩demo, 源码在GitHub)]]></title>
    <url>%2F2016%2F10%2F18%2F%E4%B8%80%E4%B8%AA%E7%BE%A4%E8%81%9A(%E9%B1%BC%E7%BE%A4)AI%E6%8F%92%E4%BB%B6%E5%9F%BA%E4%BA%8E%E8%99%9A%E5%B9%BB4(%E6%9C%89%E7%8E%B0%E6%88%90%E6%89%93%E5%8C%85%E5%A5%BD%E7%9A%84%E8%AF%95%E7%8E%A9demo%2C%20%E6%BA%90%E7%A0%81%E5%9C%A8GitHub)%2F</url>
    <content type="text"><![CDATA[fishA fish flock AI Plugin for Unreal Engine 4 一个基于虚幻4的鱼群 AI 插件 this Plugin version can Run 2000+ fishes at the same time 这个插件版本可以同时运行 2000+ 条鱼儿 Video Preview Watch the Video Preview 查看 视频演示 Download &amp; PlayDownload Download MyFish.exe (Win64) (This is packaged by an unoptimized version( check out branch old_demo)) 下载 MyFish.exe (Win64) 玩玩 这个包是没有经过优化过的版本打包出来的(是用old_demo分支的版本打包的) How to play VR : (My Device is HTC Vive) Motion Controller FaceButton1 =&gt; Move forward 手柄圆盘上键 =&gt; 往前移动 PC’s KeyBoard Arrow UP and Down =&gt; Move faster or slower 电脑键盘的上下箭头键 =&gt; 调整移动速度 Hold Motion Controller Trigger Down =&gt; Attract fishes 按住手柄扳机键 =&gt; 吸引鱼群 PC : EQ =&gt; Up &amp; Down EQ 键 =&gt; 上下 WASD =&gt; Basic movement WASD 键 =&gt; 基本的移动指令(前后左右) Hold Left Mouse Button Down =&gt; Attract fishes 按住鼠标左键 =&gt; 吸引鱼群 Arrow UP and Down =&gt; Move faster or slower 上下箭头键 =&gt; 调整移动速度 How to useplace Plugins folder in your project root directory, then just like 把Plugins文件夹放在你项目的根目录, 接下来如图 About This Unreal Engine Version 4.15 Read Craig Reynolds’s thesis 查看 Craig Reynolds的论文 This project implements a new flocking Ai algorithm, with 3 components : 算法简要 Separation : every fish will try to steer away from their neighbors 分离性 ：每条鱼都会与周围的鱼保持距离 Following the leader : every fish will try to follow its leader 跟随一个领头者 ： 每条鱼都会跟随一个领头者 Avoiding enemies. 躲避敌人]]></content>
      <categories>
        <category>UE4</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>UE4</tag>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[XXTEA的python实现]]></title>
    <url>%2F2016%2F09%2F13%2FXXTEA%E7%9A%84python%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[在数据的加解密领域，算法分为对称密钥与非对称密钥两种。 对称密钥与非对称密钥由于各自的特点，所应用的领域是不尽相同的。 对称密钥加密算法由于其速度快，一般用于整体数据的加密，而非对称密钥加密算法的安全性能佳，在数字签名领域得到广泛的应用。 微型加密算法（TEA）及其相关变种（XTEA，Block TEA，XXTEA） 都是分组加密算法，它们很容易被描述，实现也很简单（典型的几行代码）。 TEA是Tiny Encryption Algorithm的缩写，以加密解密速度快，实现简单著称。 TEA 算法最初是由剑桥计算机实验室的 David Wheeler 和 Roger Needham 在 1994 年设计的。 该算法使用 128 位的密钥为 64 位的信息块进行加密，它需要进行 64 轮迭代，尽管作者认为 32 轮已经足够了。 该算法使用了一个神秘常数δ作为倍数，它来源于黄金比率，以保证每一轮加密都不相同。 但δ的精确值似乎并不重要，这里 TEA 把它定义为 δ=「(√5 - 1)231」（也就是程序中的 0×9E3779B9）。 之后 TEA 算法被发现存在缺陷，作为回应，设计者提出了一个 TEA 的升级版本——XTEA（有时也被称为“tean”）。 XTEA 跟 TEA 使用了相同的简单运算，但它采用了截然不同的顺序，为了阻止密钥表攻击，四个子密钥（在加密过程中，原 128 位的密钥被拆分为 4 个 32 位的子密钥）采用了一种不太正规的方式进行混合，但速度更慢了。 在跟描述 XTEA 算法的同一份报告中，还介绍了另外一种被称为 Block TEA 算法的变种，它可以对 32 位大小任意倍数的变量块进行操作。 该算法将 XTEA 轮循函数依次应用于块中的每个字，并且将它附加于它的邻字。 该操作重复多少轮依赖于块的大小，但至少需要 6 轮。 该方法的优势在于它无需操作模式（CBC，OFB，CFB 等），密钥可直接用于信息。 对于长的信息它可能比 XTEA 更有效率。 在 1998 年，Markku-Juhani Saarinen 给出了一个可有效攻击 Block TEA 算法的代码，但之后很快 David J. Wheeler 和 Roger M. Needham 就给出了 Block TEA 算法的修订版，这个算法被称为 XXTEA。 XXTEA 使用跟 Block TEA 相似的结构，但在处理块中每个字时利用了相邻字。 它利用一个更复杂的 MX 函数代替了 XTEA 轮循函数，MX 使用 2 个输入量。 XXTEA 算法很安全，而且非常快速，非常适合应用于 Web 开发中。 TEA算法是由剑桥大学计算机实验室的David Wheeler和Roger Needham于1994年发明， TEA是Tiny Encryption Algorithm的缩写，以加密解密速度快，实现简单著称。 TEA算法每一次可以操作64bit(8byte)，采用128bit(16byte)作为key，算法采用迭代的形式，推荐的迭代轮数是64轮，最少32轮。 为解决TEA算法密钥表攻击的问题，TEA算法先后经历了几次改进，从XTEA到BLOCK TEA，直至最新的XXTEA。 XTEA也称做TEAN，它使用与TEA相同的简单运算，但四个子密钥采取不正规的方式进行混合以阻止密钥表攻击。 Block TEA算法可以对32位的任意整数倍长度的变量块进行加解密的操作，该算法将XTEA轮循函数依次应用于块中的每个字，并且将它附加于被应用字的邻字。 XXTEA使用跟Block TEA相似的结构，但在处理块中每个字时利用了相邻字，且用拥有两个输入量的MX函数代替了XTEA轮循函数。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667import struct _DELTA = 0x9E3779B9 def _long2str(v, w): n = (len(v) - 1) &lt;&lt; 2 if w: m = v[-1] if (m &lt; n - 3) or (m &gt; n): return &apos;&apos; n = m s = struct.pack(&apos;&lt;%iL&apos; % len(v), *v) return s[0:n] if w else s def _str2long(s, w): n = len(s) m = (4 - (n &amp; 3) &amp; 3) + n s = s.ljust(m, &quot;\0&quot;) v = list(struct.unpack(&apos;&lt;%iL&apos; % (m &gt;&gt; 2), s)) if w: v.append(n) return v def encrypt(str, key): if str == &apos;&apos;: return str v = _str2long(str, True) k = _str2long(key.ljust(16, &quot;\0&quot;), False) n = len(v) - 1 z = v[n] y = v[0] sum = 0 q = 6 + 52 // (n + 1) while q &gt; 0: sum = (sum + _DELTA) &amp; 0xffffffff e = sum &gt;&gt; 2 &amp; 3 for p in xrange(n): y = v[p + 1] v[p] = (v[p] + ((z &gt;&gt; 5 ^ y &lt;&lt; 2) + (y &gt;&gt; 3 ^ z &lt;&lt; 4) ^ (sum ^ y) + (k[p &amp; 3 ^ e] ^ z))) &amp; 0xffffffff z = v[p] y = v[0] v[n] = (v[n] + ((z &gt;&gt; 5 ^ y &lt;&lt; 2) + (y &gt;&gt; 3 ^ z &lt;&lt; 4) ^ (sum ^ y) + (k[n &amp; 3 ^ e] ^ z))) &amp; 0xffffffff z = v[n] q -= 1 return _long2str(v, False) def decrypt(str, key): if str == &apos;&apos;: return str v = _str2long(str, False) k = _str2long(key.ljust(16, &quot;\0&quot;), False) n = len(v) - 1 z = v[n] y = v[0] q = 6 + 52 // (n + 1) sum = (q * _DELTA) &amp; 0xffffffff while (sum != 0): e = sum &gt;&gt; 2 &amp; 3 for p in xrange(n, 0, -1): z = v[p - 1] v[p] = (v[p] - ((z &gt;&gt; 5 ^ y &lt;&lt; 2) + (y &gt;&gt; 3 ^ z &lt;&lt; 4) ^ (sum ^ y) + (k[p &amp; 3 ^ e] ^ z))) &amp; 0xffffffff y = v[p] z = v[n] v[0] = (v[0] - ((z &gt;&gt; 5 ^ y &lt;&lt; 2) + (y &gt;&gt; 3 ^ z &lt;&lt; 4) ^ (sum ^ y) + (k[0 &amp; 3 ^ e] ^ z))) &amp; 0xffffffff y = v[0] sum = (sum - _DELTA) &amp; 0xffffffff return _long2str(v, True) if __name__ == &quot;__main__&quot;: print decrypt(encrypt(&apos;Hello XXTEA!&apos;, &apos;16bytelongstring&apos;), &apos;16bytelongstring&apos;)]]></content>
      <categories>
        <category>脚本</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>xxtea</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PHP的魔术]]></title>
    <url>%2F2016%2F09%2F01%2FPHP%E7%9A%84%E9%AD%94%E6%9C%AF%2F</url>
    <content type="text"><![CDATA[PHP 将所有以 （两个下划线）开头的类方法保留为魔术方法。所以在定义类方法时，除了上述魔术方法，建议不要以 为前缀。 PHP魔幻（术）方法 __construct() 实例化类时自动调用。 __destruct() 类对象使用结束时自动调用。 __set() 在给未定义的属性赋值的时候调用。 __get() 调用未定义的属性时候调用。 __isset() 使用isset()或empty()函数时候会调用。 __unset() 使用unset()时候会调用。 __sleep() 使用serialize序列化时候调用。 __wakeup() 使用unserialize反序列化的时候调用。 __call() 调用一个不存在的方法的时候调用。 __callStatic()调用一个不存在的静态方法是调用。 __toString() 把对象转换成字符串的时候会调用。比如 echo。 __invoke() 当尝试把对象当方法调用时调用。 __set_state() 当使用var_export()函数时候调用。接受一个数组参数。 __clone() 当使用clone复制一个对象时候调用。]]></content>
      <categories>
        <category>脚本</category>
      </categories>
      <tags>
        <tag>php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从零开始搭建一台简易linux服务器(三)]]></title>
    <url>%2F2016%2F08%2F27%2F%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%90%AD%E5%BB%BA%E4%B8%80%E5%8F%B0%E7%AE%80%E6%98%93linux%E6%9C%8D%E5%8A%A1%E5%99%A8(%E4%B8%89)%2F</url>
    <content type="text"><![CDATA[安装MySQL执行命令安装MySQL：sudo apt-get install mysql-server安装的时候会提示填入一个root的初始密码，先输入个8做初始密码吧 #导入客户数据库base_accountmysql -uroot -p &lt; *.sql(某个sql文件) 安装svn并checkout一个svn服务器上的目录 进入 /data/www目录下 ：cd /data/www 执行命令安装：sudo apt-get install subversion checkout一个目录（比如svn://112.124.26.188/myapp/td/01CServer_PHP/errorMsg），执行命令：svn checkout svn://112.124.26.188/myapp/td/01CServer_PHP/errorMsg （或者 svn co svn://112.124.26.188/myapp/td/01CServer_PHP/errorMsg） 测试是否可以访问并将相应数据传入数据库中访问 localhost/errorMsg/ErrorMsg.php?data=3_2&amp;error_msg=zhangnimashuai然后查看数据库相应表里是否增加了数据 ##证书登陆 (可选)#对dev 将id_rsa私钥和id_rsa.pub公钥以及authorized_keys授权文件拷贝至~dev/.ssh/目录chmod 600 id_rsa; chmod 644 id_rsa.pub; chmod 644 authorized_keys #SSH 证书登陆配置sudo vi /etc/ssh/sshd_config取消注释 : #AuthorizedKeysFile .ssh/authorized_keys修改yes-&gt;no : PasswordAuthentication nosudo service ssh restart #重启服务 测试登陆sudo service nginx restartsudo service php5-fpm restart #测试成功后去除dev用户的sudo权限 （可选）sudo visudo 删除：dev ALL=(ALL:ALL) ALL]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>vbox</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从零开始搭建一台简易linux服务器(二)]]></title>
    <url>%2F2016%2F08%2F25%2F%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%90%AD%E5%BB%BA%E4%B8%80%E5%8F%B0%E7%AE%80%E6%98%93linux%E6%9C%8D%E5%8A%A1%E5%99%A8(%E4%BA%8C)%2F</url>
    <content type="text"><![CDATA[安装nginx(如若有有不明白，还可以前往参考 wiki.ubuntu.org.cn/Nginx )执行命令安装nginx：sudo apt-get install nginx测试是否安装成功：在本机的浏览器里访问 localhost ;如果现实”Welcome to nginx!”，表明你的 Nginx 服务器安装成功！启动 Nginx：sudo /etc/init.d/nginx start关闭 Nginx：sudo /etc/init.d/nginx stop重启 nginx：sudo /etc/init.d/nginx restart 或者 sudo service nginx restartsudo service apache2 stop (如果之前装了apache2则需要sudo apt-get remove apache2 卸载掉apache2然后执行这个stop命令) 修改nginx的server配置文件 执行命令：sudo vi /etc/nginx/sites-available/default 然后将default文件里的内容全部删除，把下面的内容粘贴进去：server {listen 80 default_server; root /data/www; #这里表示nginx根目录index index.php index.html index.htm; server_name localhost;chunked_transfer_encoding off; location / {try_files $uri $uri/ =404;} error_page 404 /index.html; location ~ .php$ { #加上这个代码块就可以用php访问了，这个代码块还有fastcgi的相关内容try_files $uri =404;fastcgi_split_path_info ^(.+.php)(/.+)$;fastcgi_pass 127.0.0.1:9000;fastcgi_index index.php;include fastcgi_params;}} 安装以及启动fastcgi 执行命令安装：sudo apt-get install spawn-fcgi 启动fastcgi ：spawn-fcgi -a 127.0.0.1 -p 9000 -C 10 -u www-data -f /usr/bin/php-cgi 为了让php-cgi开机自启动： Ubuntu开机之后会执行/etc/rc.local文件中的脚本 所以我们可以直接在/etc/rc.local中添加启动脚本。 将 spawn-fcgi -a 127.0.0.1 -p 9000 -C 10 -u www-data -f /usr/bin/php-cgi 添加到语句：exit 0 前面才行 安装PHP执行命令安装PHP：sudo apt-get install php5-cli php5-cgi php5-fpm php5-mcrypt php5-mysql php设置sudo vi /etc/php5/fpm/php.ini #设置cgi.fix_pathinfo=0sudo service php5-fpm restart sudo vi /etc/php5/fpm/pool.d/www.conflisten.owner = www-datalisten.group = www-datalisten.mode = 0660 （去掉原www.conf里“listen.mode = 0660”前的分号，那个分号是注释的意思）sudo service php5-fpm restart 测试是否可以访问 在nginx根目录也就是 上面server配置文件里的 /data/www(若没有这个目录就建一个，并改变权限，执行sudo chown dev:dev data/)文件夹里新建index.html（不建此文件将不能在本机访问localhost） 将下面的内容粘贴到index.html文件里 Welcome to nginx!Welcome to nginx! 第1步完成后将可以在浏览器访问 http://localhost 再在 /data/www文件夹里新建test.php将下面的内容粘贴到test.php文件里&lt;?php phpinfo(); ?&gt; 第3步完成后将可以在浏览器访问 http://localhost/test.php（注：如果没有启动fastcgi，访问之后将会下载此php文件。若启动了fastcgi，则访问phpinfo的网页;如果出现No input file specified就在上面的server配置文件里的下述地方加入这条语句：fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;如下：location ~ .php$ {try_files $uri =404;fastcgi_split_path_info ^(.+.php)(/.+)$;fastcgi_pass 127.0.0.1:9000;fastcgi_index index.php;fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;include fastcgi_params;} ）]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>vbox</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从零开始搭建一台简易linux服务器(一)]]></title>
    <url>%2F2016%2F08%2F23%2F%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%90%AD%E5%BB%BA%E4%B8%80%E5%8F%B0%E7%AE%80%E6%98%93linux%E6%9C%8D%E5%8A%A1%E5%99%A8(%E4%B8%80)%2F</url>
    <content type="text"><![CDATA[#virtualBox网络设置在virtualBox的你的那个虚拟机里的网络设置里添加两张网卡：1.“网络地址转换（NAT）”， 不是那个“NAT网络”噢， 这张网卡是用来访问宿主机和外网的， 但是仅仅有这张网卡宿主机是不能访问你的这个虚拟机的， 所以还需要下面这第2张2.“仅主机（Host-Olny）网络”， 这张网卡是用来让宿主机是访问你的这个虚拟机的， 这样就能用ssh工具从宿主机连到你的这个虚拟机了 #创建dev用户sudo adduser dev #增加dev权限sudo visudo 添加：dev ALL=(ALL:ALL) ALL 关于Ubuntu的root密码Ubuntu的默认root密码是随机的，即每次开机都有一个新的root密码。我们可以在终端输入命令 sudo passwd，然后输入当前用户的密码，enter，终端会提示我们输入新的密码并确认，此时的密码就是root新密码。修改成功后，输入命令 su root，再输入新的密码就ok了。 安装ssh服务端先更换源， 然后执行sudo apt-get update执行命令：sudo apt-get install openssh-server测试是否安装成功：ssh localhost]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>vbox</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[boost之program_options]]></title>
    <url>%2F2016%2F08%2F15%2Fboost%E4%B9%8Bprogram_options%2F</url>
    <content type="text"><![CDATA[介绍命令行接口是普遍,基础的人机交互接口，从命令行提取程序的运行时选项的方法有很多。 你可以自己编写相对应的完整的解析函数，或许你有丰富的C语言编程经验，熟知getopt()函数的用法，又或许使用Python的你已经在使用optparse库来简化这一工作。 大家在平时不断地谈及到“不要重复造轮子”，那就需要掌握一些顺手的库，这里介绍一种C++方式来解析命令行选项的方法，就是使用Boost.Program_options库。 program_options提供程序员一种方便的命令行和配置文件进行程序选项设置的方法。 使用program_options库而不是你自己动手写相关的解析代码，因为它更简单，声明程序选项的语法简洁，并且库自身也非常小。 将选项值转换为适合的类型值的工作也都能自动完成。 库有着完备的错误检查机制，如果自己手写解析代码时，就可能会错过对一些出错情况的检查了。 最后，选项值不仅能从命令行获取，也能从配置文件，甚至于环境变量中提取，而这些选择不会增加明显的工作量。 示例说明以下面简单的hello程序进行说明，默认打印hello world,如果传入-p选项，就会打印出人的姓名，另外通过传入-h选项，可以打印出帮助选项。 略微看一眼代码文件和相应的屏幕输入输出，然后我们再一起来看看这些是如何发生的。 123456789101112131415161718192021222324252627//hello.cpp #include &lt;iostream&gt;#include &lt;string&gt;#include &lt;boost/program_options.hpp&gt;using namespace std;int main(int argc, char* argv[])&#123; using namespace boost::program_options; //声明需要的选项 options_description desc(&quot;Allowed options&quot;); desc.add_options() (&quot;help,h&quot;, &quot;produce help message&quot;) (&quot;person,p&quot;, value&lt;string&gt;()-&gt;default_value(&quot;world&quot;), &quot;who&quot;) ; variables_map vm; store(parse_command_line(argc, argv, desc), vm); notify(vm); if (vm.count(&quot;help&quot;)) &#123; cout &lt;&lt; desc; return 0; &#125; cout &lt;&lt; &quot;Hello &quot; &lt;&lt; vm[&quot;person&quot;].as&lt;string&gt;() &lt;&lt; endl; return 0;&#125; 下面是在Windows命令提示符窗口上的输入输出结果，其中”&gt;”表示提示符。 1234567891011&gt;hello Hello world&gt;hello -hAllowed options: -h [ --help ] produce help message -p [ --person ] arg (=world) who&gt;hello --person lenHello len 首先通过options_description类声明了需要的选项，add_options返回了定义了operator()的特殊的代理对象。 这个调用看起来有点奇怪，其参数依次为选项名，选项值，以及选项的描述。 注意到示例中的选项名为”help,h”，是因为声明了具有短选项名和长选项名的选项，这跟gnu程序的命令行具有一致性。 当然你可以省略短选项名，但是这样就不能用命令选项简写了。 第二个选项的声明，定义了选项值为string类型，其默认值为world. 接下来,声明了variables_map类的对象，它主要用来存储选项值，并且能储存任意类型的值。 然后，store,parse_command_line和notify函数使vm能存储在命令行中发现的选项。 最后我们就自由地使用这些选项了，variables_map类的使用就像使用std::map一样，除了它必须用as方法去获取值。 如果as方法调用的指定类型与实际存储的类型不同，就会有异常抛出。 具有编程的你可能有这样的经验，使用cl或gcc对源文件进行编译时，可直接将源文件名放置在命令行中，而无需什么选项字母，如gcc a.c之类的。 prgram_options也能处理这种情况，在库中被称为”positional options”(位置选项),但这需要程序员的一点儿帮助才能完成。 看下面的经过对应修改的代码，我们无需传入”-p”选项，就能可指定”person”选项值 123positional_options_description p;p.add(&quot;person&quot;, -1);store(command_line_parser(argc, argv).options(desc).positional(p).run(), vm); 12&gt;hello lenHello len 前面新增的两行是为了说明所有的位置选项都应被解释成”person”选项，这里还采用了command_line_parser类来解析命令行，而不是用parse_command_line函数。 后者只是对前者类的简单封装，但是现在我们需要传入一些额外的信息，所以要使用类本身。 选项复合来源一般来说，在命令行上指定所有选项，对用户来说是非常烦人的。 如果有些选项要应用于每次运行，那该怎么办呢。 我们当然希望能创建出带有些常用设置的选项文件，跟命令行一起应用于程序中。 当然这一切需要将命令行与配置文件中的值结合起来。 比如，在命令行中指定的某些选项值应该能覆盖配置文件中的对应值，或者将这些值组合起来。 下面的代码段将选项通过文件读取，这文件是文本格式，可用”#”表示注释，格式如命令行中的参数一样，选项=值 123ifstream ifs(&quot;config.cfg&quot;);store(parse_config_file(ifs,config),vm);notify(vm); 参考Boost.prgram_options库文档]]></content>
      <categories>
        <category>c++</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>boost</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于UNP与APUE与TLPI三本大部头的阅读建议(着重讲UNP)]]></title>
    <url>%2F2016%2F08%2F11%2F%E5%85%B3%E4%BA%8EUNP%E4%B8%8EAPUE%E4%B8%8ETLPI%E4%B8%89%E6%9C%AC%E5%A4%A7%E9%83%A8%E5%A4%B4%E7%9A%84%E9%98%85%E8%AF%BB%E5%BB%BA%E8%AE%AE(%E7%9D%80%E9%87%8D%E8%AE%B2UNP)%2F</url>
    <content type="text"><![CDATA[这本书不能一次性所有都想看完。 要有目的性的看，因为这本书类似于百科全书所有都讲， 不分轻重， 如果都看，硬啃，只会迷失了自己，反而不知道看了什么 这本书不能单独看。 这本书必须配合TCP/IP详解和UNIX环境高级编程（简称APUE）以及The Linux Programming Interface（不知道这本书的译名是什么， 简称TLPI）来看 个人看的是卷一第三版，因当前工作经验范围和阅历受限，对于IT码农，IPv6的和SCTP的章节暂且略过，所以目前大概划出的必看章节（其他可挑选）是 1 2 3 4 5 6 7 8 11 13 16 22 26 30 书中的源码在linux环境下不一定能一次性编译过。 有些地方得自己修改 建议阅读电子版。 使用可以搜索书签的pdf阅读器（比较推荐福昕）， 并且多开几个此书的副本，因为经常会源码和源码讲解对照着看，如果有双屏效率会极大的提高]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>UNP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Reactor模式和Proactor]]></title>
    <url>%2F2016%2F08%2F07%2FReactor%E5%92%8CProactor%2F</url>
    <content type="text"><![CDATA[在高性能的I/O设计中，有两个比较著名的模式Reactor和Proactor模式，其中Reactor模式用于同步I/O，而Proactor运用于异步I/O操作。 在比较这两个模式之前，我们首先的搞明白几个概念，什么是阻塞和非阻塞，什么是同步和异步, 同步和异步是针对应用程序和内核的交互而言的， 同步指的是用户进程触发IO操作并等待或者轮询的去查看IO操作是否就绪， 异步是指用户进程触发IO操作以后便开始做自己的事情，而当IO操作已经完成的时候会得到IO完成的通知。 而阻塞和非阻塞是针对于进程在访问数据的时候，根据IO操作的就绪状态来采取的不同方式， 说白了是一种读取或者写入操作函数的实现方式， 阻塞方式下读取或者写入函数将一直等待， 非阻塞方式下，读取或者写入函数会立即返回一个状态值。 同步 vs 异步一般来说I/O模型可以分为： 同步阻塞， 同步非阻塞， 异步阻塞， 异步非阻塞IO 同步阻塞IO：在此种方式下，用户进程在发起一个IO操作以后，必须等待IO操作的完成，只有当真正完成了IO操作以后，用户进程才能运行。 JAVA传统的IO模型属于此种方式！ 同步非阻塞IO:在此种方式下，用户进程发起一个IO操作以后边可返回做其它事情，但是用户进程需要时不时的询问IO操作是否就绪， 这就要求用户进程不停的去询问，从而引入不必要的CPU资源浪费。 其中目前JAVA的NIO就属于同步非阻塞IO。 异步阻塞IO：此种方式下是指应用发起一个IO操作以后，不等待内核IO操作的完成，等内核完成IO操作以后会通知应用程序，这其实就是同步和异步最关键的区别，同步必须等待或者主动的去询问IO是否完成，那么为什么说是阻塞的呢？因为此时是通过select系统调用来完成的，而select函数本身的实现方式是阻塞的，而采用select函数有个好处就是它可以同时监听多个文件句柄，从而提高系统的并发性！ 异步非阻塞IO:在此种模式下，用户进程只需要发起一个IO操作然后立即返回，等IO操作真正的完成以后，应用程序会得到IO操作完成的通知，此时用户进程只需要对数据进行处理就好了，不需要进行实际的IO读写操作，因为真正的IO读取或者写入操作已经由内核完成了。 目前Java中还没有支持此种IO模型。 Reactor vs Proactor搞清楚了以上概念以后，我们再回过头来看看，Reactor模式和Proactor模式。 Reactor首先来看看Reactor模式，Reactor模式应用于同步I/O的场景。 我们分别以读操作和写操作为例来看看Reactor中的具体步骤： 读取操作： 应用程序注册读就需事件和相关联的事件处理器 事件分离器等待事件的发生 当发生读就需事件的时候，事件分离器调用第一步注册的事件处理器 事件处理器首先执行实际的读取操作，然后根据读取到的内容进行进一步的处理 写入操作:类似于读取操作，只不过第一步注册的是写就绪事件。 Proactor下面我们来看看Proactor模式中读取操作和写入操作的过程： 读取操作： 应用程序初始化一个异步读取操作，然后注册相应的事件处理器，此时事件处理器不关注读取就绪事件，而是关注读取完成事件，这是区别于Reactor的关键。 事件分离器等待读取操作完成事件 在事件分离器等待读取操作完成的时候，操作系统调用内核线程完成读取操作，并将读取的内容放入用户传递过来的缓存区中。 这也是区别于Reactor的一点，Proactor中，应用程序需要传递缓存区。 事件分离器捕获到读取完成事件后，激活应用程序注册的事件处理器，事件处理器直接从缓存区读取数据，而不需要进行实际的读取操作。 写入操作:Proactor中写入操作和读取操作类似，只不过感兴趣的事件是写入完成事件。 小结从上面可以看出，Reactor和Proactor模式的主要区别就是真正的读取和写入操作是有谁来完成的， Reactor中需要应用程序自己读取或者写入数据，而Proactor模式中，应用程序不需要进行实际的读写过程， 它只需要从缓存区读取或者写入即可，操作系统会读取缓存区或者写入缓存区到真正的IO设备. 总结综上所述，同步和异步是相对于应用和内核的交互方式而言的，同步 需要主动去询问， 而异步的时候内核在IO事件发生的时候通知应用程序， 而阻塞和非阻塞仅仅是系统在调用系统调用的时候函数的实现方式而已。]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>proactor</tag>
        <tag>reactor</tag>
        <tag>同步</tag>
        <tag>异步</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重新看unix网络编程的一些心得]]></title>
    <url>%2F2016%2F08%2F02%2F%E9%87%8D%E6%96%B0%E7%9C%8Bunix%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%9A%84%E4%B8%80%E4%BA%9B%E5%BF%83%E5%BE%97%2F</url>
    <content type="text"><![CDATA[老书新看, 有了许多不同的见解, 也准备拿出以前自己私人的老笔记做修正放到博客里, 加深理解. 在这个浮躁人人都能写书的时代基本要看一本书需要挑很久, 谁写的, 写得怎么样, 是否是业界经典, 都要需要一一斟酌各种查证方可, 不然看一本烂书事半功倍, 浪费生命,影响效率, 被误导跑偏, 能让人静下心来的书籍不多, 能让人看好几遍仍回味无穷的经典就更少了 陈硕说过, 学东西不要只是从网上看点大牛的博客总结就行了, 总要完整地看些相关领域的经典著作的, 系统的知识结构打下坚实的基础才能继续看有关优化效率方面的书籍, 深以为然 孟岩说, 最近不止一次听到当一个人拥有相关领域的知识基础之后就可以找一本effective*的书来研读了, 颇有道理 看书的顺序忌胶柱鼓瑟, 并不是他的目录结构怎么编排你就该怎么看的, 大多数经典书籍基本都是面面俱到, 如果直接跟着这种面向知识体系本身的编排思路去看, 容易迷失乏味而无法继续, 应该找到属于自己看书顺序 个人总结的看书顺序是先翻阅自己感兴趣的,接着仔细观察他的目录来确定他的编排思路, 然后花一到两天的时间通览全书以获得大体知识体系构架, 之后找到实战性最强的章节来实操并逐个突破实战过程中的各个知识点]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>UNP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈当前流行的pomelo和skynet和kbengine]]></title>
    <url>%2F2016%2F08%2F01%2F%E6%B5%85%E8%B0%88%E5%BD%93%E5%89%8D%E6%B5%81%E8%A1%8C%E7%9A%84pomelo%E5%92%8Cskynet%E5%92%8Ckbengine%2F</url>
    <content type="text"><![CDATA[根据之前的博文&lt;&lt;服务端常用架构&gt;&gt;来看 网易pomelo属于第二代游戏服务端五型的架构，即图7的架构。 skynet因为是一个服务端框架，官方只是提供了login server 和 gate server的参考实现，其他的需要自己来实现，编程的自由度变大了，架构完全取决于程序员自己的选择，程序员可以自己尝试去实现第二代的架构，也可以实现第三代的架构。注意: skynet仅仅是框架，其他属于完整解决方案。 Kbengine属于第三代服务端框架，可能类似于图10。（这个理解不确定）Kbengine引擎应该是对图10中的Gate服务器和NODE和OBJ进行了细分。在功能上大体划分为与位置有关（在Kbengine中称为Cellapp）和与位置无关（在Kbengine中称为Baseapp）。类似于下面的示图架构。]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>skynet</tag>
        <tag>pomelo</tag>
        <tag>kbengine</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[快速完成一个slg游戏思路(二)]]></title>
    <url>%2F2016%2F07%2F30%2F%E5%BF%AB%E9%80%9F%E5%AE%8C%E6%88%90%E4%B8%80%E4%B8%AAslg%E6%B8%B8%E6%88%8F%E6%80%9D%E8%B7%AF(%E4%BA%8C)%2F</url>
    <content type="text"><![CDATA[ChatServer 从登录成功就开始连接, 注册一个Chat_ID, player_ID 和 Chat_ID相互对应, 会注册相应的房间频道, 并为每位Player存了一份黑名单, 在客户端做了本地黑名单, 聊天服务器也做了黑名单二次验证处理. 世界频道 : 则用MsgServer的非实时推送思路 私密聊天 : 则选择 workerman 的tcp, MsgServer 实时推送 : workerman 的tcp 非实时推送 : 客户端定时15秒轮询一下服务器，如果有消息就取下来，如果没消息可以逐步放长轮询时间，比如30秒；如果有消息，就缩短轮询时间到10秒，5秒， deployToolCapistrano是一个开源的部署工具, 用ruby来写, 语法超简洁的 优点 实时则走 workerman 非实时则跑 yii 访问一下，请求一下关卡数据，玩完了又提交一下， 验算一下是否合法，获得什么奖励， 数据库用单台 MySQL或者 MongoDB即可，后端的 Redis做缓存 此类服务器用来实现一款三国类策略或者卡牌及酷跑的游戏已经绰绰有余， 这类游戏因为逻辑简单，玩家之间交互不强， 使用HTTP来开发的话，开发速度快，调试只需要一个浏览器就可以把逻辑调试清楚了]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>mysql</tag>
        <tag>php</tag>
        <tag>yii</tag>
        <tag>nginx</tag>
        <tag>tcp</tag>
        <tag>http</tag>
        <tag>udp</tag>
        <tag>workerman</tag>
        <tag>Capistrano</tag>
        <tag>ruby</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[快速完成一个slg游戏思路(一)]]></title>
    <url>%2F2016%2F07%2F30%2F%E5%BF%AB%E9%80%9F%E5%AE%8C%E6%88%90%E4%B8%80%E4%B8%AAslg%E6%B8%B8%E6%88%8F%E6%80%9D%E8%B7%AF(%E4%B8%80)%2F</url>
    <content type="text"><![CDATA[LoginServer(GateWay)当完成渠道sdk回调验证之后, 验证完玩家信息, 用了nginx的负载均衡给每位玩家分配一台不繁忙的游戏服务器, 在redis中存了一份玩家在线有效时间key,超时则掉线, 这个key也可以用来完成封号操作 MainServer 因为弱交互/短连接的关系, 大多数情况玩家和玩家之间不需要实时面对面PK， 打一下对方的离线数据， 计算下排行榜，排行榜是实时计算的, 存在redis里, 做了分页处理 买卖下道具即可 所以 MainServer 选择了: yii redis mysql nginx pvpServeer而 pvpServer 则选择 workerman 的tcp模式, 实时交互数据, MainServer 和 pvpServer之间通信并接同一个数据库. 其实这里可以不选择用tcp, 而自撸一个可靠udp来提高效率]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>mysql</tag>
        <tag>php</tag>
        <tag>yii</tag>
        <tag>nginx</tag>
        <tag>tcp</tag>
        <tag>http</tag>
        <tag>udp</tag>
        <tag>workerman</tag>
        <tag>Capistrano</tag>
        <tag>ruby</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务端常用架构(三)]]></title>
    <url>%2F2016%2F07%2F11%2F%E6%9C%8D%E5%8A%A1%E7%AB%AF%E5%B8%B8%E7%94%A8%E6%9E%B6%E6%9E%84(%E4%B8%89)%2F</url>
    <content type="text"><![CDATA[休闲游戏服务器休闲游戏同战网服务器类似，都是全区架构，不同的是有房间服务器，还有具体的游戏服务器，游戏主体不再以玩家 P2P进行，而是连接到专门的游戏服务器处理： 和战网一样的全区架构，用户数据不能象分区的 RPG那样一次性load到内存，然后在内存里面直接修改。全区架构下，为了应对一个用户同时玩几个游戏，用户数据需要区分基本数据和不同的游戏数据，而游戏数据又需要区分积分数据、和文档数据。胜平负之类的积分可以直接提交增量修改，而更为普遍的文档类数据则需要提供读写令牌，写令牌只有一块，读令牌有很多块。同帐号同一个游戏同时在两台电脑上玩时，最先开始的那个游戏获得写令牌，可以操作任意的用户数据。而后开始的那个游戏除了可以提交胜平负积分的增量改变外，对用户数据采用只读的方式，保证游戏能运行下去，但是会提示用户，游戏数据锁定。 现代动作类网游从早期的韩国动作游戏开始，传统的战网动作类游戏和 RPG游戏开始尝试融合。单纯的动作游戏玩家容易疲倦，留存也没有 RPG那么高；而单纯 RPG战斗却又慢节奏的乏味，无法满足很多玩家激烈对抗的期望，于是二者开始融合成为新一代的：动作 + 城镇模式。玩家在城镇中聚集，然后以开副本的方式几个人出去以动作游戏的玩法来完成各种 RPG任务。本质就是一套 RPG服务端+副本服务端。由于每次副本时人物可以控制在8人以内，因此可以获得更为实时的游戏体验，让玩家玩的更加爽快。 说了那么多的游戏服务器类型，其实也差不多了，剩下的类型大家拼凑一下其实也就是这个样子而已。游戏服务端经历了那么多结构上的变迁，内部开发模式是否依然不变？究竟是继续延续传统的开发方式？还是有了更多突破性的方法？经历那么多次架构变迁，后面是否有共通的逻辑？未来的发展还会存在哪些困难？游戏服务端开发如何达到最终的彼岸？请看下节：技术的演进。]]></content>
      <categories>
        <category>server</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[服务端常用架构(二)]]></title>
    <url>%2F2016%2F07%2F11%2F%E6%9C%8D%E5%8A%A1%E7%AB%AF%E5%B8%B8%E7%94%A8%E6%9E%B6%E6%9E%84(%E4%BA%8C)%2F</url>
    <content type="text"><![CDATA[第三代游戏服务器 2007从魔兽世界开始无缝世界地图已经深入人心，比较以往游戏玩家走个几步还需要切换场景，每次切换就要等待 LOADING个几十秒是一件十分破坏游戏体验的事情。于是对于 2005年以后的大型 MMORPG来说，无缝地图已成为一个标准配置。比较以往按照地图来切割游戏而言，无缝世界并不存在一块地图上面的人有且只由一台服务器处理了： 每台 Node服务器用来管理一块地图区域，由 NodeMaster（NM）来为他们提供总体管理。更高层次的 World则提供大陆级别的管理服务。这里省略若干细节服务器，比如传统数据库前端，登录服务器，日志和监控等，统统用 ADMIN概括。在这样的结构下，玩家从一块区域走向另外一块区域需要简单处理一下： 玩家1完全由节点A控制，玩家3完全由节点B控制。而处在两个节点边缘的2号玩家，则同时由A和B提供服务。玩家2从A移动到B的过程中，会同时向A请求左边的情况，并向B请求右边的情况。但是此时玩家2还是属于A管理。直到玩家2彻底离开AB边界很远，才彻底交由B管理。按照这样的逻辑将世界地图分割为一块一块的区域，交由不同的 Node去管理。 对于一个 Node所负责的区域，地理上没必要连接在一起，比如大陆的四周边缘部分和高山部分的区块人比较少，可以统一交给一个Node去管理，而这些区块在地理上并没有联系在一起的必要性。一个 Node到底管理哪些区块，可以根据游戏实时运行的负载情况，定时维护的时候进行更改 NodeMaster 上面的配置。 于是碰到第一个问题是很多 Node服务器需要和玩家进行通信，需要问管理服务器特定UID为多少的玩家到底在哪台 Gate上，以前按场景切割的服务器这个问题不大，问了一次以后就可以缓存起来了，但是现在服务器种类增加不少，玩家又会飘来飘去，按UID查找玩家比较麻烦；另外一方面 GATE需要动态根据坐标计算和哪些 Node通信，导致逻辑越来越厚，于是把：“用户对象”从负责连接管理的 GATE中切割出来势在必行于是有了下面的模型： 网关服务器再次退回到精简的网络转发功能，而用户逻辑则由按照 UID划分的 OBJ服务器来承担，GATE是按照网络接入时的负载来分布，而 OBJ则是按照资源的编号（UID）来分布，这样和一个用户通信直接根据 UID计算出 OBJ服务器编号发送数据即可。而新独立出来的 OBJ则提供了更多高层次的服务： • 对象移动：管理具体玩家在不同的 Node所管辖的区域之间的移动，并同需要的 Node进行沟通。• 数据广播：Node可以给每个用户设置若干 TAG，然后通知 Object Master 按照TAG广播。• 对象消息：通用消息推送，给某个用户发送数据，直接告诉 OBJ，不需要直接和 GATE打交道。• 好友聊天：角色之间聊天直接走 OBJ/OBJ MASTER。整个服务器主体分为三层以后，NODE专注场景，OBJ专注玩家对象，GATE专注网络。这样的模型在无缝场景服务器中得到广泛的应用。但是随着时间的推移，负载问题也越来越明显，做个活动，远来不活跃的区域变得十分活跃，靠每周维护来调整还是比较笨重的，于是有了动态负载均衡。 动态负载均衡有两种方法，第一种是按照负载，由 Node Master 定时动态移动修改一下各个 Node的边界，而不同的玩家对象按照先前的方法从一台 Node上迁移到另外一台 Node上： 图11 动态负载均衡 这样 Node Master定时查找地图上的热点区域，计算新的场景切割方式，然后告诉其他服务器开始调整，具体处理方式还是和上面对象跨越边界移动的方法一样。 但是上面这种方式实现相对复杂一些，于是人们设计出了更为简单直接的一种新方法： 图12 基于网格的动态负载均衡 还是将地图按照标准尺寸均匀切割成静态的网格，每个格子由一个具体的Node负责，但是根据负载情况，能够实时的迁移到其他 Node上。在迁移分为三个阶段：准备，切换，完成。三个状态由Node Master负责维护。准备阶段新的 Node开始同步老 Node上面该网格的数据，完成后告诉NM；NM确认OK后同时通知新旧 Node完成切换。完成切换后，如果 Obj服务器还在和老的 Node进行通信，老的 Node将会对它进行纠正，得到纠正的 OBJ将修正自己的状态，和新的 Node进行通信。 很多无缝动态负载均衡的服务端宣称自己支持无限的人数，但不意味着 MMORPG游戏的人数上限真的可以无限扩充，因为这样的体系会受制于网络带宽和客户端性能。带宽决定了同一个区域最大广播上限，而客户端性能决定了同一个屏幕到底可以绘制多少个角色。 从无缝地图引入了分布式对象模型开始，已经完全脱离 MUDOS体系，成为一种新的服务端模型。又由于动态负载均衡的引入，让无缝服务器如虎添翼，容纳着超过上一代游戏服务器数倍的人数上限，并提供了更好的游戏体验，我们称其为第三代游戏服务端架构。网游以大型多人角色扮演为开端，RPG网游在相当长的时间里一度占据90%以上，使得基于 MMORPG的服务端架构得到了蓬勃的发展，然而随着玩家对RPG的疲惫，各种非MMORPG游戏如雨后春笋般的出现在人们眼前，受到市场的欢迎。 战网游戏服务器经典战网服务端和 RPG游戏有两个区别：RPG是分区分服的，北京区的用户和广州区的用户老死不相往来。而战网，虽然每局游戏一般都是 8人以内，但全国只有一套服务器，所有的玩家都可以在一起游戏，而玩家和玩家之使用 P2P的方式连接在一起，组成一局游戏： 玩家通过 Match Making 服务器使用：创建、加入、自动匹配、邀请等方式组成一局游戏。服务器会选择一个人做 Host，其他人 P2P连接到做主的玩家上来。STUN是帮助玩家之间建立 P2P的牵引服务器，而由于 P2P联通情况大概只有 75%，实在联不通的玩家会通过 Forward进行转发。 大量的连接对战，体育竞技游戏采用类似的结构。P2P有网状模型（所有玩家互相连接），和星状模型（所有玩家连接一个主玩家）。复杂的游戏状态在网状模型下难以形成一致，因此星状P2P模型经受住了历史的考验。除去游戏数据，支持语音的战网系统也会将所有人的语音数据发送到做主的那个玩家机器上，通过混音去重再编码的方式返回给所有用户。 战网类游戏，以竞技、体育、动作等类型的游戏为主，较慢节奏的 RPG（包括ARPG）有本质上的区别，而激烈的游戏过程必然带来到较 RPG复杂的多的同步策略，这样的同步机制往往带来的是很多游戏结果由客户端直接计算得出，那在到处都是破解的今天，如何保证游戏结果的公正呢？ 主要方法就是投票法，所有客户端都会独立计算，然后传递给服务器。如果结果相同就更新记录，如果结果不一致，会采取类似投票的方式确定最终结果。同时记录本剧游戏的所有输入，在可能的情况下，找另外闲散的游戏客户端验算整局游戏是否为该结果。并且记录经常有作弊嫌疑的用户，供运营人员封号时参考。]]></content>
      <categories>
        <category>server</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[服务端常用架构(一)]]></title>
    <url>%2F2016%2F07%2F11%2F%E6%9C%8D%E5%8A%A1%E7%AB%AF%E5%B8%B8%E7%94%A8%E6%9E%B6%E6%9E%84(%E4%B8%80)%2F</url>
    <content type="text"><![CDATA[卡牌、跑酷等弱交互服务端卡牌跑酷类因为交互弱，玩家和玩家之间不需要实时面对面PK，打一下对方的离线数据，计算下排行榜，买卖下道具即可，所以实现往往使用简单的 HTTP服务器： 登录时可以使用非对称加密（RSA, DH），服务器根据客户端uid，当前时间戳还有服务端私钥，计算哈希得到的加密 key 并发送给客户端。之后双方都用 HTTP通信，并用那个key进行RC4加密。客户端收到key和时间戳后保存在内存，用于之后通信，服务端不需要保存 key，因为每次都可以根据客户端传上来的 uid 和时间戳以及服务端自己的私钥计算得到。用模仿 TLS的行为，来保证多次 HTTP请求间的客户端身份，并通过时间戳保证同一人两次登录密钥不同。 每局开始时，访问一下，请求一下关卡数据，玩完了又提交一下，验算一下是否合法，获得什么奖励，数据库用单台 MySQL或者 MongoDB即可，后端的 Redis做缓存（可选）。如果要实现通知，那么让客户端定时15秒轮询一下服务器，如果有消息就取下来，如果没消息可以逐步放长轮询时间，比如30秒；如果有消息，就缩短轮询时间到10秒，5秒，即便两人聊天，延迟也能自适应。 此类服务器用来实现一款三国类策略或者卡牌及酷跑的游戏已经绰绰有余，这类游戏因为逻辑简单，玩家之间交互不强，使用 HTTP来开发的话，开发速度快，调试只需要一个浏览器就可以把逻辑调试清楚了。 第一代游戏服务器 19781978年，英国著名的财经学校University of Essex的学生 Roy Trubshaw编写了世界上第一个MUD程序《MUD1》，在University of Essex于1980年接入 ARPANET之后加入了不少外部的玩家，甚至包括国外的玩家。《MUD1》程序的源代码在 ARPANET共享之后出现了众多的改编版本，至此MUD才在全世界广泛流行起来。不断完善的 MUD1的基础上产生了开源的 MudOS（1991），成为众多网游的鼻祖： MUDOS采用 C语言开发，因为玩家和玩家之间有比较强的交互（聊天，交易，PK），MUDOS使用单线程无阻塞套接字来服务所有玩家，所有玩家的请求都发到同一个线程去处理，主线程每隔1秒钟更新一次所有对象（网络收发，更新对象状态机，处理超时，刷新地图，刷新NPC）。 游戏世界采用房间的形式组织起来，每个房间有东南西北四个方向可以移动到下一个房间，由于欧美最早的网游都是地牢迷宫形式的，因此场景的基本单位被成为 “房间”。MUDOS使用一门称为LPC的脚本语言来描述整个世界（包括房间拓扑，配置，NPC，以及各种剧情）。游戏里面的高级玩家（巫师），可以不断的通过修改脚本来为游戏添加房间以及增加剧情。早年 MUD1上线时只有17个房间，Roy Trubshaw毕业以后交给他的师弟 Richard Battle，在 Richard Battle手上，不断的添加各种玩法到一百多个房间，终于让 MUD发扬光大。 用户使用 Telnet之类的客户端用 Tcp协议连接到 MUDOS上，使用纯文字进行游戏，每条指令用回车进行分割。比如 1995年国内第一款 MUD游戏《侠客行》，你敲入：”go east”，游戏就会提示你：“后花园 - 这里是归云庄的后花园，种满了花草，几个庄丁正在浇花。此地乃是含羞草生长之地。这里唯一的出口是 north。这里有：花待阿牧（A mu），还有二位庄丁（Zhuang Ding）”，然后你继续用文字操作，查看阿牧的信息：“look a mu”，系统提示：“花待阿牧（A mu）他是陆乘风的弟子，受命在此看管含羞草。他看起来三十多岁，生得眉清目秀，端正大方，一表人才。他的武艺看上去【不是很高】，出手似乎【极轻】”。然后你可以选择击败他获得含羞草，但是你吃了含羞草却又可能会中毒死亡。在早期网上资源贫乏的时候，这样的游戏有很强的代入感。 用户数据保存在文件中，每个用户登录时，从文本文件里把用户的数据全部加载进来，操作全部在内存里面进行，无需马上刷回磁盘。用户退出了，或者每隔5分钟检查到数据改动了，都会保存会磁盘。这样的系统在当时每台服务器承载个4000人同时游戏，不是特别大的问题。从1991年的 MUDOS发布后，全球各地都在为他改进，扩充，退出新版本，随着 Windows图形机能的增强。1997游戏《UO》在 MUDOS的基础上为角色增加的x,y坐标，为每个房间增加了地图，并且为每个角色增加了动画，形成了第一代的图形网络游戏。 因为游戏内容基本可以通过 LPC脚本进行定制，所以MUDOS也成为名副其实的第一款服务端引擎，引擎一次性开发出来，然后制作不同游戏内容。后续国内的《万王之王》等游戏，很多都是跟《UO》一样，直接在 MUDOS上进行二次开发，加入房间的地图还有角色的坐标等要素，该架构一直为国内的第一代 MMORPG提供了稳固的支持，直到 2003年，还有游戏基于 MUDOS开发。 虽然后面图形化增加了很多东西，但是这些MMORPG后端的本质还是 MUDOS。随着游戏内容的越来越复杂，架构变得越来越吃不消了，各种负载问题慢慢浮上水面，于是有了我们的第二代游戏服务器。 类型3：第二代游戏服务器 2003 2000年后，网游已经脱离最初的文字MUD，进入全面图形化年代。最先承受不住的其实是很多小文件，用户上下线，频繁的读取写入用户数据，导致负载越来越大。随着在线人数的增加和游戏数据的增加，服务器变得不抗重负。同时早期 EXT磁盘分区比较脆弱，稍微停电，容易发生大面积数据丢失。因此第一步就是拆分文件存储到数据库去。 此时游戏服务端已经脱离陈旧的 MUDOS体系，各个公司在参考 MUDOS结构的情况下，开始自己用 C在重新开发自己的游戏服务端。并且脚本也抛弃了 LPC，采用扩展性更好的 Python或者 Lua来代替。由于主逻辑使用单线程模型，随着游戏内容的增加，传统单服务器的结构进一步成为瓶颈。于是有人开始拆分游戏世界，变为下面的模型： 游戏服务器压力拆分后得意缓解，但是两台游戏服务器同时访问数据库，大量重复访问，大量数据交换，使得数据库成为下一个瓶颈。于是形成了数据库前端代理（DB Proxy），游戏服务器不直接访问数据库而是访问代理，再有代理访问数据库，同时提供内存级别的cache。早年 MySQL4之前没有提供存储过程，这个前端代理一般和 MySQL跑在同一台上，它转化游戏服务器发过来的高级数据操作指令，拆分成具体的数据库操作，一定程度上代替了存储过程： 但是这样的结构并没有持续太长时间，因为玩家切换场景经常要切换连接，中间的状态容易错乱。而且游戏服务器多了以后，相互之间数据交互又会变得比较麻烦，于是人们拆分了网络功能，独立出一个网关服务 Gate（有的地方叫 Session，有的地方叫 LinkSvr之类的，名字不同而已）： 把网络功能单独提取出来，让用户统一去连接一个网关服务器，再有网关服务器转发数据到后端游戏服务器。而游戏服务器之间数据交换也统一连接到网管进行交换。这样类型的服务器基本能稳定的为玩家提供游戏服务，一台网关服务1-2万人，后面的游戏服务器每台服务5k-1w，依游戏类型和复杂度不同而已，图中隐藏了很多不重要的服务器，如登录和管理。这是目前应用最广的一个模型，到今天任然很多新项目会才用这样的结构来搭建。 人都是有惯性的，按照先前的经验，似乎把 MUDOS拆分的越开性能越好。于是大家继续想，网关可以拆分呀，基础服务如聊天交易，可以拆分呀，还可以提供web接口，数据库可以拆分呀，于是有了下面的模型： 这样的模型好用么？确实有成功游戏使用类似这样的架构，并且发挥了它的性能优势，比如一些大型 MMORPG。但是有两个挑战：每增加一级服务器，状态机复杂度可能会翻倍，导致研发和找bug的成本上升；并且对开发组挑战比较大，一旦项目时间吃紧，开发人员经验不足，很容易弄挂。 比如我见过某上海一线游戏公司的一个 RPG上来就要上这样的架构，我看了下他们团队成员的经验，问了下他们的上线日期，劝他们用前面稍微简单一点的模型。人家自信得很，认为有成功项目是这么做的，他们也要这么做，自己很想实现一套。于是他们义无反顾的开始编码，项目做了一年多，然后，就没有然后了。 现今在游戏成功率不高的情况下，一开始上一套比较复杂的架构需要考虑投资回报率，比如你的游戏上线半年内 PCU会去到多少？如果一个 APRG游戏，每组服务器5千人都到不了的话，那么选择一套更为贴近实际情况的结构更为经济。即使后面你的项目真的超过5千人朝着1万人目标奔的话，相信那个时候你的项目已经挣大钱了，你数着钱加着班去逐步迭代，一次次拆分它，相信心里也是乐开花的。 上面这些类型基本都是从拆分 MUDOS开始，将 MUDOS中的各个部件从单机一步步拆成分布式。虽然今天任然很多新项目在用上面某一种类似的结构，或者自己又做了其他热点模块的拆分。因为他们本质上都是对 MUDOS的分解，故将他们归纳为第二代游戏服务器。]]></content>
      <categories>
        <category>server</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[linux编程须知(阅读开源服务器源码基础)]]></title>
    <url>%2F2016%2F07%2F04%2Flinux%E7%BC%96%E7%A8%8B%E9%A1%BB%E7%9F%A5(%E9%98%85%E8%AF%BB%E5%BC%80%E6%BA%90%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%BA%90%E7%A0%81%E5%9F%BA%E7%A1%80)%2F</url>
    <content type="text"><![CDATA[当阅读一些开源服务器源码的时候, 如果不知道以下知识, 就会有知识盲点, 导致不知所云.这篇博客会讲述一些相关的编程知识点, 把之前的笔记总结一下.还是那句老话, 带着问题阅读是最容易让人类迅速进入状态的. 进程的内存布局是什么样的? 线程的同步机制有哪些? 互斥量 条件变量 自旋锁 读写锁 如何避免死锁 顺序加锁(例如，线程2和线程3只有在获取了锁A之后才能尝试获取锁C(译者注：获取锁A是获取锁C的必要条件)。因为线程1已经拥有了锁A，所以线程2和3需要一直等到锁A被释放。然后在它们尝试对B或C加锁之前，必须成功地对A加了锁。 加锁时限(另外一个可以避免死锁的方法是在尝试获取锁的时候加一个超时时间，这也就意味着在尝试获取锁的过程中若超过了这个时限该线程则放弃对该锁请求。) 进程间的同步机制(也就是进程间通信, 能通信就能同步了嘛)有哪些? 管道 FIFO 消息队列 信号量 共享内存 套接字 linux的任务调度机制是什么？Linux 分实时进程和普通进程，实时进程应该先于普通进程而运行。而实时进程的调度机制为： FIFO(先入先出服务调度) RR（时间片轮转调度）。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>UNP</tag>
        <tag>TLPI</tag>
        <tag>APUE</tag>
        <tag>OS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB能取代MySQL或者Redis能取代memcached么]]></title>
    <url>%2F2016%2F06%2F30%2FMongoDB%E8%83%BD%E5%8F%96%E4%BB%A3MySQL%E6%88%96%E8%80%85Redis%E8%83%BD%E5%8F%96%E4%BB%A3memcached%E4%B9%88%2F</url>
    <content type="text"><![CDATA[mongodb和memcached不是一个范畴内的东西。 mongodb是文档型的非关系型数据库，其优势在于查询功能比较强大，能存储海量数据。 mongodb和memcached不存在谁替换谁的问题。和memcached更为接近的是redis。 它们都是内存型数据库，数据保存在内存中，通过tcp直接存取，优势是速度快，并发高，缺点是数据&gt; 类型有限，查询功能不强，一般用作缓存。 一般现在的项目中，用redis来替代memcached。 Redis相比memcached： redis具有持久化机制，可以定期将内存中的数据持久化到硬盘上。 redis具备binlog功能，可以将所有操作写入日志，当redis出现故障，可依照binlog进行数据恢复。 redis支持virtual memory，可以限定内存使用大小，当数据超过阈值，则通过类似LRU的算法把内存中的最不常用数据保存到硬盘的页面文件中。 redis原生支持的数据类型更多，使用的想象空间更大。 mongodb 是文档数据库，用于方便懒人替代mysql等关系数据库的。不过mongodb在内存足够的情况下读写性能不错，大部分应用可以省去cache这一层了。 根据业务场景, 懒人可以使用MongoDB来取代MySQL+memcached,.]]></content>
      <categories>
        <category>DB</category>
      </categories>
      <tags>
        <tag>mongodb</tag>
        <tag>redis</tag>
        <tag>mysql</tag>
        <tag>memcached</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NAT穿越基础]]></title>
    <url>%2F2016%2F06%2F21%2FNAT%E7%A9%BF%E8%B6%8A%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[NAT有哪些类型及其穿透原理是什么? NAT类型 : 锥NAT 全锥NAT ：全锥NAT 把所有来自相同内部IP 地址和端口的请求映射到相同的外部IP 地址和端口。任何一个外部主机均可通过该映射发送数据包到该内部主机。 限制性锥NAT ：限制性锥NAT 把所有来自相同内部IP 地址和端口的请求映射到相同的外部IP 地址和端口。但是, 和全锥NAT 不同的是：只有当内部主机先给外部主机发送数据包, 该外部主机才能向该内部主机发送数据包。 端口限制性锥NAT ：端口限制性锥NAT 与限制性锥NAT 类似, 只是多了端口号的限制, 即只有内部主机先向外部地址：端口号对发送数据包, 该外部主机才能使用特定的端口号向内部主机发送数据包。 对称NAT ：对称NAT 与上述3 种类型都不同, 不管是全锥NAT ，限制性锥NAT 还是端口限制性锥NAT ，它们都属于锥NAT （Cone NAT ）。当同一内部主机使用相同的端口与不同地址的外部主机进行通信时, 对称NAT 会重新建立一个Session ，为这个Session 分配不同的端口号，或许还会改变IP 地址。 穿透原理 : 查看这篇博客]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>nat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL进阶(二)]]></title>
    <url>%2F2016%2F06%2F16%2FMySQL%E8%BF%9B%E9%98%B6(%E4%BA%8C)%2F</url>
    <content type="text"><![CDATA[事务 MySQL 事务主要用于处理操作量大，复杂度高的数据。比如说，在人员管理系统中，你删除一个人员，你即需要删除人员的基本资料，也要删除和该人员相关的信息，如信箱，文章等等，这样，这些数据库操作语句就构成一个事务！ 在 MySQL 中只有使用了 Innodb 数据库引擎的数据库或表才支持事务。 事务处理可以用来维护数据库的完整性，保证成批的 SQL 语句要么全部执行，要么全部不执行。 事务用来管理 insert,update,delete 语句 ACID 一般来说，事务是必须满足4个条件（ACID）： Atomicity（原子性）、Consistency（一致性或稳定性）、Isolation（隔离性）、Durability（持久性） 事务的原子性：一组事务，要么成功；要么撤回。 稳定性 ：有非法数据（外键约束之类），事务撤回。 隔离性：事务独立运行。一个事务处理后的结果，影响了其他事务，那么其他事务会撤回。事务的100%隔离，需要牺牲速度。 持久性：软、硬件崩溃后，InnoDB数据表驱动会利用日志文件重构修改。可靠性和高速度不可兼得. 在 MySQL 命令行的默认设置下，事务都是自动提交的，即执行 SQL 语句后就会马上执行 COMMIT 操作。因此要显式地开启一个事务务须使用命令 BEGIN 或 START TRANSACTION，或者执行命令 SET AUTOCOMMIT=0，用来禁止使用当前会话的自动提交。 事物控制语句： BEGIN或START TRANSACTION；显式地开启一个事务； COMMIT；也可以使用COMMIT WORK，不过二者是等价的。COMMIT会提交事务，并使已对数据库进行的所有修改称为永久性的； ROLLBACK；有可以使用ROLLBACK WORK，不过二者是等价的。回滚会结束用户的事务，并撤销正在进行的所有未提交的修改； SAVEPOINT identifier；SAVEPOINT允许在事务中创建一个保存点，一个事务中可以有多个SAVEPOINT； RELEASE SAVEPOINT identifier；删除一个事务的保存点，当没有指定的保存点时，执行该语句会抛出一个异常； ROLLBACK TO identifier；把事务回滚到标记点； SET TRANSACTION；用来设置事务的隔离级别。InnoDB存储引擎提供事务的隔离级别有READ UNCOMMITTED、READ COMMITTED、REPEATABLE READ和SERIALIZABLE。 MYSQL 事务处理主要有两种方法： 用 BEGIN, ROLLBACK, COMMIT来实现 BEGIN 开始一个事务 ROLLBACK 事务回滚 COMMIT 事务确认 直接用 SET 来改变 MySQL 的自动提交模式: SET AUTOCOMMIT=0 禁止自动提交 SET AUTOCOMMIT=1 开启自动提交 事务的4个隔离级别 具体例子参考这篇博客 未提交读(Read Uncommitted)：允许脏读，也就是可能读取到其他会话中未提交事务修改的数据 提交读(Read Committed)：只能读取到已经提交的数据。Oracle等多数数据库默认都是该级别 (不重复读) 可重复读(Repeated Read)：可重复读。在同一个事务内的查询都是事务开始时刻一致的，InnoDB默认级别。在SQL标准中，该隔离级别消除了不可重复读，但是还存在幻象读 串行读(Serializable)：完全串行化的读，每次读都需要获得表级共享锁，读写相互都会阻塞 相关术语 脏读 :脏读就是指当一个事务正在访问数据，并且对数据进行了修改，而这种修改还没有提交到数据库中，这时，另外一个事务也访问这个数据，然后使用了这个数据。 不可重复读 :是指在一个事务内，多次读同一数据。在这个事务还没有结束时，另外一个事务也访问该同一数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改，那么第一个事务两次读到的的数据可能是不一样的。这样就发生了在一个事务内两次读到的数据是不一样的，因此称为是不可重复读。 幻读 :第一个事务对一个表中的数据进行了修改，这种修改涉及到表中的全部数据行。同时，第二个事务也修改这个表中的数据，这种修改是向表中插入一行新数据。那么，以后就会发生操作第一个事务的用户发现表中还有没有修改的数据行，就好象发生了幻觉一样。 临时表临时表在我们需要保存一些临时数据时是非常有用的。临时表只在当前连接可见，当关闭连接时，Mysql会自动删除表并释放所有空间。 防SQL注入 防止SQL注入，我们需要注意以下几个要点： 永远不要信任用户的输入。对用户的输入进行校验，可以通过正则表达式，或限制长度；对单引号和 双”-“进行转换等。 永远不要使用动态拼装sql，可以使用参数化的sql或者直接使用存储过程进行数据查询存取。 永远不要使用管理员权限的数据库连接，为每个应用使用单独的权限有限的数据库连接。 不要把机密信息直接存放，加密或者hash掉密码和敏感的信息。 应用的异常信息应该给出尽可能少的提示，最好使用自定义的错误信息对原始错误信息进行包装 sql注入的检测方法一般采取辅助软件或网站平台来检测，软件一般采用sql注入检测工具jsky，网站平台就有亿思网站安全平台检测工具。MDCSOFT SCAN等。采用MDCSOFT-IPS可以有效的防御SQL注入，XSS攻击等。 可以总结为 : 连接权限 包装提示 校验输入]]></content>
      <categories>
        <category>DB</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[MySQL进阶(一)]]></title>
    <url>%2F2016%2F06%2F14%2FMySQL%E8%BF%9B%E9%98%B6(%E4%B8%80)%2F</url>
    <content type="text"><![CDATA[引擎 MySQL是有多个引擎的, 不同的场景情况用不同的引擎以提升性能和灵活性. 三大最常用的引擎 : InnoDB : 可靠的事务处理引擎 ,不支持全文搜索 MyISAM : 支持全文搜索, 不支持事务处理 MEMORY : 功能等同于MyISAM, 但数据存储在内存而不是磁盘, 所以速度非常快, 特别适用于临时表(temporary table) 索引 索引是用来改善搜索性能的, 不要滥用索引, 索引会降低更新表的速度，如对表进行INSERT、UPDATE和DELETE。因为更新表时，MySQL不仅要保存数据，还要保存一下索引文件。 索引有三种 : 普通索引normal 唯一索引unique : 它与前面的普通索引类似，不同的就是：索引列的值必须唯一，但允许有空值。如果是组合索引，则列值的组合必须唯一。 全文索引fulltext : 表示 全文搜索的索引。 FULLTEXT 用于搜索很长一篇文章的时候，效果最好。用在比较短的文本，如果就一两行字的，普通的 INDEX 也可以。 建立索引需要遵守的规则 : 选择唯一性索引 为经常需要排序、分组和联合操作的字段建立索引 为常作为查询条件的字段建立索引 限制索引的数目 尽量使用数据量少的索引 尽量使用前缀来索引 删除不再使用或者很少使用的索引 一些优化建议 like和fulltext like没有fulltext快, 但需要大内容的全文本搜索的时候来一发fulltext吧 选择正确数据类型 比如 : 定长的数据类型比可变长度的数据类型性能要高 正确使用索引 勿滥用select *语句 关闭自动提交]]></content>
      <categories>
        <category>DB</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[UE4旋转笔记]]></title>
    <url>%2F2016%2F05%2F31%2FUE4%E6%97%8B%E8%BD%AC%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[最近想将一个vector转化为rotator，转而需要考虑UE4到底是怎么旋转的。下面我们做个实验： 我们先将两个staticMesh放入场景，并将它们的rotation调成一样，如上图。上面那个为renti_a_gear，下面那个为renti_a_gear2. 第一种情况： 绕自身坐标系来旋转 如上图，两个staticMesh旋转之后rotation是一样的，可以证明，绕自身坐标系旋转的顺序是Z-&gt;Y-&gt;X 第二种情况： 绕世界坐标系来旋转 如上图，两个staticMesh旋转之后rotation是一样的，可以证明，绕世界坐标系旋转的顺序跟第一种情况刚好反过来， 是X-&gt;Y-&gt;Z]]></content>
      <categories>
        <category>UE4</category>
      </categories>
      <tags>
        <tag>UE4</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[http报文笔记整理]]></title>
    <url>%2F2016%2F05%2F24%2Fhttp%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86%E4%B9%8B%E6%8A%A5%E6%96%87%2F</url>
    <content type="text"><![CDATA[看了书和各种网上资料, 学东西嘛, 要做总结, 这些老笔记整理一下, 供以后方便查阅也加强印象和理解. 报文的组成 起始行(start line) 首部(header) 主体(body) 可细分为 : 方法 :如GET, HEAD, POST 关于HTTP请求GET和POST的区别 : 1.提交方式的区别: 12345- GET提交，请求的数据会附在URL之后（就是把数据放置在HTTP协议头＜request-line＞中），以?分割URL和传输数据，多个参数用&amp;连接;例如：login.action?name=hyddd&amp;password=idontknow&amp;verify=%E4%BD%A0 %E5%A5%BD。如果数据是英文字母/数字，原样发送，如果是空格，转换为+，如果是中文/其他字符，则直接把字符串用BASE64加密，得出如： %E4%BD%A0%E5%A5%BD，其中％XX中的XX为该符号以16进制表示的ASCII。- POST提交：把提交的数据放置在是HTTP包的包体＜request-body＞中。上文示例中红色字体标明的就是实际的传输数据因此，GET提交的数据会在地址栏中显示出来，而POST提交，地址栏不会改变 2.传输数据的大小：1234567首先声明,HTTP协议没有对传输的数据大小进行限制，HTTP协议规范也没有对URL长度进行限制。 而在实际开发中存在的限制主要有：GET:特定浏览器和服务器对URL长度有限制，例如IE对URL长度的限制是2083字节(2K+35)。对于其他浏览器，如Netscape、FireFox等，理论上没有长度限制，其限制取决于操作系统的支持。因此对于GET提交时，传输数据就会受到URL长度的限制。POST:由于不是通过URL传值，理论上数据不受限。但实际各个WEB服务器会规定对post提交数据大小进行限制，Apache、IIS6都有各自的配置。 安全性：12345POST的安全性要比GET的安全性高。注意：这里所说的安全性和上面GET提到的“安全”不是同个概念。上面“安全”的含义仅仅是不作数据修改，而这里安全的含义是真正的Security的含义，比如：通过GET提交数据，用户名和密码将明文出现在URL上，因为(1)登录页面有可能被浏览器缓存， (2)其他人查看浏览器的历史纪录，那么别人就可以拿到你的账号和密码了， 请求URL URL是浏览器寻找信息时所需的资源位置 .URL分为三个部分 : URL文案 服务器位置 资源路径 版本号上图中的HTTP/1.0 200 OK, HTTP/1.0就是版本号 状态码 : 如最著名的404, 302, 如上图中的HTTP/1.0 200 OK中, 状态码就是200 原因短语 如上图中的HTTP/1.0 200 OK中, OK就是原因短语 首部 主体主体部分是可选的, 主体是http报文要传输的内容, 可以承载很多类型的数字数据 : 图片, 视频, 软件应用程序, 电子邮件等]]></content>
      <categories>
        <category>脚本</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[php与cgi]]></title>
    <url>%2F2016%2F05%2F22%2Fhttp%E7%AC%94%E8%AE%B0%E4%B9%8Bphp%E4%B8%8Ecgi%2F</url>
    <content type="text"><![CDATA[首先，CGI是干嘛的？CGI是为了保证web server传递过来的数据是标准格式的，方便CGI程序的编写者。 web server（比如说nginx）只是内容的分发者。比如，如果请求/index.html，那么web server会去文件系统中找到这个文件，发送给浏览器，这里分发的是静态数据。好了，如果现在请求的是/index.php，根据配置文件，nginx知道这个不是静态文件，需要去找PHP解析器来处理，那么他会把这个请求简单处理后交给PHP解析器。Nginx会传哪些数据给PHP解析器呢？url要有吧，查询字符串也得有吧，POST数据也要有，HTTP header不能少吧，好的，CGI就是规定要传哪些数据、以什么样的格式传递给后方处理这个请求的协议。仔细想想，你在PHP代码中使用的用户从哪里来的。 当web server收到/index.php这个请求后，会启动对应的CGI程序，这里就是PHP的解析器。接下来PHP解析器会解析php.ini文件，初始化执行环境，然后处理请求，再以规定CGI规定的格式返回处理后的结果，退出进程。web server再把结果返回给浏览器。 好了，CGI是个协议，跟进程什么的没关系。那fastcgi又是什么呢？Fastcgi是用来提高CGI程序性能的。 提高性能，那么CGI程序的性能问题在哪呢？”PHP解析器会解析php.ini文件，初始化执行环境”，就是这里了。标准的CGI对每个请求都会执行这些步骤（不闲累啊！启动进程很累的说！），所以处理每个时间的时间会比较长。这明显不合理嘛！那么Fastcgi是怎么做的呢？首先，Fastcgi会先启一个master，解析配置文件，初始化执行环境，然后再启动多个worker。当请求过来时，master会传递给一个worker，然后立即可以接受下一个请求。这样就避免了重复的劳动，效率自然是高。而且当worker不够用时，master可以根据配置预先启动几个worker等着；当然空闲worker太多时，也会停掉一些，这样就提高了性能，也节约了资源。这就是fastcgi的对进程的管理。 那PHP-FPM又是什么呢？是一个实现了Fastcgi的程序，被PHP官方收了。 大家都知道，PHP的解释器是php-cgi。php-cgi只是个CGI程序，他自己本身只能解析请求，返回结果，不会进程管理（皇上，臣妾真的做不到啊！）所以就出现了一些能够调度php-cgi进程的程序，比如说由lighthttpd分离出来的spawn-fcgi。好了PHP-FPM也是这么个东东，在长时间的发展后，逐渐得到了大家的认可（要知道，前几年大家可是抱怨PHP-FPM稳定性太差的），也越来越流行。好了，最后来回来你的问题。 网上有的说，fastcgi是一个协议，php-fpm实现了这个协议 对。 有的说，php-fpm是fastcgi进程的管理器，用来管理fastcgi进程的 对。php-fpm的管理对象是php-cgi。但不能说php-fpm是fastcgi进程的管理器，因为前面说了fastcgi是个协议，似乎没有这么个进程存在，就算存在php-fpm也管理不了他（至少目前是）。 有的说，php-fpm是php内核的一个补丁 以前是对的。因为最开始的时候php-fpm没有包含在PHP内核里面，要使用这个功能，需要找到与源码版本相同的php-fpm对内核打补丁，然后再编译。后来PHP内核集成了PHP-FPM之后就方便多了，使用–enalbe-fpm这个编译参数即可。 有的说，修改了php.ini配置文件后，没办法平滑重启，所以就诞生了php-fpm 是的，修改php.ini之后，php-cgi进程的确是没办法平滑重启的。php-fpm对此的处理机制是新的worker用新的配置，已经存在的worker处理完手上的活就可以歇着了，通过这种机制来平滑过度。 还有的说PHP-CGI是PHP自带的FastCGI管理器，那这样的话干吗又弄个php-fpm出 不对。php-cgi只是解释PHP脚本的程序而已。 参考]]></content>
      <categories>
        <category>脚本</category>
      </categories>
      <tags>
        <tag>php</tag>
        <tag>cgi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vector的增长方式与使用注意点]]></title>
    <url>%2F2016%2F05%2F17%2Fvector%E7%9A%84%E5%A2%9E%E9%95%BF%E6%96%B9%E5%BC%8F%E4%B8%8E%E4%BD%BF%E7%94%A8%E6%B3%A8%E6%84%8F%E7%82%B9%2F</url>
    <content type="text"><![CDATA[增长方式为了支持快速随机访问 ， vector 将元素连续存储一一每个元素紧挨着前一个元素存储 。 假定容器中元素是连续存储 的， 且容器的大小是可变的 ， 考虑 向 vector 或 string中添加元素会发生什么 : 如果没有空间容纳新元素，容器不可能简单地将它添加到内存中其他位置一一因为元素必须连续存储。 容器必须分配新的内存空间来保存己有元素和新元素 ， 将已有元素从 旧位置移动到新空 间中， 然后添加新元素，释放旧存储空间 。 如果我们每添加一个新元素， vector 就执行一次这样的内存分配和释放操作 ，性能会慢到不可接受 。 为了避免这种代价，标准库实现者采用了可以减少容器空间重新分配次数的策略。 当不得不在取新的内 存空间 时， vector 和 string 的实现通常会分配比新的空间需求更大的内存空间 。 容器预留这些空间作为备用 ， 可用来保存更多的新元素 。 这样，就不需要每次添加新元素都重新分配容器的内存空间了 。 这种分配策略比每次添加新元素时都重新分配容器内存空间的策略要高效得多 。 其实际性能也表现得足够好一一虽然 vector 在每次重新分配内存空间时都要移动所有元素，但使用 此策略后，其扩张操作通常比 list 和 deque 还要快 。 迭代器失效看了上方的实现方式, 相信很容易能理解迭代器失效问题了啊 向容器中添加元素和从容器中删除元素 的操作可能会使指向容器元素的指针、引用或法代器失效。 一个失效的指针、引用或法代器将不再表示任何元素 。 使用失效的指针、引用或迭代器是一种严重的程序设计错误，很可能引起与使用未初始化指针一样的问题 capacity &amp; size 理解 capacity 和 size 的区别非常重要。 容器的 size 是指它已经保存的元素的数目 ; 而 capacity 则是在不分配新的内存空间的前提下它最多可以保存多少元素。 函数 函数 表述 c.assign(beg,end) 将[beg; end)区间中的数据赋值给c。 c.assign(n,elem) 将n个elem的拷贝赋值给c。 c.at(idx) 传回索引idx所指的数据，如果idx越界，抛出out_of_range。 c.back() 传回最后一个数据，不检查这个数据是否存在。 c.begin() 传回迭代器重的可一个数据。 c.capacity() 返不分配新的内存空间的前提下它最多可以保存多少元素。 c.clear() 移除容器中所有数据。 c.empty() 判断容器是否为空。 c.end() 指向迭代器中的最后一个数据地址。 c.erase(pos) 删除pos位置的数据，传回下一个数据的位置。 c.erase(beg,end) 删除[beg,end)区间的数据，传回下一个数据的位置。 c.front() 传回第一个数据。 get_allocator 使用构造函数返回一个拷贝。 c.insert(pos,elem) 在pos位置插入一个elem拷贝，传回新数据位置。 c.insert(pos,n,elem) 在pos位置插入n个elem数据。无返回值。 c.insert(pos,beg,end) 在pos位置插入在[beg,end)区间的数据。无返回值。 c.max_size() 返回容器中最大数据的数量。 c.pop_back() 删除最后一个数据。 c.push_back(elem) 在尾部加入一个数据。 c.rbegin() 传回一个逆向队列的第一个数据。 c.rend() 传回一个逆向队列的最后一个数据的下一个位置。 c.resize(num) 重新指定队列的长度。 c.reserve() 保留适当的容量。 c.size() 返回容器中实际数据的个数。 c1.swap(c2) 将c1和c2元素互换。 swap(c1,c2) 同上操作。 构造 &amp; 销毁 写法 表述 vector c 创建一个空的vector。 vector c1(c2) 复制一个vector。 vector c(n) 创建一个vector，含有n个数据，数据均已缺省构造产生。 vector c(n, elem) 创建一个含有n个elem拷贝的vector。 vector c(beg,end) 创建一个以[beg;end)区间的vector。 c.~ vector () 销毁所有数据，释放内存。]]></content>
      <categories>
        <category>c++</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>stl</tag>
        <tag>vector</tag>
        <tag>string</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[stl关联容器的特性]]></title>
    <url>%2F2016%2F04%2F26%2Fstl%E5%85%B3%E8%81%94%E5%AE%B9%E5%99%A8%E7%9A%84%E7%89%B9%E6%80%A7%2F</url>
    <content type="text"><![CDATA[概绍 关联容器和 顺序容器有着根本的不问 : 关联容器中的元素是按关键字来保在和访问的 。 与之相对，顺序容器中的元素是按它们在容器中的位置来顺序保存和访问的 。 关联容器支持高效的关键字查找和访问 。 两个主要的关联容器类型是 map set map 中 的元素是一些关键字一值 ( key-value )对 : 关键字起到索 引 的作用，值则表示与索引相关联的数据 。 set 中每个元素只包含一个关键字 : set 支持高效的关键字检查一个给定关键字是否在 set 中 。 例如，在某些文本处理过程中，可以用一个 set 来保存想要忽略的单词。字典则是一个很好的使用 map 的例子 : 可 以将单词作为关键字 ， 将单词释义作为值 。 map &amp; set 的实现因为需要快速定位到键值的关系, 以红黑树的结构实现，其自平衡特性可以让插入删除等操作都可以在O(log n)时间内完成 map的基本操作函数 函数 含义 begin() 返回指向map头部的迭代器 clear(） 删除所有元素 count() 返回指定元素出现的次数 empty() 如果map为空则返回true end() 返回指向map末尾的迭代器 equal_range() 返回特殊条目的迭代器对 erase() 删除一个元素 find() 查找一个元素 get_allocator() 返回map的配置器 insert() 插入元素 key_comp() 返回比较元素key的函数 lower_bound() 返回键值&gt;=给定元素的第一个位置 max_size() 返回可以容纳的最大元素个数 rbegin() 返回一个指向map尾部的逆向迭代器 rend() 返回一个指向map头部的逆向迭代器 size() 返回map中元素的个数 swap() 交换两个map upper_bound() 返回键值&gt;给定元素的第一个位置 value_comp() 返回比较元素value的函数]]></content>
      <categories>
        <category>c++</category>
      </categories>
      <tags>
        <tag>stl</tag>
        <tag>map</tag>
        <tag>set</tag>
        <tag>pair</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5分钟学会git(二)]]></title>
    <url>%2F2016%2F04%2F13%2F5%E5%88%86%E9%92%9F%E5%AD%A6%E4%BC%9Agit(%E4%BA%8C)%2F</url>
    <content type="text"><![CDATA[贮藏stash 设想一个场景，假设我们正在一个新的分支做新的功能，这个时候突然有一个紧急的bug需要修复，而且修复完之后需要立即发布。当然你说我先把刚写的一点代码进行提交不就行了么？这样理论上当然是ok的，但是这会产品垃圾commit，原则上我们每次的commit都要有实际的意义，你的代码只是刚写了一半，还没有什么实际的意义是不建议就这样commit的，那么有没有一种比较好的办法，可以让我暂时切到别的分支，修复完bug再切回来，而且代码也能保留的呢？ 试试git stash吧 git stash : 把当前的文件改动贮藏起来 git stash list: 查看当前有哪些贮藏记录 git stash pop stash_list_id: 会帮你把代码还原，还自动帮你把这条 stash 记录删除 12345678910111213141516171819202122232425b@b-VirtualBox:~/git_test_link/Flock-AI-Fish-Unreal-VR$ git checkout old_demo error: Your local changes to the following files would be overwritten by checkout: README.mdPlease, commit your changes or stash them before you can switch branches.Abortingb@b-VirtualBox:~/git_test_link/Flock-AI-Fish-Unreal-VR$ git stash Saved working directory and index state WIP on new_test_branch: b3ad5d2 modify mdHEAD is now at b3ad5d2 modify mdb@b-VirtualBox:~/git_test_link/Flock-AI-Fish-Unreal-VR$ git checkout old_demo Switched to branch &apos;old_demo&apos;Your branch is up-to-date with &apos;origin/old_demo&apos;.b@b-VirtualBox:~/git_test_link/Flock-AI-Fish-Unreal-VR$ git checkout new_test_branch Switched to branch &apos;new_test_branch&apos;b@b-VirtualBox:~/git_test_link/Flock-AI-Fish-Unreal-VR$ git stash liststash@&#123;0&#125;: WIP on new_test_branch: b3ad5d2 modify mdb@b-VirtualBox:~/git_test_link/Flock-AI-Fish-Unreal-VR$ git stash pop stash@&#123;0&#125;On branch new_test_branchChanges not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: README.mdno changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;)Dropped stash@&#123;0&#125; (88cd440c10c80bb6eaef9f4d86ab4a0be3d6dc00) 对比diff 比如查看当前还未git add的文件的不同 : git diff 比如查看当前已经add 没有commit 的改动 : git diff –cached 比如查看当前所有改动和HEAD的区别(当前还未git add的文件的改动和当前当前已经add 但没有commit 的改动), 也就是上面两条命令的合并 : git diff HEAD 比如查看 commit_id为a和commit_id为b的temp文件夹的差异 : git diff a b temp 处理冲突 假设这样一个场景，A和B两位同学各自开了两个分支来开发不同的功能，大部分情况下都会尽量互不干扰的，但是有一个需求A需要改动一个基础库中的一个类的方法，不巧B这个时候由于业务需要也改动了基础库的这个方法，因为这种情况比较特殊，A和B都认为不会对地方造成影响，等两人各自把功能做完了，需要合并的到主分支 master 的时候，我们假设先合并A的分支，这个时候没问题的，之后再继续合并B的分支，这个时候想想也知道就有冲突了，因为A和B两个人同时更改了同一个地方，Git 本身他没法判断你们两个谁更改的对，但是这个时候他会智能的提示有 conflicts 就像下面这种情况 :1234b@b-VirtualBox:~/git_test_link/Flock-AI-Fish-Unreal-VR$ git merge plugin Auto-merging README.mdCONFLICT (content): Merge conflict in README.mdAutomatic merge failed; fix conflicts and then commit the result. 打开READ.md文件一看发现冲突的地方如下:12345&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEADmmmp=======nani&gt;&gt;&gt;&gt;&gt;&gt;&gt; plugin 冲突的地方由 ==== 分出了上下两个部分，上部分一个叫 HEAD 的字样代表是我当前所在分支的代码，下半部分是一个叫 plugin 分支的代码，可以看到 HEAD 是那里加了一行mmmp，而plugin分支则加了一句nani, 所以我们得跟团队的其他人商量一下看看要改成什么样，而且同时也要把那些 «&lt; HEAD、==== 以及 »»»plugin 这些标记符号也一并删除，最后进行一次 commit 就ok了。 标签tag 主要介绍附注标签( annotated tag) 创建附注标签git tag -a v0.1.2 -m “0.1.2版本” 创建轻量标签不需要传递参数，直接指定标签名称即可。创建附注标签时，参数a即annotated的缩写，指定标签类型，后附标签名。参数m指定标签说明，说明信息会保存在标签对象中。 切换到标签与切换分支命令相同，用git checkout [tagname] 查看标签信息用git show命令可以查看标签的版本信息：git show v0.1.2 删除标签误打或需要修改标签时，需要先将标签删除，再打新标签。git tag -d v0.1.2 # 删除标签 参数d即delete的缩写，意为删除其后指定的标签。 给指定的commit打标签打标签不必要在head之上，也可在之前的版本上打，这需要你知道某个提交对象的校验和（通过git log获取）。git tag -a v0.1.1 9fbc3d0 标签发布通常的git push不会将标签对象提交到git服务器，我们需要进行显式的操作： git push origin v0.1.2 # 将v0.1.2标签提交到git服务器git push origin -–tags # 将本地所有标签一次性提交到git服务器]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5分钟学会git(一)]]></title>
    <url>%2F2016%2F04%2F12%2F5%E5%88%86%E9%92%9F%E5%AD%A6%E4%BC%9Agit(%E4%B8%80)%2F</url>
    <content type="text"><![CDATA[我之前有一份私人git笔记老长老长了, 今天得空, 把它浓缩成5分钟版本.感觉纯基础性的东西整理成博客差也差不多了, 还有很多凌乱的工作笔记慢慢在一点一点整理放上来吧,估计下面几篇博客就开始游戏服务器的开发心得之类的了. 本篇博客因为要5分钟撸完git, 所以语言尽量精简, 只说新人必须知道的, 如果要git进阶的, 后面再另写博客说明, 不该说的废话就不说了 安装 sudo apt-get install git 查看状态 比如查看当前分支的状态 : git status, 这条命令也会给很多其他的git命令提示的喔 查看当前在哪个分支 : git branch12345b@b-VirtualBox:~/git_test_link/Flock-AI-Fish-Unreal-VR$ git branch master new_test_branch* old_demo plugin 标记为*的那个就是当前分支, 也就是old_demo分支 克隆 比如从我的一个远端github项目克隆一份到本地 : git clone git@github.com:nosix1992/Flock-AI-Fish-Unreal-VR.git这个地址是这样得来的, 如图 : 分支 比如创建一个新的分支test_branch : git branch test_branch 比如切换到分支test_branch : git checkout test_branch 比如把test_branch合并到主分支master上来 : 先切换到master上来git checkout master 然后 git merge test_branch git rebase test_branch rebase 跟 merge 的区别你们可以理解成有两个书架，你需要把两个书架的书整理到一起去，第一种做法是 merge ，比较粗鲁暴力，就直接腾出一块地方把另一个书架的书全部放进去，虽然暴力，但是这种做法你可以知道哪些书是来自另一个书架的；第二种做法就是 rebase ，他会把两个书架的书先进行比较，按照购书的时间来给他重新排序，然后重新放置好，这样做的好处就是合并之后的书架看起来很有逻辑，但是你很难清晰的知道哪些书来自哪个书架的。各有好处的，不同的团队根据不同的需要以及不同的习惯来选择就好。 比如删除分支test_branch : git branch -d test_branch git branch -D test_branch 有些时候可能会删除失败，比如如果a分支的代码还没有合并到master，你执行 git branch -d a 是删除不了的，它会智能的提示你a分支还有未合并的代码，但是如果你非要删除，那就执行 git branch -D a 就可以强制删除a分支。 提交 比如将修改之后的文件test_file加入到暂存区里 : git add test_file 撤销刚刚的git add(也就是说把test_file从暂存区中移出) : git reset HEAD test_file 比如将暂存区里的提交并加入提交信息”update test_file” : git commit -m “update test_file” 把git commit撤销 : 只是把commit撤销并且把文件从暂存区中移出, 但保留已有的文件更改 : 通用命令为 git reset commit_id, 这个commit_id用git log命令来查看, 比如要恢复到刚刚提交的上一次提交的版本, 就用git reset HEAD^(这句命令的意思是说: 恢复到commit id 为HEAD^的版本, HEAD是指向最新的提交，上一次提交是HEAD^,上上次是HEAD^^,也可以写成HEAD～2 ,依次类推. ) 把commit撤销且不保留已有的文件更改 : git reset –hard commit_id 比如只是撤销某个文件test_file的修改 : git checkout –test_file 将代码推到远端 : 这之前的所有这些add, commit都是本地仓库的操作, 比如我们把本地的master分支推到github的那个项目的master分支 : git push origin master]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++ 很基础的易混淆点（二）]]></title>
    <url>%2F2015%2F12%2F09%2FC%2B%2B%20%E5%BE%88%E5%9F%BA%E7%A1%80%E7%9A%84%E6%98%93%E6%B7%B7%E6%B7%86%E7%82%B9%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[位操作运算符的问题二进制的100 的第0位是 01(第二位) 0(第一位) 0(第0位)，所以把一个数的第三位进行清零、置位、取反的操作如下：123456789101112131415161718192021#include &lt;stdio.h&gt;#define Bit3 (0X01&lt;&lt;3)/*对一个数的第三位进行清零、置位、取反*/int main()&#123; int a=15 ; // 0000 1111 printf(&quot;原大小：%d\n&quot;, a); a &amp;= ~Bit3; //清零, 0000 0111 printf(&quot;清零后：%d\n&quot;, a); a |= Bit3; //置位, 0000 1111 printf(&quot;置位后：%d\n&quot;, a); a ^= Bit3; //取反, 0000 0111 printf(&quot;取反后：%d\n&quot;, a); return 0;&#125; 字符串分配的位置问题程序的存储区域分为：代码段、只读数据段、已初始化的读写数据段、未初始化的数据段、堆、栈。1、代码段、只读数据段、已初始化的读写数据段、未初始化的数据段都属于静态区域。2、堆内存只在程序运行时出现，一般有程序员分配和释放。3、栈内存只在程序运行时出现，在函数内部使用的变量，函数参数以及返回值将使用栈空间。1234567891011121314151617char* get_str()&#123; char *str = &quot;hello&quot;; //第一种情况：分配在静态存储区上 //char str[] = &quot;hello&quot;; //第二种情况分配在栈上 return str;&#125;int main()&#123; char* p = get_str(); // 如果是第一种情况，下述打印可以打印出正确的值；但是第二种情况打印结果是错的。 printf(&quot;%s/n&quot;, p); *++p = &apos;a&apos;; // 如果是第一种情况，运行时将会段错误，因为不能修改它； printf(&quot;%s/n&quot;, p); return 0;&#125; 复杂类型的声明和typedef定义 用变量a给出下面的定义:一个有10个指针的数组，该指针指向一个函数，该函数有一个整型参数并返回一个整型数 int (*a[10])(int); typedef表示一个长度为4的数组;typedef int ARR[4]; typedef表示一个函数指针有一个整型参数并返回一个整型数：typedef int（*FUNC）（int）；]]></content>
      <categories>
        <category>c++</category>
      </categories>
      <tags>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux常用命令笔记整理之tcpdump]]></title>
    <url>%2F2015%2F11%2F03%2FLinux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86%E4%B9%8Btcpdump%2F</url>
    <content type="text"><![CDATA[强大的抓包工具, 博大精深内容太多, 所以这篇博客整理得只说常用, 具体的参考tcpdump用户手册,tcpdump需要root权限, 所以记得加上sudo 常用参数 -nn选项：意思是说当tcpdump遇到协议号或端口号时，不要将这些号码转换成对应的协议名称或端口名称。比如，大家都知道80是http端口，tcpdump就不会将它显示成http了 -c选项：是Count的含义，这设置了我们希望tcpdump帮我们抓几个包。 -i : 指定哪一张网卡 -l : 使得输出变为行缓冲 -t : 输出时不打印时间戳 -v : 输出更详细的信息 -F : 指定过滤表达式所在的文件, 可以建立了一个filter.txt文本文件来存储过滤表达式，然后通过-F来指定filter.txt -w : 将流量保存到文件中 -r : 读取raw packets文件 常用过滤规则 只看到目的机器dst(比如是qq.com)之间的网络包sudo tcpdump -i eth0 ‘dst qq.com’ 也可以写成 sudo tcpdump -i eth0 ‘dst host qq.com’ 注 : 上述的那个host可以省略tcpdump支持如下的类型： host：指定主机名或IP地址，例如’host roclinux.cn’或’host 202.112.18.34′ net ：指定网络段，例如’arp net 128.3’或’dst net 128.3′ portrange：指定端口区域，例如’src or dst portrange 6000-6008′ port : 端口如果我们没有设置过滤类型，那么默认是host。 只抓udp的包sudo tcpdump -i eth0 ‘udp’ tcpdump具有根据网络包的协议来进行过滤的能力，我们还可以把udp改为ether、ip、ip6、arp、tcp、rarp等 只抓目的机器的某个端口的包(比如只抓baidu.com的53或者80端口的包)sudo tcpdump -i eth0 ‘dst baidu.com and (dst port 53 or dst port 80)’ 通过eth0网卡的，且来源是qq.com服务器或者目标是qq.com服务器的网络包sudo tcpdump -i eth0 ‘host qq.com’ 通过eth0网卡的，且qq.com和baidu.com之间通讯的网络包，或者qq.com和sina.cn之间通讯的网络包tcpdump -i eth0 ‘host qq.com and (baidu.com or sina.cn)’ 获取和baidu.com之间建立TCP三次握手中第一个网络包，即带有SYN标记位的网络包sudo tcpdump -i eth0 ‘tcp[tcpflags] &amp; tcp-syn != 0 and dst host baidu.com’ 注 :因为用proto [ expr : size]语法在写过滤表达式时，你需要把协议格式完全背在脑子里，才能把表达式写对。可这对大多数人来说，可能有些困难。为了让tcpdump工具更人性化一些，有一些常用的偏移量，可以通过一些名称来代替，比如icmptype表示ICMP协议的类型域、icmpcode表示ICMP的code域，tcpflags则表示TCP协议的标志字段域。 更进一步的，对于ICMP的类型域，可以用这些名称具体指代：icmp-echoreply, icmp-unreach, icmp-sourcequench, icmp-redirect, icmp-echo, icmp-routeradvert, icmp-routersolicit, icmp-timxceed, icmp-paramprob, icmp-tstamp, icmp-tstampreply, icmp-ireq, icmp-ireqreply, icmp-maskreq, icmp-maskreply。 而对于TCP协议的标志字段域，则可以细分为tcp-fin, tcp-syn, tcp-rst, tcp-push, tcp-ack, tcp-urg。 输出内容解释1234567891011121314151617b@b-VirtualBox:~$ sudo tcpdump -i eth0 &apos;host baidu.com&apos;tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on eth0, link-type EN10MB (Ethernet), capture size 65535 bytes06:46:17.487920 IP 192.168.1.57.60110 &gt; 111.13.101.208.http: Flags [S], seq 546310089, win 29200, options [mss 1460,sackOK,TS val 1221546 ecr 0,nop,wscale 7], length 006:46:17.530422 IP 111.13.101.208.http &gt; 192.168.1.57.60110: Flags [S.], seq 3245676077, ack 546310090, win 8192, options [mss 1440,sackOK,nop,nop,nop,nop,nop,nop,nop,nop,nop,nop,nop,wscale 5], length 006:46:17.530458 IP 192.168.1.57.60110 &gt; 111.13.101.208.http: Flags [.], ack 1, win 229, length 006:46:17.530982 IP 192.168.1.57.60110 &gt; 111.13.101.208.http: Flags [P.], seq 1:504, ack 1, win 229, length 50306:46:17.576476 IP 111.13.101.208.http &gt; 192.168.1.57.60110: Flags [.], ack 504, win 216, length 006:46:17.577447 IP 111.13.101.208.http &gt; 192.168.1.57.60110: Flags [P.], seq 1:291, ack 504, win 216, length 29006:46:17.577459 IP 192.168.1.57.60110 &gt; 111.13.101.208.http: Flags [.], ack 291, win 237, length 006:46:17.577482 IP 111.13.101.208.http &gt; 192.168.1.57.60110: Flags [P.], seq 291:452, ack 504, win 216, length 16106:46:17.577485 IP 192.168.1.57.60110 &gt; 111.13.101.208.http: Flags [.], ack 452, win 245, length 006:46:17.866950 IP 111.13.101.208.http &gt; 192.168.1.57.60110: Flags [P.], seq 291:452, ack 504, win 216, length 16106:46:17.866966 IP 192.168.1.57.60110 &gt; 111.13.101.208.http: Flags [.], ack 452, win 245, options [nop,nop,sack 1 &#123;291:452&#125;], length 006:46:27.865805 IP 192.168.1.57.60110 &gt; 111.13.101.208.http: Flags [.], ack 452, win 245, length 006:46:27.909962 IP 111.13.101.208.http &gt; 192.168.1.57.60110: Flags [.], ack 504, win 216, length 006:46:37.925624 IP 192.168.1.57.60110 &gt; 111.13.101.208.http: Flags [.], ack 452, win 245, length 0]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>tcpdump</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux常用文本处理命令笔记整理(二)]]></title>
    <url>%2F2015%2F10%2F23%2Flinux%E5%B8%B8%E7%94%A8%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E5%91%BD%E4%BB%A4%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86(%E4%BA%8C)%2F</url>
    <content type="text"><![CDATA[sed sed是一种流编辑器，它是文本处理中非常中的工具，能够完美的配合正则表达式使用，功能不同凡响。处理时，把当前处理的行存储在临时缓冲区中，称为“模式空间”（pattern space），接着用sed命令处理缓冲区中的内容，处理完成后，把缓冲区的内容送往屏幕。接着处理下一行，这样不断重复，直到文件末尾。文件内容并没有 改变，除非你使用重定向存储输出。Sed主要用来自动编辑一个或多个文件；简化对文件的反复操作；编写转换程序等。 sed命令 a\ 在当前行下面插入文本。 i\ 在当前行上面插入文本。 c\ 把选定的行改为新的文本。 d 删除，删除选择的行。 D 删除模板块的第一行。 s 替换指定字符 h 拷贝模板块的内容到内存中的缓冲区。 H 追加模板块的内容到内存中的缓冲区。 g 获得内存缓冲区的内容，并替代当前模板块中的文本。 G 获得内存缓冲区的内容，并追加到当前模板块文本的后面。 l 列表不能打印字符的清单。 n 读取下一个输入行，用下一个命令处理新的行而不是用第一个命令。 N 追加下一个输入行到模板块后面并在二者间嵌入一个新行，改变当前行号码。 p 打印模板块的行。 P(大写) 打印模板块的第一行。 q 退出Sed。 b lable 分支到脚本中带有标记的地方，如果分支不存在则分支到脚本的末尾。 r file 从file中读行。 t label if分支，从最后一行开始，条件一旦满足或者T，t命令，将导致分支到带有标号的命令处，或者到脚本的末尾。 T label 错误分支，从最后一行开始，一旦发生错误或者T，t命令，将导致分支到带有标号的命令处，或者到脚本的末尾。 w file 写并追加模板块到file末尾。 W file 写并追加模板块的第一行到file末尾。 ! 表示后面的命令对所有没有被选定的行发生作用。 = 打印当前行号码。 把注释扩展到下一个换行符以前。 sed替换标记 g 表示行内全面替换。 p 表示打印行。 w 表示把行写入一个文件。 x 表示互换模板块中的文本和缓冲区中的文本。 y 表示把一个字符翻译为另外的字符（但是不用于正则表达式） \1 子串匹配标记 &amp; 已匹配字符串标记 sed元字符集 ^ 匹配行开始，如：/^sed/匹配所有以sed开头的行。 $ 匹配行结束，如：/sed$/匹配所有以sed结尾的行。 . 匹配一个非换行符的任意字符，如：/s.d/匹配s后接一个任意字符，最后是d。 * 匹配0个或多个字符，如：/*sed/匹配所有模板是一个或多个空格后紧跟sed的行。 [] 匹配一个指定范围内的字符，如/[ss]ed/匹配sed和Sed。 [^] 匹配一个不在指定范围内的字符，如：/[^A-RT-Z]ed/匹配不包含A-R和T-Z的一个字母开头，紧跟ed的行。 (..) 匹配子串，保存匹配的字符，如s/(love)able/\1rs，loveable被替换成lovers。 &amp; 保存搜索字符用来替换其他字符，如s/love/&amp;/，love这成love。 \&lt; 匹配单词的开始，如:/\ 匹配单词的结束，如/love>/匹配包含以love结尾的单词的行。 x{m} 重复字符x，m次，如：/0{5}/匹配包含5个0的行。 x{m,} 重复字符x，至少m次，如：/0{5,}/匹配至少有5个0的行。 x{m,n} 重复字符x，至少m次，不多于n次，如：/0{5,10}/匹配5~10个0的行。 直接编辑文件选项-i，否则并不会修改源文件 sed常用用法1：增123456b@b-VirtualBox:~/my_temp_test/abc$ cat abc3&amp;&amp; gg&amp;b@b-VirtualBox:~/my_temp_test/abc$ sed -i &apos;/gg/a\hello, my friend&apos; abc3b@b-VirtualBox:~/my_temp_test/abc$ cat abc3&amp;&amp; gg&amp;hello, my friend sed -i ‘/gg/a\hello, my friend’ abc3的含义是：在abc3文件中的“gg”字符串的下一行插入“hello， my friend” sed常用用法2：删123456b@b-VirtualBox:~/my_temp_test/abc$ cat abc3&amp;&amp; gg&amp;hello, my friendb@b-VirtualBox:~/my_temp_test/abc$ sed -i &apos;/gg/d&apos; abc3b@b-VirtualBox:~/my_temp_test/abc$ cat abc3hello, my friend sed -i ‘/gg/d’ abc3的含义是：将abc3文件中所有包含的“gg”字符串的行删除 sed常用用法3：改12345b@b-VirtualBox:~/my_temp_test/abc$ cat abc3hello, my friendb@b-VirtualBox:~/my_temp_test/abc$ sed -i &apos;s/hello/welcome/g&apos; abc3b@b-VirtualBox:~/my_temp_test/abc$ cat abc3welcome, my friend sed -i ‘s/hello/welcome/g’ abc3的含义是：将abc3文件中所有包含的“gg”字符串都修改为“welcome”]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>文本处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux常用文本处理命令笔记整理(一)]]></title>
    <url>%2F2015%2F10%2F21%2Flinux%E5%B8%B8%E7%94%A8%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E5%91%BD%E4%BB%A4%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86(%E4%B8%80)%2F</url>
    <content type="text"><![CDATA[linux常用文本处理的命令的使用率很高， 所以整理了一些之前的笔记，用markdown来记录备忘。首先抛出问题， 带着问题来学记忆知识更有动力： 如何通过一条命令取得eth0的IP4地址 ： ` ifconfig eth0 | grep -w &apos;inet&apos; | awk &apos;{print $2}&apos; | awk -F: &apos;{print $2}&apos;` 如何通过一条命令替换当前路径下所有文件中的所有“xxx”为“yyy“ ： `ls -alF | grep &apos;^-&apos; | xargs sed -i &apos;s/xxx/yyy/g&apos;` 如何通过一条命令杀掉占用端口34600的进程 ：` sudo lsof -i:34600 | grep -v &apos;PID&apos; | awk &apos;{print $2}&apos; | xargs kill -9` grep grep（global search regular expression(RE) and print out the line，全面搜索正则表达式并把行打印出来）是一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹配的行打印出来。 -a 不要忽略二进制数据。 -A&lt;显示列数&gt; 除了显示符合范本样式的那一行之外，并显示该行之后的内容。 -b 在显示符合范本样式的那一行之外，并显示该行之前的内容。 -c 计算符合范本样式的列数。 -C&lt;显示列数&gt;或-&lt;显示列数&gt; 除了显示符合范本样式的那一列之外，并显示该列之前后的内容。 -d&lt;进行动作&gt; 当指定要查找的是目录而非文件时，必须使用这项参数，否则grep命令将回报信息并停止动作。 -e&lt;范本样式&gt; 指定字符串作为查找文件内容的范本样式。 -E 将范本样式为延伸的普通表示法来使用，意味着使用能使用扩展正则表达式。 -f&lt;范本文件&gt; 指定范本文件，其内容有一个或多个范本样式，让grep查找符合范本条件的文件内容，格式为每一列的范本样式。 -F 将范本样式视为固定字符串的列表。 -G 将范本样式视为普通的表示法来使用。 -h 在显示符合范本样式的那一列之前，不标示该列所属的文件名称。 -H 在显示符合范本样式的那一列之前，标示该列的文件名称。 -i 胡列字符大小写的差别。（常用） -l 列出文件内容符合指定的范本样式的文件名称。 -L 列出文件内容不符合指定的范本样式的文件名称。 -n 在显示符合范本样式的那一列之前，标示出该列的编号。 -q 不显示任何信息。 -R/-r 此参数的效果和指定“-d recurse”参数相同。 -s 不显示错误信息。 -v 反转查找。（常用） -w 只显示全字符合的列。（常用） -x 只显示全列符合的列。 -y 此参数效果跟“-i”相同。 -o 只输出文件中匹配到的部分。 awk awk是一种编程语言，用于在linux/unix下对文本和数据进行处理。数据可以来自标准输入(stdin)、一个或多个文件，或其它命令的输出。它支持用户自定义函数和动态正则表达式等先进功能，是linux/unix下的一个强大编程工具。它在命令行中使用，但更多是作为脚本来使用。awk有很多内建的功能，比如数组、函数等，这是它和C语言的相同之处，灵活性是awk最大的优势。 常用命令选项 -F fs fs指定输入分隔符（awk默认的分隔符是空格），fs可以是字符串或正则表达式，如-F: -v var=value 赋值一个用户定义变量，将外部变量传递给awk 常用用法123456b@b-VirtualBox:~/my_temp_test/abc$ cat abc3klj;k uu&amp;&amp; ss&amp;b@b-VirtualBox:~/my_temp_test/abc$ cat abc3 | awk &apos;&#123;print $NF&#125;&apos;uuss&amp; cat abc3 | awk ‘{print $NF}’的含义是：输出abc3文件的每一行的最后一列12b@b-VirtualBox:~/my_temp_test/abc$ cat abc3 | grep k | awk -F\; &apos;&#123;print $1&#125;&apos;klj cat abc3 | grep k | awk -F\; ‘{print $1}’的含义是：先输入含有k的那一行（即klj；k）， 然后对那一行以；（\;， 这个分号需要转义）分隔，打印出分隔后的第一列（即klj）]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>文本处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++ 很基础的易混淆点（一）]]></title>
    <url>%2F2015%2F09%2F09%2FC%2B%2B%20%E5%BE%88%E5%9F%BA%E7%A1%80%E7%9A%84%E6%98%93%E6%B7%B7%E6%B7%86%E7%82%B9%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[###2.1.1 : C++标准规定的各种算术类型的尺寸的最小值, 同时允许编译器赋予这些类型更大的尺寸. 比如char的最小尺寸为8位 执行浮点数运算选用double ，这是因为float 通常精度不够而且双精度浮点 数和单精度浮点数的计算代价相差无儿。事实上， 对于某些机器来说，双精度运 算甚至比单精度还快 ###2.1.2 : 当我们赋给无符号类型一个超出它表示范围的值时，结果是初始值对无符号类型表 示数值总数取棋后的余数。例如， 8 比特大小的un signe d char 可以表示0 至 255 区间内的值，如果我们赋了一个区间以外的值，则实际的结果是该值对256 取模后所得的余数。因此，把 -1 赋给8 比特大小的uns 工gned char 所得的结果 是255 当我们赋给带符号类型一个超出它表示范围的值时，结果是未定义的( undefined )。 此时， 程序，可能继续工作、可能崩溃，也可能生成垃圾数据。 如果表达式里既有带符号类型又有无符号类型， 当带符号类型取值为负时会出现异 常结果， 这是因为带符号数会自动地转换成无符号数。例如，在一个形如a*b 的式子 中，如果a = -1 , b = 1 ，而且a 和b 都是int ，则表达式的值显然为- 1 0 然而，如 果a 是int ， 而b 是unsigned ， 则结果须视在当前机器上int 所占位数而定。在我 们的环境里，结果是4294967295 ###2.2.1 : 如果是内置类型的变量未被显式初始化，它的值由定义的位置决定。定义于任何函数 体之外的变量被初始化为0 。然而如6. 1. 1 节(第1 85 页〉所示， 一种例外情况是，定义 在函数体内部的内置类型变量将不被初始化( tminitialized ) 。一个未被初始化的内置类型 变量的值是未定义的(参见2. 1. 2 节， 第33 页) ，如果试图拷贝或以其他形式谛问此类值 将引发错误 定义于函数体内的内置类型的对象如果没有初始化，时值未定义。类的对象 如果没有显式地初始化，则其位由类确定。 ###2.2.2 : 为了支持分离式编译， C←←语言将声明和定义区分开来。声明( declaration ) 使得名字 为程序所知， 一个文件如果想使用别处定义的名字则必须包含对那个名字的声明。而定义 ( defi nition ) 负责创建与名字关联的实体。 变量声明规定了变量的类型和名字， 在这一点上定义与之相同。但是除此之外，定义 还申请存储空间，也可能会为变量赋一个初始值。 如果想声明一个变量;而非定义它，就在变量名前添加关键字extern ，而且不要显式 地初始化变量: extern int i ; // 声明i 而非定义i int j ; / / 声明并定义j 任何包含了显式初始化的声明即成为定义。我们能给由extern 关键字标记的变量赋 一个初始值，但是这么做也就抵消了extern 的作用。extern 语句如果包含初始值就不 再是声明，而变成定义了: extern doub1e pi = 3 . 1416 ; // 定义 在函数体内部，如果试图初始化一个由extern 关键字标记的变革， 将引发错误 ###2.2.3 : C++也为标准库保留了一些名字。用户在自定义的标识符中不能连续出现两个下画钱，也不能以下画线紧连大写字句开头。此外，定义在函数体外的标识稍不能以下画线 开头。 比如: int _ = 3; 是合法的 ###2.3.1 : 其他所 有引用的类型都要和l 与之绑定的对象严格匹配。而且，引用只能绑定在对象上，而不能与 字面值或某个表达式的计算结果绑定在一起， 相关原因将在2 .4 . 1 节详述: int &amp;refVa14 = 10 ; //错误· 引用类型的初始值必须是一个对象 double dval = 3.14 ; int &amp;refVa15 = dva1 ; // 错误: 此处引用类型的初始位必须是int 型对象 ###2.3.2 : 因为引用不是对象， 没有实际地址，所以不能定义指向引用的指针。 ###2.4 : 默认状态下， const 对象仅在文件内有效 当以编译时初始化的方式定义一个const 对象时，就如对bufSize 的定义一样: const int bufS 工ze = 512; 11 输入缓冲区大小 编译器将在编译过程中把用到该变量的地方都替换成对应的值。也就是说，编译器会找到 代码中所有用到bufSize 的地方，然后用512 替换。 为了执行上述替换， 编译器必须知道变量的初始值。如果程序包含多个文件，则每个 用了co nst 对象的文件都必须得能访问到它的初始值才行。要做到这一点，就必须在每 一个用到变量的文件中都有对它的定义(参见2.2.2 节， 第4 1 页)。为了支持这一用法， 同时避免对同一变量的重复定义，默认情况下， const 对象被设定为仅在文件内有效。、 多个文件中出现了同名的const 变量时，其实等同于在不同文件中分别定义了独立的变量。 某些时候有这样一种const 变量，它的初始值不是一个常量表达式，但又确实有必 要在文件间共享。这种情况f ， 我们不希望编译器为每个文件分别生成独立的变量。相反， 我们想让这类const 对象像其他(非常量)对象一样工作，也就是说，只在一个文件中 定义const ，而在其他多个文件中声明并使用它。 解决的办法是，对于c o nst 变量不管是声明还是定义都添加extern 关键字， 这样 只需定义一次就可以了: // file 1 . cc 定义并初始化了一个常壶，该常量能被其他文件访问 extern const int bufS 工ze = fcn(); // file 1 . h 头文件 extern const int bufSize ; /1 与f ile 1. cc 中定义的bufS 工ze 是同一个 如上述程序所示， fi1e 1. cc 定义并初始化了bufSize 。因为这条语句包含了初始值， 所以它(显然〉是一次定义。然而，因为b ufSize 是←个常量，必须用extern 加以限 定使其被其他文件使用。 file 1. h 头文件中的声明也由extern 做了限定，其作用是指明bufS 工ze 并非本 文件FiIi 独有，它的定义将在别处出现。 ###2.4.1 初始化和对const 的引用 2 . 3 . 1 节(第46 页〉提到， 号| 用的类型必须与其所引用对象的类型→致，但是有两个 例外。第一种例外情况就是在初始化常量引用时允许用任意表达式作为初始值，只要该表 达式的结果能转换成(参见2.1 .2 节，第3 2 页)引用的类型叩可。尤其，允许为一个常量 引用绑定非常量的对象、字面值， 甚至是个-般表达式: int i= 42 ; . const int &amp;r1 = i ; // ft许将c ons t in t&amp;#~ 定到一个普通int 对象上 const int &amp;r2 = 42; // 正确r1 是一个常量引用 const int &amp;r3 = r1 * 2 ; // 正确r3 是一个常受引用 int &amp;r4 = r1 * 2 ; // 错误r4 是一个普通的非常受引用 要想、理解这种例外情况的原因，陆简单的办法是弄清楚当一个常量引用被绑定到另外一种 类型上时到底发生了什么: doub1e dval = 3 . 14 ; const int &amp;ri = dva1 ; 此处ri 引用了一个int 型的数。对口的操作应该是整数运算，但dval 却是一个双精 度浮点数而非整数。因此为了确保让rl 绑定一个整数，编译器把上述代码变成了如下 形式: const int temp = dval; 1/ 由双精度浮点数生成一个临时的整型常量 const int &amp;ri = temp ; 11 让rl 绑定这个临时受 在这种情况下， ri 绑定了一个临时量( tempo ra ry )对象。所谓临时量对象就是当编译器 而要一个空间来暂存表达式的求值结果时临时创建的一个未命名的对象。c++程序员们常 常把临时量对象简称为临时量。 接下来探讨当ri 不是常量时，如果执行了类似于上面的初始化过程将带来什么样的 后果。如果且不是常量，就允许对ri 赋值，这样就会改变ri 所引用对象的值。注意， 此时绑定的对象是一个临时量;而三11:: dvalo 程序员既然让rl 引用dval ， 就肯定想通过 ri 改变dval 的值，否则干什么要给ri 赋值l呢?如此看来， 既然大家基本上不会想着把 引用绑定到临时量上， c++语言也就把这种行为归为非法。 ###2.5.2 和原来另I~些只对应一种特定类型的说明符(比如double) 不|司. auto 让编译器通QÐ 过初始值来推算变量的类型。显然. auto 定义的变量必须有初始值: 使用auto 也能在一条语句中声明多个变量。因为一条声明语句只能有一个基本数据 类型，所以该语句中所有变量的初始基本数据类型都必须一样: int i = 0; const int ci = i; auto &amp;n = i, *p = &amp;ci // 错误i 的类型是int 而&amp; ci 的类型是const int]]></content>
      <categories>
        <category>c++</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>C++Primer</tag>
        <tag>EffectiveC++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gdb多进程调试]]></title>
    <url>%2F2015%2F08%2F31%2Fgdb%E5%A4%9A%E8%BF%9B%E7%A8%8B%E5%A4%9A%E7%BA%BF%E7%A8%8B%E8%B0%83%E8%AF%95%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"><![CDATA[gdb多进程调试 set follow-fork-mode [parent|child] set detach-on-fork [on|off] follow-fork-mode detach-on-fork 说明 parent on 只调试主进程（GDB默认） child on 只调试子进程 parent off 同时调试两个进程，gdb跟主进程，子进程block在fork位置 child off 同时调试两个进程，gdb跟子进程，主进程block在fork位置 查询正在调试的进程：info inferiors 切换调试的进程： inferior +inferior number catch fork命令可以捕获进程的创建 attach + pid ， 可以附到一个正在运行的进程上进行调试 gdb多线程调试 show scheduler-locking //显示当前scheduler-locking set scheduler-locking [on/off/step] //设置scheduler-locking on：只有当前调试线程运行，其他线程处于暂停状态。 off：当前调试线程外的其他线程一直在正常运行。 step：其他线程跟随当前调试线程运行，但具体怎么协同运行，测试中无法体现。 注意：set scheduler-locking要处于线程运行环境下才能生效，也就是程序已经运行并且暂停在某个断点处，否则会出现“Target ‘exec’ cannot support this command.”这样的错误；而且经过测试，设置后的scheduler-locking值在整个进程内有效，不属于某个线程。 gdb多进程/多线程调试实战例子123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158b@b-VirtualBox:~/Documents/temp_test$ sudo gdb ./o_multi_thread_process [sudo] password for b: GNU gdb (Ubuntu 7.7.1-0ubuntu5~14.04.2) 7.7.1Copyright (C) 2014 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law. Type &quot;show copying&quot;and &quot;show warranty&quot; for details.This GDB was configured as &quot;x86_64-linux-gnu&quot;.Type &quot;show configuration&quot; for configuration details.For bug reporting instructions, please see:&lt;http://www.gnu.org/software/gdb/bugs/&gt;.Find the GDB manual and other documentation resources online at:&lt;http://www.gnu.org/software/gdb/documentation/&gt;.For help, type &quot;help&quot;.Type &quot;apropos word&quot; to search for commands related to &quot;word&quot;...Reading symbols from ./o_multi_thread_process...done.(gdb) attach 3027Attaching to program: /home/b/Documents/temp_test/o_multi_thread_process, process 3027Reading symbols from /lib/x86_64-linux-gnu/libpthread.so.0...Reading symbols from /usr/lib/debug//lib/x86_64-linux-gnu/libpthread-2.19.so...done.done.[New LWP 3029][Thread debugging using libthread_db enabled]Using host libthread_db library &quot;/lib/x86_64-linux-gnu/libthread_db.so.1&quot;.Loaded symbols for /lib/x86_64-linux-gnu/libpthread.so.0Reading symbols from /lib/x86_64-linux-gnu/libc.so.6...Reading symbols from /usr/lib/debug//lib/x86_64-linux-gnu/libc-2.19.so...done.done.Loaded symbols for /lib/x86_64-linux-gnu/libc.so.6Reading symbols from /lib64/ld-linux-x86-64.so.2...Reading symbols from /usr/lib/debug//lib/x86_64-linux-gnu/ld-2.19.so...done.done.Loaded symbols for /lib64/ld-linux-x86-64.so.20x00007f5c9acb8dfd in nanosleep () at ../sysdeps/unix/syscall-template.S:8181 ../sysdeps/unix/syscall-template.S: No such file or directory.(gdb) set follow-fork-mode parent (gdb) set detach-on-fork off(gdb) catch forkCatchpoint 1 (fork)(gdb) rStarting program: /home/b/Documents/temp_test/o_multi_thread_process [Thread debugging using libthread_db enabled]Using host libthread_db library &quot;/lib/x86_64-linux-gnu/libthread_db.so.1&quot;.Catchpoint 1 (forked process 3002), 0x00007ffff78b7ee4 in __libc_fork () at ../nptl/sysdeps/unix/sysv/linux/x86_64/../fork.c:130130 ../nptl/sysdeps/unix/sysv/linux/x86_64/../fork.c: No such file or directory.(gdb) info inferiors Num Description Executable * 1 process 2998 /home/b/Documents/temp_test/o_multi_thread_process (gdb) b 14Breakpoint 2 at 0x7ffff78b7f5b: file ../nptl/sysdeps/unix/sysv/linux/x86_64/../fork.c, line 14.(gdb) info breakpoints Num Type Disp Enb Address What1 catchpoint keep y fork, process 3002 catchpoint already hit 1 time2 breakpoint keep y 0x00007ffff78b7f5b in __libc_fork at ../nptl/sysdeps/unix/sysv/linux/x86_64/../fork.c:14(gdb) d 2(gdb) info breakpoints Num Type Disp Enb Address What1 catchpoint keep y fork, process 3002 catchpoint already hit 1 time(gdb) b multi_thread_process.cpp : 14Breakpoint 3 at 0x4007f4: file ./multi_thread_process.cpp, line 14.(gdb) cContinuing.[New process 3002][Thread debugging using libthread_db enabled]Using host libthread_db library &quot;/lib/x86_64-linux-gnu/libthread_db.so.1&quot;.Reading symbols from /usr/lib/debug/lib/x86_64-linux-gnu/libpthread-2.19.so...done.Reading symbols from /usr/lib/debug/lib/x86_64-linux-gnu/libc-2.19.so...done.Reading symbols from /usr/lib/debug/lib/x86_64-linux-gnu/ld-2.19.so...done.Breakpoint 3, main (argc=1, argv=0x7fffffffe598) at ./multi_thread_process.cpp:1515 if(pid != 0)(gdb) info inferiors Num Description Executable 2 process 3002 /home/b/Documents/temp_test/o_multi_thread_process * 1 process 2998 /home/b/Documents/temp_test/o_multi_thread_process (gdb) inferior 2[Switching to inferior 2 [process 3002] (/home/b/Documents/temp_test/o_multi_thread_process)][Switching to thread 2 (Thread 0x7ffff7fdf740 (LWP 3002))] 0 0x00007ffff78b7ee4 in __libc_fork () at ../nptl/sysdeps/unix/sysv/linux/x86_64/../fork.c:130130 ../nptl/sysdeps/unix/sysv/linux/x86_64/../fork.c: No such file or directory.(gdb) set scheduler-locking on(gdb) b multi_thread_process.cpp : 50Breakpoint 4 at 0x400916: multi_thread_process.cpp:50. (2 locations)(gdb) info threads Id Target Id Frame * 2 Thread 0x7ffff7fdf740 (LWP 3002) &quot;o_multi_thread_&quot; 0x00007ffff78b7ee4 in __libc_fork () at ../nptl/sysdeps/unix/sysv/linux/x86_64/../fork.c:130 1 Thread 0x7ffff7fdf740 (LWP 2998) &quot;o_multi_thread_&quot; main (argc=1, argv=0x7fffffffe598) at ./multi_thread_process.cpp:15(gdb) cContinuing.Breakpoint 3, main (argc=1, argv=0x7fffffffe598) at ./multi_thread_process.cpp:1515 if(pid != 0)(gdb) info threads Id Target Id Frame * 2 Thread 0x7ffff7fdf740 (LWP 3002) &quot;o_multi_thread_&quot; main (argc=1, argv=0x7fffffffe598) at ./multi_thread_process.cpp:15 1 Thread 0x7ffff7fdf740 (LWP 2998) &quot;o_multi_thread_&quot; main (argc=1, argv=0x7fffffffe598) at ./multi_thread_process.cpp:15(gdb) cContinuing.ProcessB: 3002 step1ProcessB: 3002 step2ProcessB: 3002 step3^CProgram received signal SIGINT, Interrupt.0x00007ffff78b7de0 in __nanosleep_nocancel () at ../sysdeps/unix/syscall-template.S:8181 ../sysdeps/unix/syscall-template.S: No such file or directory.(gdb) info threads Id Target Id Frame * 2 Thread 0x7ffff7fdf740 (LWP 3002) &quot;o_multi_thread_&quot; 0x00007ffff78b7de0 in __nanosleep_nocancel () at ../sysdeps/unix/syscall-template.S:81 1 Thread 0x7ffff7fdf740 (LWP 2998) &quot;o_multi_thread_&quot; main (argc=1, argv=0x7fffffffe598) at ./multi_thread_process.cpp:15(gdb) info inferiors Num Description Executable * 2 process 3002 /home/b/Documents/temp_test/o_multi_thread_process 1 process 2998 /home/b/Documents/temp_test/o_multi_thread_process (gdb) inferior 1[Switching to inferior 1 [process 2998] (/home/b/Documents/temp_test/o_multi_thread_process)][Switching to thread 1 (Thread 0x7ffff7fdf740 (LWP 2998))] 0 main (argc=1, argv=0x7fffffffe598) at ./multi_thread_process.cpp:1515 if(pid != 0)(gdb) list10 &#123;11 int pid;12 13 pid = fork();14 15 if(pid != 0)16 processA();17 else18 processB();19 (gdb) rThe program being debugged has been started already.Start it from the beginning? (y or n) nProgram not restarted.(gdb) cContinuing.ProcessA: 2998 step1[New Thread 0x7ffff77f6700 (LWP 3017)]^CProgram received signal SIGINT, Interrupt.0x00007ffff78b7dfd in nanosleep () at ../sysdeps/unix/syscall-template.S:8181 ../sysdeps/unix/syscall-template.S: No such file or directory.(gdb) info threads Id Target Id Frame 3 Thread 0x7ffff77f6700 (LWP 3017) &quot;o_multi_thread_&quot; clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:81 2 Thread 0x7ffff7fdf740 (LWP 3002) &quot;o_multi_thread_&quot; 0x00007ffff78b7de0 in __nanosleep_nocancel () at ../sysdeps/unix/syscall-template.S:81* 1 Thread 0x7ffff7fdf740 (LWP 2998) &quot;o_multi_thread_&quot; 0x00007ffff78b7dfd in nanosleep () at ../sysdeps/unix/syscall-template.S:81(gdb)]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>gdb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 常用SIG信号及其键值]]></title>
    <url>%2F2015%2F08%2F04%2FLinux%20%E5%B8%B8%E7%94%A8SIG%E4%BF%A1%E5%8F%B7%E5%8F%8A%E5%85%B6%E9%94%AE%E5%80%BC%2F</url>
    <content type="text"><![CDATA[01 SIGHUP 挂起（hangup） 02 SIGINT 中断，当用户从键盘按^c键或^break键时 03 SIGQUIT 退出，当用户从键盘按quit键时 04 SIGILL 非法指令 05 SIGTRAP 跟踪陷阱（trace trap），启动进程，跟踪代码的执行 06 SIGIOT IOT指令 07 SIGEMT EMT指令 08 SIGFPE 浮点运算溢出 09 SIGKILL 杀死、终止进程 10 SIGBUS 总线错误 11 SIGSEGV 段违例（segmentation violation），进程试图去访问其虚地址空间以外的位置 12 SIGSYS 系统调用中参数错，如系统调用号非法 13 SIGPIPE 向某个非读管道中写入数据 14 SIGALRM 闹钟。当某进程希望在某时间后接收信号时发此信号 15 SIGTERM 软件终止（software termination） 16 SIGUSR1 用户自定义信号1 17 SIGUSR2 用户自定义信号2 18 SIGCLD 某个子进程死 19 SIGPWR 电源故障]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>sig</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[socket可读可写条件与非阻塞connect或accept浅析]]></title>
    <url>%2F2015%2F06%2F22%2Fsocket%E5%8F%AF%E8%AF%BB%E5%8F%AF%E5%86%99%E6%9D%A1%E4%BB%B6%E4%B8%8E%E9%9D%9E%E9%98%BB%E5%A1%9Econnect%E6%88%96accept%E6%B5%85%E6%9E%90%2F</url>
    <content type="text"><![CDATA[socket可读的条件: socket的接收缓冲区中的数据字节大于等于该socket的接收缓冲区低水位标记的当前大小。对这样的socket的读操作将不阻塞并返回一个大于0的值(也就是返回准备好读入的数据)。我们可以用SO_RCVLOWATsocket选项来设置该socket的低水位标记。对于TCP和UDP .socket而言，其缺省值为1. 该连接的读这一半关闭(也就是接收了FIN的TCP连接)。对这样的socket的读操作将不阻塞并返回0 给监听套接字准备好新连接 有一个socket有异常错误条件待处理.对于这样的socket的读操作将不会阻塞,并且返回一个错误(-1),errno则设置成明确的错误条件.这些待处理的错误也可通过指定socket选项SO_ERROR调用getsockopt来取得并清除; socket可写的条件: socket的发送缓冲区中的数据字节大于等于该socket的发送缓冲区低水位标记的当前大小。对这样的socket的写操作将不阻塞并返回一个大于0的值(也就是返回准备好写入的数据)。我们可以用SO_SNDLOWAT socket选项来设置该socket的低水位标记。对于TCP和UDPsocket而言，其缺省值为2048 该连接的写这一半关闭。对这样的socket的写操作将产生SIGPIPE信号，该信号的缺省行为是终止进程。 使用非阻塞connect的套接字已建立连接, 或者connect已经以失败告终 有一个socket异常错误条件待处理.对于这样的socket的写操作将不会阻塞并且返回一个错误(-1),errno则设置成明确的错误条件.这些待处理的错误也可以通过指定socket选项SO_ERROR调用getsockopt函数来取得并清除; 非阻塞connect/accept相关述的各种条件可以大体总结为下图 注意 : 当socket异常错误的时候socket是可读并可写的, 所以在非阻塞connect(判断是否可写)/accept(判断是否可读)的时候要特别注意这种情况, 要用getsockopt函数, 使用SO_ERROR选项来检查处理.]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>socket</tag>
        <tag>非阻塞</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关系型数据库与NoSQL的爱恨情仇]]></title>
    <url>%2F2015%2F05%2F20%2F%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8ENoSQL%E7%9A%84%E7%88%B1%E6%81%A8%E6%83%85%E4%BB%87%2F</url>
    <content type="text"><![CDATA[NoSQL因关系数据库的不足而生随着互联网的不断发展，各种类型的应用层出不穷，所以导致在这个云计算的时代， 对技术提出了更多的需求，主要体现在下面这四个方面： 低延迟的读写速度：应用快速地反应能极大地提升用户的满意度; 支撑海量的数据和流量：对于搜索这样大型应用而言，需要利用PB级别的数据和能应对百万级的流量; 大规模集群的管理：系统管理员希望分布式应用能更简单的部署和管理; 庞大运营成本的考量：IT经理们希望在硬件成本、软件成本和人力成本能够有大幅度地降低; 目前世界上主流的存储系统大部分还是采用了关系型数据库，其主要有一下优点： 事务处理—保持数据的一致性； 由于以标准化为前提，数据更新的开销很小（相同的字段基本上只有一处）； 可以进行Join等复杂查询。 虽然关系型数据库已经在业界的数据存储方面占据不可动摇的地位，但是由于其天生的几个限制， 使其很难满足上面这几个需求： 扩展困难：由于存在类似Join这样多表查询机制，使得数据库在扩展方面很艰难; 读写慢：这种情况主要发生在数据量达到一定规模时由于关系型数据库的系统逻辑非常复杂，使得其非常容易发生死锁等的并发问题，所以导致其读写速度下滑非常严重; 成本高：企业级数据库的License价格很惊人，并且随着系统的规模，而不断上升; 有限的支撑容量：现有关系型解决方案还无法支撑Google这样海量的数据存储; 业界为了解决上面提到的几个需求，推出了多款新类型的数据库，并且由于它们在设计上和传统的NoSQL数据库相比有很大的不同，所以被统称为“NoSQL”系列数据库。 总的来说，在设计上，它们非常关注对数据高并发地读写和对海量数据的存储等，与关系型数据库相比，它们在架构和数据模型方量面做了“减法”， 而在扩展和并发等方面做了“加法”。 现在主流的NoSQL数据库有MongoDB和Redis以及BigTable、Hbase、Cassandra、SimpleDB、CouchDB、等。 接下来，将关注NoSQL数据库到底存在哪些优缺点。 NoSQL的优缺点在优势方面，主要体现在下面这三点： 简单的扩展：典型例子是Cassandra，由于其架构是类似于经典的P2P，所以能通过轻松地添加新的节点来扩展这个集群; 快速的读写：主要例子有redis，由于其逻辑简单，而且纯内存操作，使得其性能非常出色，单节点每秒可以处理超过10万次读写操作; 低廉的成本：这是大多数分布式数据库共有的特点，因为主要都是开源软件，没有昂贵的License成本; 但瑕不掩瑜，NoSQL数据库还存在着很多的不足，常见主要有下面这几个： 不提供对SQL的支持：如果不支持SQL这样的工业标准，将会对用户产生一定的学习和应用迁移成本; 支持的特性不够丰富：现有产品所提供的功能都比较有限，大多数NoSQL数据库都不支持事务，也不像MS SQL Server和Oracle那样能提供各种附加功能，比如BI和报表等; 现有产品的不够成熟：大多数产品都还处于初创期，和关系型数据库几十年的完善不可同日而语; 上面NoSQL产品的优缺点都是些比较共通的，在实际情况下，每个产品都会根据自己所遵从的数据模型和CAP理念而有所不同.]]></content>
      <categories>
        <category>DB</category>
      </categories>
      <tags>
        <tag>nosql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux一些不要想当然的事(一)之目录权限]]></title>
    <url>%2F2015%2F03%2F18%2Flinux%E4%B8%80%E4%BA%9B%E4%B8%8D%E8%A6%81%E6%83%B3%E5%BD%93%E7%84%B6%E7%9A%84%E4%BA%8B(%E4%B8%80)%E4%B9%8B%E7%9B%AE%E5%BD%95%E6%9D%83%E9%99%90%2F</url>
    <content type="text"><![CDATA[目录的可读/可写/可执行权限 不要把目录的这几个权限和档案的这几个权限混淆了, 不要想当然的以为是差不多的, 差很多!记忆技巧 : 档案的rwx是针对于档案的内容来设计的, 而目录的rwx是针对于目录的文件名列表来设计的 目录可读r 目录可读权限r : 只能获得文件列表 特别注意:如果一个目录为非空, 却没有r权限, 即使你有wx的权限, 你用rm -r也是删不掉的, 因为没有r权限拿不到这个目录的文件列表, rm -r 自然也就不晓得要删除什么东西了.只有求助root了123456789101112131415161718192021b@b-VirtualBox:~/my_temp_test/abc$ mkdir tempb@b-VirtualBox:~/my_temp_test/abc$ touch temp/ddb@b-VirtualBox:~/my_temp_test/abc$ ls tempddb@b-VirtualBox:~/my_temp_test/abc$ chmod 444 tempb@b-VirtualBox:~/my_temp_test/abc$ ls templs: cannot access temp/dd: Permission deniedddb@b-VirtualBox:~/my_temp_test/abc$ cd temp/bash: cd: temp/: Permission deniedb@b-VirtualBox:~/my_temp_test/abc$ cat temp/dd cat: temp/dd: Permission deniedb@b-VirtualBox:~/my_temp_test/abc$ touch temp/yytouch: cannot touch ‘temp/yy’: Permission deniedb@b-VirtualBox:~/my_temp_test/abc$ rm temp/dd rm: cannot remove ‘temp/dd’: Permission deniedb@b-VirtualBox:~/my_temp_test/abc$ rm -r temprm: descend into write-protected directory ‘temp’? yrm: cannot remove ‘temp/dd’: Permission deniedrm: remove write-protected directory ‘temp’? yrm: cannot remove ‘temp’: Directory not empty 目录可写w 目录可写权限w : 代表可以在目录下增加或删除档案和目录和改名(但是必须得有目录可执行权限x的支持才可以, 所以一般有w就会有x) 不要和档案的可写权限混淆了, 即使没有目录可写权限, 有目录可执行x也是可以修改目录下的档案的, 只要拥有要修改的那个档案的可写权限既可. 但也要注意的是: 档案的w是针对于档案的内容来说的, 你可以编辑修改他的内容, 但是如果想删除这个档案, 你需要这个档案所在的目录的w权限.1234567891011121314b@b-VirtualBox:~/my_temp_test/abc$ chmod 222 tempb@b-VirtualBox:~/my_temp_test/abc$ mkdir temp/uumkdir: cannot create directory ‘temp/uu’: Permission deniedb@b-VirtualBox:~/my_temp_test/abc$ touch temp/ootouch: cannot touch ‘temp/oo’: Permission deniedb@b-VirtualBox:~/my_temp_test/abc$ chmod 333 temp b@b-VirtualBox:~/my_temp_test/abc$ mkdir temp/uub@b-VirtualBox:~/my_temp_test/abc$ touch temp/oob@b-VirtualBox:~/my_temp_test/abc$ rm -r temprm: cannot remove ‘temp’: Permission deniedb@b-VirtualBox:~/my_temp_test/abc$ rm -r temp/uub@b-VirtualBox:~/my_temp_test/abc$ rm temp/oob@b-VirtualBox:~/my_temp_test/abc$ ls templs: cannot open directory temp: Permission denied 目录可执行x 目录可执行权限x : 有进入目录的权限, 有在这个目录下执行命令的权限. 但不可以删除或者增加档案和目录(因为不具备目录的可写权限w)1234567891011121314151617b@b-VirtualBox:~/my_temp_test/abc$ chmod 111 temp/b@b-VirtualBox:~/my_temp_test/abc$ ls templs: cannot open directory temp: Permission deniedb@b-VirtualBox:~/my_temp_test/abc$ echo &quot;xxd&quot; &gt; temp/ddb@b-VirtualBox:~/my_temp_test/abc$ cat temp/ddxxdb@b-VirtualBox:~/my_temp_test/abc$ touch temp/yytouch: cannot touch ‘temp/yy’: Permission deniedb@b-VirtualBox:~/my_temp_test/abc$ rm temp/ddrm: cannot remove ‘temp/dd’: Permission deniedb@b-VirtualBox:~/my_temp_test/abc$ rm -r temprm: descend into write-protected directory ‘temp’? yrm: remove write-protected directory ‘temp’? yrm: cannot remove ‘temp’: Permission deniedb@b-VirtualBox:~/my_temp_test/abc$ cd tempb@b-VirtualBox:~/my_temp_test/abc/temp$ lsls: cannot open directory .: Permission denied]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>directory</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux常用运维命令(df和free)笔记整理(三)]]></title>
    <url>%2F2015%2F03%2F11%2FLinux%E5%B8%B8%E7%94%A8%E8%BF%90%E7%BB%B4%E5%91%BD%E4%BB%A4(df%E5%92%8Cfree)%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86(%E4%B8%89)%2F</url>
    <content type="text"><![CDATA[df df命令用于显示磁盘分区上的可使用的磁盘空间。默认显示单位为KB。可以利用该命令来获取硬盘被占用了多少空间，目前还剩下多少空间等信息。 -a或–all：包含全部的文件系统； –block-size=&lt;区块大小&gt;：以指定的区块大小来显示区块数目； -h或–human-readable：以可读性较高的方式来显示信息； -H或–si：与-h参数相同，但在计算时是以1000 Bytes为换算单位而非1024 Bytes； -i或–inodes：显示inode的信息； -k或–kilobytes：指定区块大小为1024字节； -l或–local：仅显示本地端的文件系统； -m或–megabytes：指定区块大小为1048576字节； –no-sync：在取得磁盘使用信息前，不要执行sync指令，此为预设值； -P或–portability：使用POSIX的输出格式； –sync：在取得磁盘使用信息前，先执行sync指令； -t&lt;文件系统类型&gt;或–type=&lt;文件系统类型&gt;：仅显示指定文件系统类型的磁盘信息； -T或–print-type：显示文件系统的类型； -x&lt;文件系统类型&gt;或–exclude-type=&lt;文件系统类型&gt;：不要显示指定文件系统类型的磁盘信息； –help：显示帮助； –version：显示版本信息 df常用用法：df -h12345678910b@b-VirtualBox:~$ df -hFilesystem Size Used Avail Use% Mounted onudev 990M 4.0K 990M 1% /devtmpfs 201M 968K 200M 1% /run/dev/sda1 8.8G 4.1G 4.3G 49% /none 4.0K 0 4.0K 0% /sys/fs/cgroupnone 5.0M 0 5.0M 0% /run/locknone 1001M 76K 1001M 1% /run/shmnone 100M 36K 100M 1% /run/user/dev/sr0 57M 57M 0 100% /media/b/VBOXADDITIONS_5.1.22_115126 free free命令可以显示当前系统未使用的和已使用的内存数目，还可以显示被内核使用的内存缓冲区。 free常用用法：free -m或者free -g12345b@b-VirtualBox:~$ free -m total used free shared buffers cachedMem: 2000 1231 768 9 72 456-/+ buffers/cache: 702 1297Swap: 1021 0 1021]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux常用运维命令(netstat和lsof)笔记整理(二)]]></title>
    <url>%2F2015%2F03%2F09%2FLinux%E5%B8%B8%E7%94%A8%E8%BF%90%E7%BB%B4%E5%91%BD%E4%BB%A4(netstat%E5%92%8Clsof)%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86(%E4%BA%8C)%2F</url>
    <content type="text"><![CDATA[netstat netstat命令用来打印Linux中网络系统的状态信息，可让你得知整个Linux系统的网络情况。 -a或–all：显示所有连线中的Socket； -A&lt;网络类型&gt;或–&lt;网络类型&gt;：列出该网络类型连线中的相关地址； -c或–continuous：持续列出网络状态； -C或–cache：显示路由器配置的快取信息； -e或–extend：显示网络其他相关信息； -F或–fib：显示FIB； -g或–groups：显示多重广播功能群组组员名单； -h或–help：在线帮助； -i或–interfaces：显示网络界面信息表单； -l或–listening：显示监控中的服务器的Socket； -M或–masquerade：显示伪装的网络连线； -n或–numeric：直接使用ip地址，而不通过域名服务器； -N或–netlink或–symbolic：显示网络硬件外围设备的符号连接名称； -o或–timers：显示计时器； -p或–programs：显示正在使用Socket的程序识别码和程序名称； -r或–route：显示Routing Table； -s或–statistice：显示网络工作信息统计表； -t或–tcp：显示TCP传输协议的连线状况； -u或–udp：显示UDP传输协议的连线状况； -v或–verbose：显示指令执行过程； -V或–version：显示版本信息； -w或–raw：显示RAW传输协议的连线状况； -x或–unix：此参数的效果和指定”-A unix”参数相同； –ip或–inet：此参数的效果和指定”-A inet”参数相同。 netstat常用用法：netstat -anlpnetstat -anlpt的含义是 ： 列出所有处于使用tcp协议的 Sockets123456789b@b-VirtualBox:~$ sudo netstat -anlptActive Internet connections (servers and established)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program nametcp 0 0 127.0.1.1:53 0.0.0.0:* LISTEN 1075/dnsmasq tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 935/sshd tcp 0 0 127.0.0.1:631 0.0.0.0:* LISTEN 2271/cupsd tcp6 0 0 :::22 :::* LISTEN 935/sshd tcp6 0 0 ::1:631 :::* LISTEN 2271/cupsd tcp6 1 0 ::1:50654 ::1:631 CLOSE_WAIT 1027/cups-browsed 查看udp的就是netstat -anlpu；只查看tcp和udp的就是netstat -anlptu lsof （list open files） lsof命令用于查看你进程开打的文件，打开文件的进程，进程打开的端口(TCP、UDP)。找回/恢复删除的文件。是十分方便的系统监视工具，因为lsof命令需要访问核心内存和各种文件，所以需要root用户执行。 在linux环境下，任何事物都以文件的形式存在，通过文件不仅仅可以访问常规数据，还可以访问网络连接和硬件。所以如传输控制协议 (TCP) 和用户数据报协议 (UDP) 套接字等，系统在后台都为该应用程序分配了一个文件描述符，无论这个文件的本质如何，该文件描述符为应用程序与基础操作系统之间的交互提供了通用接口。因为应用程序打开文件的描述符列表提供了大量关于这个应用程序本身的信息，因此通过lsof工具能够查看这个列表对系统监测以及排错将是很有帮助的。 -a：列出打开文件存在的进程； -c&lt;进程名&gt;：列出指定进程所打开的文件； -g：列出GID号进程详情； -d&lt;文件号&gt;：列出占用该文件号的进程； +d&lt;目录&gt;：列出目录下被打开的文件； +D&lt;目录&gt;：递归列出目录下被打开的文件； -n&lt;目录&gt;：列出使用NFS的文件； -i&lt;条件&gt;：列出符合条件的进程。（4、6、协议、:端口、 @ip ） -p&lt;进程号&gt;：列出指定进程号所打开的文件； -u：列出UID号进程详情； -h：显示帮助信息； -v：显示版本信息 -R: 显示PPID（父进程ID） lsof常用用法1：lsof -pps -ef |grep sshd|grep -v grep| awk ‘{print $2}’|xargs sudo lsof -p的含义是：列出sshd进程打开的所有文件描述符123456789101112131415161718192021222324252627282930313233343536373839b@b-VirtualBox:~$ ps -ef |grep sshd|grep -v grep| awk &apos;&#123;print $2&#125;&apos;|xargs sudo lsof -plsof: WARNING: can&apos;t stat() fuse.gvfsd-fuse file system /run/user/1000/gvfs Output information may be incomplete.COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEsshd 935 root cwd DIR 8,1 4096 2 /sshd 935 root rtd DIR 8,1 4096 2 /sshd 935 root txt REG 8,1 770944 301274 /usr/sbin/sshdsshd 935 root mem REG 8,1 43616 136982 /lib/x86_64-linux-gnu/libnss_files-2.19.sosshd 935 root mem REG 8,1 47760 136992 /lib/x86_64-linux-gnu/libnss_nis-2.19.sosshd 935 root mem REG 8,1 39824 136978 /lib/x86_64-linux-gnu/libnss_compat-2.19.sosshd 935 root mem REG 8,1 101240 137033 /lib/x86_64-linux-gnu/libresolv-2.19.sosshd 935 root mem REG 8,1 14256 136950 /lib/x86_64-linux-gnu/libkeyutils.so.1.4sshd 935 root mem REG 8,1 43672 403209 /usr/lib/x86_64-linux-gnu/libkrb5support.so.0.1sshd 935 root mem REG 8,1 186824 403203 /usr/lib/x86_64-linux-gnu/libk5crypto.so.3.1sshd 935 root mem REG 8,1 31792 137035 /lib/x86_64-linux-gnu/librt-2.19.sosshd 935 root mem REG 8,1 141574 137027 /lib/x86_64-linux-gnu/libpthread-2.19.sosshd 935 root mem REG 8,1 252032 137010 /lib/x86_64-linux-gnu/libpcre.so.3.13.1sshd 935 root mem REG 8,1 14664 136924 /lib/x86_64-linux-gnu/libdl-2.19.sosshd 935 root mem REG 8,1 97296 136976 /lib/x86_64-linux-gnu/libnsl-2.19.sosshd 935 root mem REG 8,1 1840928 136907 /lib/x86_64-linux-gnu/libc-2.19.sosshd 935 root mem REG 8,1 14592 136916 /lib/x86_64-linux-gnu/libcom_err.so.2.1sshd 935 root mem REG 8,1 831616 403207 /usr/lib/x86_64-linux-gnu/libkrb5.so.3.3sshd 935 root mem REG 8,1 290520 403037 /usr/lib/x86_64-linux-gnu/libgssapi_krb5.so.2.2sshd 935 root mem REG 8,1 43368 136917 /lib/x86_64-linux-gnu/libcrypt-2.19.sosshd 935 root mem REG 8,1 100728 137070 /lib/x86_64-linux-gnu/libz.so.1.2.8sshd 935 root mem REG 8,1 10680 137062 /lib/x86_64-linux-gnu/libutil-2.19.sosshd 935 root mem REG 8,1 1934624 136919 /lib/x86_64-linux-gnu/libcrypto.so.1.0.0sshd 935 root mem REG 8,1 281552 136921 /lib/x86_64-linux-gnu/libdbus-1.so.3.7.6sshd 935 root mem REG 8,1 14536 440884 /usr/lib/x86_64-linux-gnu/libck-connector.so.0.0.0sshd 935 root mem REG 8,1 134296 137037 /lib/x86_64-linux-gnu/libselinux.so.1sshd 935 root mem REG 8,1 55856 136999 /lib/x86_64-linux-gnu/libpam.so.0.83.1sshd 935 root mem REG 8,1 104936 136897 /lib/x86_64-linux-gnu/libaudit.so.1.0.0sshd 935 root mem REG 8,1 36632 137067 /lib/x86_64-linux-gnu/libwrap.so.0.7.6sshd 935 root mem REG 8,1 149120 136883 /lib/x86_64-linux-gnu/ld-2.19.sosshd 935 root 0u CHR 1,3 0t0 6 /dev/nullsshd 935 root 1u CHR 1,3 0t0 6 /dev/nullsshd 935 root 2u CHR 1,3 0t0 6 /dev/nullsshd 935 root 3u IPv4 10479 0t0 TCP *:ssh (LISTEN)sshd 935 root 4u IPv6 10481 0t0 TCP *:ssh (LISTEN) ps -ef | grep sshd | grep -v grep : 获取ps打印出来的列表中的sshd进程所在的那一行（grep -v grep的含义是清除掉包含“grep”字符串的那一行）, 即为： 12b@b-VirtualBox:~$ ps -ef | grep sshd | grep -v greproot 935 1 0 17:37 ? 00:00:00 /usr/sbin/sshd -D awk ‘{print $2}’ : 获取上述命令打印出来结果的第2列（上述结果的第二列为sshd的pid， 是935） xargs sudo lsof -p ： 列出上述结果pid为935的进程打开的所有文件描述符， 等价于sudo lsof -p 935的结果 lsof常用用法：lsof -i:sudo lsof -i:22含义为列出占用22的进程1234b@b-VirtualBox:~$ sudo lsof -i:22COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEsshd 935 root 3u IPv4 10479 0t0 TCP *:ssh (LISTEN)sshd 935 root 4u IPv6 10481 0t0 TCP *:ssh (LISTEN)]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux常用运维命令(iostat)笔记整理(一)]]></title>
    <url>%2F2015%2F03%2F07%2FLinux%E5%B8%B8%E7%94%A8%E8%BF%90%E7%BB%B4%E5%91%BD%E4%BB%A4(iostat)%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86(%E4%B8%80)%2F</url>
    <content type="text"><![CDATA[在linux服务器开发过程中， 经常需要各种命令配合来查看各种状态，所以整理了一些老的笔记来备忘。 iostat iostat主要用于监控系统设备的IO负载情况，iostat首次运行时显示自系统启动开始的各项统计信息，之后运行iostat将显示自上次运行该命令以后的统计信息。用户可以通过指定统计的次数和时间来获得所需的统计信息 -c 仅显示CPU统计信息.与-d选项互斥. -d 仅显示磁盘统计信息.与-c选项互斥. -k 以K为单位显示每秒的磁盘请求数,默认单位块. -t 在输出数据时,打印搜集数据的时间. -V 打印版本号和帮助信息. -x 输出扩展信息. iostat常用用法1：iostat -d指定采样时间间隔与采样次数 我们可以以”iostat interval [count] ”形式指定iostat命令的采样间隔和采样次数：12345678910linux # iostat -d 1 2Linux 2.6.16.60-0.21-smp (linux) 06/13/12Device: tps Blk_read/s Blk_wrtn/s Blk_read Blk_wrtnsda 0.55 8.93 36.27 6737086 27367728sdb 0.00 0.00 0.00 928 0Device: tps Blk_read/s Blk_wrtn/s Blk_read Blk_wrtnsda 2.00 0.00 72.00 0 72sdb 0.00 0.00 0.00 0 0 以上命令输出Device的信息，采样时间为1秒，采样2次，若不指定采样次数，则iostat会一直输出采样信息，直到按”ctrl+c”退出命令。注意，第1次采样信息与单独执行iostat的效果一样，为从系统开机到当前执行时刻的统计信息。 iostat常用用法2： iostat -x -k -d123456linux # iostat -x -k -d 1Linux 2.6.16.60-0.21-smp (linux) 06/13/12……Device: rrqm/s wrqm/s r/s w/s rkB/s wkB/s avgrq-sz avgqu-sz await svctm %utilsda 0.00 9915.00 1.00 90.00 4.00 34360.00 755.25 11.79 120.57 6.33 57.60 以上各列的含义如下： rrqm/s: 每秒对该设备的读请求被合并次数，文件系统会对读取同块(block)的请求进行合并 wrqm/s: 每秒对该设备的写请求被合并次数 r/s: 每秒完成的读次数 w/s: 每秒完成的写次数 rkB/s: 每秒读数据量(kB为单位) wkB/s: 每秒写数据量(kB为单位) avgrq-sz:平均每次IO操作的数据量(扇区数为单位) avgqu-sz: 平均等待处理的IO请求队列长度 await: 平均每次IO请求等待时间(包括等待时间和处理时间，毫秒为单位) svctm: 平均每次IO请求的处理时间(毫秒为单位) %util: 采用周期内用于IO操作的时间比率，即IO队列非空的时间比率 对于以上示例输出，我们可以获取到以下信息： 每秒向磁盘上写30M左右数据(wkB/s值)每秒有91次IO操作(r/s+w/s)，其中以写操作为主体平均每次IO请求等待处理的时间为120.57毫秒，处理耗时为6.33毫秒等待处理的IO请求队列中，平均有11.79个请求驻留]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python的struct模块]]></title>
    <url>%2F2015%2F03%2F02%2Fpython%E7%9A%84struct%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[struct, 这玩意c/c++也有, 顾名思义, 能联想到这玩意是啥了 模块的主要作用就是对python基本类型值与 用python字符串格式表示的C struct类型间 的转化（This module performs conversions between Python values and C structs represented as Python strings.） 基本用法123456789101112import structimport binasciivalues = (1, &apos;abc&apos;, 2.7)s = struct.Struct(&apos;I3sf&apos;)packed_data = s.pack(*values)unpacked_data = s.unpack(packed_data) print &apos;Original values:&apos;, valuesprint &apos;Format string :&apos;, s.formatprint &apos;Uses :&apos;, s.size, &apos;bytes&apos;print &apos;Packed Value :&apos;, binascii.hexlify(packed_data)print &apos;Unpacked Type :&apos;, type(unpacked_data), &apos; Value:&apos;, unpacked_data 输出为:12345Original values: (1, &apos;abc&apos;, 2.7) Format string : I3sf Uses : 12 bytes Packed Value : 0100000061626300cdcc2c40 Unpacked Type : &lt;type &apos;tuple&apos;&gt; Value: (1, &apos;abc&apos;, 2.700000047683716) 代码中， 首先定义了一个元组数据， 包含int、string、float三种数据类型， 然后定义了struct对象，并制定了format‘I3sf’， I 表示int， 3s表示三个字符长度的字符串， f 表示 float。最后通过struct的pack和unpack进行打包和解包。通过输出结果可以发现， value被pack之后， 转化为了一段二进制字节串， 而unpack可以把该字节串再转换回一个元组， 但是值得注意的是对于float的精度发生了改变， 这是由一些比如操作系统等客观因素所决定的。打包之后的数据所占用的字节数与C语言中的struct十分相似。定义format可以参照官方api提供的对照表： 字节序设置另一方面，打包的后的字节顺序默认上是由操作系统的决定的， 当然struct模块也提供了自定义字节顺序的功能， 可以指定大端存储、小端存储等特定的字节顺序， 对于底层通信的字节顺序是十分重要的， 不同的字节顺序和存储方式也会导致字节大小的不同。在format字符串前面加上特定的符号即可以表示不同的字节顺序存储方式， 例如采用小端存储 s = struct.Struct(‘&lt;I3sf’)就可以了。官方api library 也提供了相应的对照列表：]]></content>
      <categories>
        <category>脚本</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL一些需要注意的小细节]]></title>
    <url>%2F2015%2F02%2F27%2FMySQL%E4%B8%80%E4%BA%9B%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E5%B0%8F%E7%BB%86%E8%8A%82%2F</url>
    <content type="text"><![CDATA[distinct关键字 distinct是应用于所有列的, 而不是某一个列1234567891011121314151617181920212223242526272829mysql&gt; select * from test_table;+------+------+| one | two |+------+------+| 56 | 12 || 52 | 10 || 56 | 12 || 56 | 13 |+------+------+4 rows in set (0.00 sec)mysql&gt; select distinct one, two from test_table;+------+------+| one | two |+------+------+| 56 | 12 || 52 | 10 || 56 | 13 |+------+------+3 rows in set (0.00 sec)mysql&gt; select distinct one from test_table;+------+| one |+------+| 56 || 52 |+------+2 rows in set (0.00 sec) and关键字 and的组合优先级比or高 12345678910111213141516171819202122232425262728293031323334353637mysql&gt; select * from test_table;+------+------+| one | two |+------+------+| 56 | 12 || 52 | 10 || 56 | 12 || 56 | 13 || NULL | NULL |+------+------+5 rows in set (0.00 sec)mysql&gt; select one, two from test_table where one = 52 or one = 56 and two &gt; 12;+------+------+| one | two |+------+------+| 52 | 10 || 56 | 13 |+------+------+2 rows in set (0.00 sec)mysql&gt; select one, two from test_table where one = 52 or (one = 56 and two &gt; 12);+------+------+| one | two |+------+------+| 52 | 10 || 56 | 13 |+------+------+2 rows in set (0.00 sec)mysql&gt; select one, two from test_table where (one = 52 or one = 56) and two &gt; 12;+------+------+| one | two |+------+------+| 56 | 13 |+------+------+1 row in set (0.00 sec) NULL null和空字符是不一样的, 找到他和删除他的方式也比较特别1234567891011121314151617181920212223242526272829303132333435363738mysql&gt; insert into test_table(one , two) values (null, null);Query OK, 1 row affected (0.00 sec)mysql&gt; select * from test_table;+------+------+| one | two |+------+------+| NULL | NULL |+------+------+1 row in set (0.00 sec)mysql&gt; delete from test_table where one = NULL;Query OK, 0 rows affected (0.00 sec)mysql&gt; select * from test_table;+------+------+| one | two |+------+------+| NULL | NULL |+------+------+1 row in set (0.00 sec)mysql&gt; delete from test_table where one = &apos; &apos;;Query OK, 0 rows affected (0.00 sec)mysql&gt; select * from test_table;+------+------+| one | two |+------+------+| NULL | NULL |+------+------+1 row in set (0.00 sec)mysql&gt; delete from test_table where isnull(one);Query OK, 1 row affected (0.00 sec)mysql&gt; select * from test_table;Empty set (0.00 sec) rollback 并不是什么都可以回滚的, 典型的如创建表和删除表这些都是不能回退的. 事务是用来管理 insert,update,delete 语句的123456789101112131415161718192021222324252627282930313233343536mysql&gt; set autocommit = 0;Query OK, 0 rows affected (0.00 sec)mysql&gt; select * from test_tab;+-----+-----+-------+| one | two | three |+-----+-----+-------+| 3 | 4 | 5 |+-----+-----+-------+1 row in set (0.00 sec)mysql&gt; set autocommit = 0;Query OK, 0 rows affected (0.00 sec)mysql&gt; insert into test_tab value (4, 4, 5);Query OK, 1 row affected (0.00 sec)mysql&gt; rollback;Query OK, 0 rows affected (0.01 sec)mysql&gt; select * from test_tab;+-----+-----+-------+| one | two | three |+-----+-----+-------+| 3 | 4 | 5 |+-----+-----+-------+1 row in set (0.00 sec)mysql&gt; drop table test_tab;Query OK, 0 rows affected (0.02 sec)mysql&gt; rollback;Query OK, 0 rows affected (0.00 sec)mysql&gt; select * from test_tab;ERROR 1146 (42S02): Table &apos;b_test_database.test_tab&apos; doesn&apos;t exist]]></content>
      <categories>
        <category>DB</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[python中的__name__和__main()__]]></title>
    <url>%2F2015%2F02%2F10%2Fpython%E4%B8%AD%E7%9A%84__name__%E5%92%8C__main()__%2F</url>
    <content type="text"><![CDATA[12345678#hello.pydef sayHello(): str=&quot;hello&quot; print(str);if __name__ == &quot;__main__&quot;: print (&apos;This is main of module &quot;hello.py&quot;&apos;) sayHello() python作为一种脚本语言，我们用python写的各个module都可以包含以上那么一个累死c中的main函数，只不过python中的这种__main__与c中有一些区别，类似于php的魔术那一套, 主要体现在： 1、当单独执行该module时，比如单独执行以上hello.py： python hello.py，则输出 12This is main of module &quot;hello.py&quot;hello 可以理解为&quot;if __name__==&quot;__main__&quot;:&quot;这一句与c中的main()函数所表述的是一致的，即作为入口； 2、当该module被其它module 引入使用时，其中的&quot;if __name__==&quot;__main__&quot;:&quot; 所表示的Block不会被执行, 这是因为此时module被其它module引用时， 其__name__的值将发生变化，__name__的值将会是module的名字。 比如在python shell中import hello后，查看hello.__name__： 123import hellohello.__name__&apos;hello&apos; 3、因此，在python中，当一个module作为整体被执行时,moduel.name的值将是&quot;__main__&quot;； 而当一个module被其它module引用时，module.__name__将是module自己的名字， 当然一个module被其它module引用时，其本身并不需要一个可执行的入口main了。]]></content>
      <categories>
        <category>脚本</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式系统设计概要笔记-四]]></title>
    <url>%2F2015%2F01%2F10%2F%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E6%A6%82%E8%A6%81%E7%AC%94%E8%AE%B0-%E5%9B%9B%2F</url>
    <content type="text"><![CDATA[分布式系统设计实践基本的理论和策略简单介绍这么多，后面本人会从工程的角度，细化说一下”数据分布“、”副本控制”和”高可用协议” 在分布式系统中，无论是计算还是存储，处理的对象都是数据，数据不存在于一台机器或进程中， 这就牵扯到如何多机均匀分发数据的问题，此小结主要讨论”哈希取模”，”一致性哈希“，”范围表划分“，”数据块划分“ 哈希取模：哈希方式是最常见的数据分布方式，实现方式是通过可以描述记录的业务的id或key(比如用户 id)， 通过Hash函数的计算求余。 余数作为处理该数据的服务器索引编号处理。 如图： 这样的好处是只需要通过计算就可以映射出数据和处理节点的关系，不需要存储映射。 难点就是如果id分布不均匀可能出现计算、存储倾斜的问题，在某个节点上分布过重。 并且当处理节点宕机时，这种”硬哈希“的方式会直接导致部分数据异常，还有扩容非常困难，原来的映射关系全部发生变更。 此处，如果是”无状态“型的节点，影响比较小，但遇到”有状态“的存储节点时，会发生大量数据位置需要变更，发生大量数据迁移的问题。 这个问题在实际生产中，可以通过按2的幂的机器数，成倍扩容的方式来缓解，如图： 不过扩容的数量和方式后收到很大限制。 下面介绍一种”自适应“的方式解决扩容和容灾的问题。 一致性哈希：一致性哈希 – Consistent Hash 是使用一个哈希函数计算数据或数据特征的哈希值，令该哈希函数的输出值域为一个封闭的环，最大值+1=最小值。 将节点随机分布到这个环上，每个节点负责处理从自己开始顺时针至下一个节点的全部哈希值域上的数据，如图： 一致性哈希的优点在于可以任意动态添加、删除节点，每次添加、删除一个节点仅影响一致性哈希环上相邻的节点。 为了尽可能均匀的分布节点和数据，一种常见的改进算法是引入虚节点的概念，系统会创建许多虚拟节点，个数远大于当前节点的个数，均匀分布到一致性哈希值域环上。 读写数据时，首先通过数据的哈希值在环上找到对应的虚节点，然后查找到对应的real节点。 这样在扩容和容错时，大量读写的压力会再次被其他部分节点分摊，主要解决了压力集中的问题。 如图： 数据范围划分：有些时候业务的数据id或key分布不是很均匀，并且读写也会呈现聚集的方式。 比如某些id的数据量特别大，这时候可以将数据按Group划分，从业务角度划分比如id为0~10000，已知8000以上的id可能访问量特别大，那么分布可以划分为[[0~8000],[8000~9000],[9000~1000]]。 将小访问量的聚集在一起。 这样可以根据真实场景按需划分，缺点是由于这些信息不能通过计算获取，需要引入一个模块存储这些映射信息。 这就增加了模块依赖，可能会有性能和可用性的额外代价。 数据块划分：许多文件系统经常采用类似设计，将数据按固定块大小(比如HDFS的64MB)，将数据分为一个个大小固定的块，然后这些块均匀的分布在各个节点，这种做法也需要外部节点来存储映射关系。 由于与具体的数据内容无关，按数据量分布数据的方式一般没有数据倾斜的问题，数据总是被均匀切分并分布到集群中。 当集群需要重新负载均衡时，只需通过迁移数据块即可完成。 如图：]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式系统设计概要笔记-三]]></title>
    <url>%2F2015%2F01%2F07%2F%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E6%A6%82%E8%A6%81%E7%AC%94%E8%AE%B0-%E4%B8%89%2F</url>
    <content type="text"><![CDATA[分布式系统设计策略重试机制一般情况下，写一段网络交互的代码，发起rpc或者http，都会遇到请求超时而失败情况。 可能是网络抖动(暂时的网络变更导致包不可达，比如拓扑变更)或者对端挂掉。 这时一般处理逻辑是将请求包在一个重试循环块里，如下：[cpp] view plain copy print?int retry = 3;while(!request() &amp;&amp; retry–)sched_yield(); // or usleep(100) 此种模式可以防止网络暂时的抖动，一般停顿时间很短，并重试多次后，请求成功！但不能防止对端长时间不能连接(网络问题或进程问题) 心跳机制心跳顾名思义，就是以固定的频率向其他节点汇报当前节点状态的方式。 收到心跳，一般可以认为一个节点和现在的网络拓扑是良好的。 当然，心跳汇报时，一般也会携带一些附加的状态、元数据信息，以便管理。 如下图： 但心跳不是万能的，收到心跳可以确认ok，但是收不到心跳却不能确认节点不存在或者挂掉了，因为可能是网络原因倒是链路不通但是节点依旧在工作。 所以切记，”心跳“只能告诉你正常的状态是ok，它不能发现节点是否真的死亡，有可能还在继续服务。 (后面会介绍一种可靠的方式 – Lease机制) 副本副本指的是针对一份数据的多份冗余拷贝，在不同的节点上持久化同一份数据，当某一个节点的数据丢失时，可以从副本上获取数据。 数据副本是分布式系统解决数据丢失异常的仅有的唯一途径。 当然对多份副本的写入会带来一致性和可用性的问题，比如规定副本数为3，同步写3份，会带来3次IO的性能问题。 还是同步写1份，然后异步写2份，会带来一致性问题，比如后面2份未写成功其他模块就去读了(下个小结会详细讨论如果在副本一致性中间做取舍)。 中心化/无中心化系统模型这方面，无非就是两种：中心节点，例如mysql的MSS单主双从、MongDB Master、HDFS NameNode、MapReduce JobTracker等，有1个或几个节点充当整个系统的核心元数据及节点管理工作，其他节点都和中心节点交互。 这种方式的好处显而易见，数据和管理高度统一集中在一个地方，容易聚合，就像领导者一样，其他人都服从就好。 简单可行。 但是缺点是模块高度集中，容易形成性能瓶颈，并且如果出现异常，就像群龙无首一样。 无中心化的设计，例如cassandra、zookeeper，系统中不存在一个领导者，节点彼此通信并且彼此合作完成任务。 好处在于如果出现异常，不会影响整体系统，局部不可用。 缺点是比较协议复杂，而且需要各个节点间同步信息。]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式系统设计概要笔记-二]]></title>
    <url>%2F2015%2F01%2F05%2F%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E6%A6%82%E8%A6%81%E7%AC%94%E8%AE%B0-%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[分布式系统特性CAP是分布式系统里最著名的理论，wiki百科如下 Consistency(all nodes see the same data at the same time) Availability (a guarantee that every request receives a response about whether it was successful or failed) Partition tolerance (the system continues to operate despite arbitrary message loss or failure of part of the system)(摘自 ：http://en.wikipedia.org/wiki/CAP_theorem) 早些时候，国外的大牛已经证明了CAP三者是不能兼得，很多实践也证明了。 本人就不挑战权威了，感兴趣的同学可以自己Google。 本人以自己的观点总结了一下： 一致性描述当前所有节点存储数据的统一模型，分为强一致性和弱一致性：强一致性描述了所有节点的数据高度一致，无论从哪个节点读取，都是一样的。 无需担心同一时刻会获得不同的数据。 是级别最高的，实现的代价比较高如图： 弱一致性又分为单调一致性和最终一致性： 1、单调一致性强调数据是按照时间的新旧，单调向最新的数据靠近，不会回退，如： 数据存在三个版本v1-&gt;v2-&gt;v3，获取只能向v3靠近(如取到的是v2，就不可能再次获得v1) 2、最终一致性强调数据经过一个时间窗口之后，只要多尝试几次，最终的状态是一致的，是最新的数据 如图： 强一致性的场景，就好像交易系统，存取钱的+/-操作必须是马上一致的，否则会令很多人误解。 弱一致性的场景，大部分就像web互联网的模式，比如发了一条微博，改了某些配置，可能不会马上生效，但刷新几次后就可以看到了，其实弱一致性就是在系统上通过业务可接受的方式换取了一些系统的低复杂度和可用性。 可用性保证系统的正常可运行性，在请求方看来，只要发送了一个请求，就可以得到恢复无论成功还是失败（不会超时）! 分区容忍性在系统某些节点或网络有异常的情况下，系统依旧可以继续服务。 这通常是有负载均衡和副本来支撑的。 例如计算模块异常可通过负载均衡引流到其他平行节点，存储模块通过其他几点上的副本来对外提供服务。 扩展性扩展性是融合在CAP里面的特性，我觉得此处可以单独讲一下。 扩展性直接影响了分布式系统的好坏，系统开发初期不可能把系统的容量、峰值都考虑到，后期肯定牵扯到扩容，而如何做到快而不太影响业务的扩容策略，也是需要考虑的。 (后面在介绍数据分布时会着重讨论这个问题)]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式系统设计概要笔记-一]]></title>
    <url>%2F2015%2F01%2F04%2F%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E6%A6%82%E8%A6%81%E7%AC%94%E8%AE%B0-%E4%B8%80%2F</url>
    <content type="text"><![CDATA[分布式系统中的概念三元组其实，分布式系统说白了，就是很多机器组成的集群，靠彼此之间的网络通信，担当的角色可能不同，共同完成同一个事情的系统。 如果按”实体“来划分的话，就是如下这几种： 1、节点 – 系统中按照协议完成计算工作的一个逻辑实体，可能是执行某些工作的进程或机器 2、网络 – 系统的数据传输通道，用来彼此通信。 通信是具有方向性的。 3、存储 – 系统中持久化数据的数据库或者文件存储。 状态特性各个节点的状态可以是“无状态”或者“有状态的”, 一般认为，节点是偏计算和通信的模块，一般是无状态的。 这类应用一般不会存储自己的中间状态信息，比如Nginx，一般情况下是转发请求而已，不会存储中间信息。 另一种“有状态”的，如MySQL等数据库，状态和数据全部持久化到磁盘等介质。 “无状态”的节点一般我们认为是可随意重启的，因为重启后只需要立刻工作就好。 “有状态”的则不同，需要先读取持久化的数据，才能开始服务。 所以，“无状态”的节点一般是可以随意扩展的，“有状态”的节点需要一些控制协议来保证扩展。 系统异常异常，可认为是节点因为某种原因不能工作，此为节点异常。 还有因为网络原因，临时、永久不能被其他节点所访问，此为网络异常。 在分布式系统中，要有对异常的处理，保证集群的正常工作。 分布式系统与单节点的不同从linux write()系统调用说起众所周知，在unix/linux/mac(类Unix)环境下，两个机器通信，最常用的就是通过socket连接对方。 传输数据的话，无非就是调用write()这个系统调用，把一段内存缓冲区发出去。 但是可以进一步想一下，write()之后能确认对方收到了这些数据吗？ 答案肯定是不能，原因就是发送数据需要走内核-&gt;网卡-&gt;链路-&gt;对端网卡-&gt;内核，这一路径太长了，所以只能是异步操作。 write()把数据写入内核缓冲区之后就返回到应用层了，具体后面何时发送、怎么发送、TCP怎么做滑动窗口、流控都是tcp/ip协议栈内核的事情了。 所以在应用层，能确认对方受到了消息只能是对方应用返回数据，逻辑确认了这次发送才认为是成功的。 这就却别与单系统编程，大部分系统调用、库调用只要返回了就说明已经确认完成了。 TCP/IP协议是“不可靠”的教科书上明确写明了互联网是不可靠的，TCP实现了可靠传输。 何来“不可靠”呢？先来看一下网络交互的例子，有A、B两个节点，之间通过TCP连接，现在A、B都想确认自己发出的任何一条消息都能被对方接收并反馈，于是开始了如下操作：A-&gt;B发送数据，然后A需要等待B收到数据的确认，B收到数据后发送确认消息给A，然后B需要等待A收到数据的确认，A收到B的数据确认消息后再次发送确认消息给B，然后A又去需要等待B收到的确认。 死循环了！！ 其实，这就是著名的“拜占庭将军”问题 所以，通信双方是“不可能”同时确认对方受到了自己的信息。 而教科书上定义的其实是指“单向”通信是成立的，比如A向B发起Http调用， 收到了HttpCode 200的响应包，这只能确认，A确认B收到了自己的请求，并且B正常处理了，不能确认的是B确认A受到了它的成功的消息。 不可控的状态在单系统编程中，我们对系统状态是非常可控的。 比如函数调用、逻辑运算，要么成功，要么失败，因为这些操作被框在一个机器内部，cpu/总线/内存都是可以快速得到反馈的。 开发者可以针对这两个状态很明确的做出程序上的判断和后续的操作。 而在分布式的网络环境下，这就变得微妙了。 比如一次rpc、http调用，可能成功、失败，还有可能是“超时”，这就比前者的状态多了一个不可控因素，导致后面的代码不是很容易做出判断。 试想一下，用A用支付宝向B转了一大笔钱，当他按下“确认”后，界面上有个圈在转啊转，然后显示请求超时了，然后A就抓狂了，不知道到底钱转没转过去，开始确认自己的账户、确认B的账户、打电话找客服等等。 所以分布式环境下，我们的其实要时时刻刻考虑面对这种不可控的“第三状态”设计开发，这也是挑战之一。 视异常为正常单系统下，进程/机器的异常概率十分小。 即使出现了问题，可以通过人工干预重启、迁移等手段恢复。 但在分布式环境下，机器上千台，每几分钟都可能出现宕机、死机、网络断网等异常，出现的概率很大。 所以，这种环境下，进程core掉、机器挂掉都是需要我们在编程中认为随时可能出现的，这样才能使我们整个系统健壮起来，所以”容错“是基本需求。 异常可以分为如下几类： 节点错误：一般是由于应用导致，一些coredump和系统错误触发，一般重新服务后可恢复。 硬件错误：由于磁盘或者内存等硬件设备导致某节点不能服务，需要人工干预恢复。 网络错误：由于点对点的网络抖动，暂时的访问错误，一般拓扑稳定后或流量减小可以恢复。 网络分化： 网络中路由器、交换机错误导致网络不可达，但是网络两边都正常，这类错误比较难恢复，并且需要在开发时特别处理。 【这种情况也会比较前面的问题较难处理】]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[(链表进阶)谈一谈各类算法和数据结构的c++实现以及相关操作的复杂度（七）]]></title>
    <url>%2F2014%2F12%2F22%2F(%E9%93%BE%E8%A1%A8%E8%BF%9B%E9%98%B6)%E8%B0%88%E4%B8%80%E8%B0%88%E5%90%84%E7%B1%BB%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%9A%84c%2B%2B%E5%AE%9E%E7%8E%B0%E4%BB%A5%E5%8F%8A%E7%9B%B8%E5%85%B3%E6%93%8D%E4%BD%9C%E7%9A%84%E5%A4%8D%E6%9D%82%E5%BA%A6%EF%BC%88%E4%B8%83%EF%BC%89%2F</url>
    <content type="text"><![CDATA[只谈一下单链表, 链表实在是太重要, 是前面两篇说算法博客的基础, 了解了其应用和衍生, 再去了解其本身就有动力了 这是一篇偏向单链表进阶的博客, 并不会讲单链表的建立/增加/删除等等, 而且这篇博客大多数只说思想不写代码(因为其实蛮简单的..) 存储结构12345typedef struct Node&#123; DataType data; struct Node *next;&#125;Node, *Node_Ptr; 1.找一个单链表的中间结点 算法思想 :(快慢指针的使用)设置两个指针，一个每次移动两个位置，一个每次移动一个位置，当第一个指针到达尾节点时，第二个指针就达到了中间节点的位置 2.判断链表中是否有环 算法思想 :(快慢指针的使用)链表中有环，其实也就是自相交. 用两个指针pslow和pfast从头开始遍历链表，pslow每次前进一个节点，pfast每次前进两个结点，若存在环，则pslow和pfast肯定会在环中相遇，若不存在，则pslow和pfast能正常到达最后一个节点 3.判断两个链表是否相交, 假设两个链表均不带环 算法思想 :如果两个链表相交于某一节点，那么在这个相交节点之后的所有节点都是两个链表所共有的。也就是说，如果两个链表相交，那么最后一个节点肯定是共有的。先遍历第一个链表，记住最后一个节点，然后遍历第二个链表，到最后一个节点时和第一个链表的最后一个节点做比较，如果相同，则相交，否则不相交。 4.链表反转比如一个链表:A-&gt;B-&gt;C-&gt;D-&gt;E反转成为:E-&gt;D-&gt;C-&gt;B-&gt;A 算法思想 :取一个指针指向A的后面那个元素elem, 每次把element放到链表的第一个位置, 遍历完毕之后就反转完毕了,过程如下:第一轮 : A-&gt;B-&gt;C-&gt;D-&gt;E, 把A后面的B设置为element第二轮 : B-&gt;A-&gt;C-&gt;D-&gt;E, 把当前的element(即为B)放到链表的第一个位置, 并把A后面的C设置为element第三轮 : C-&gt;B-&gt;A-&gt;D-&gt;E, 把当前的element(即为C)放到链表的第一个位置, 并把A后面的D设置为element第四轮 : D-&gt;C-&gt;B-&gt;A-&gt;E, 把当前的element(即为D)放到链表的第一个位置, 并把A后面的E设置为element第五轮 : E-&gt;D-&gt;C-&gt;B-&gt;A, 把当前的element(即为E)放到链表的第一个位置, 遍历完毕]]></content>
      <categories>
        <category>c++</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>链表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[(二叉树)谈一谈各类算法和数据结构的c++实现以及相关操作的复杂度（六）]]></title>
    <url>%2F2014%2F09%2F24%2F(%E4%BA%8C%E5%8F%89%E6%A0%91)%E8%B0%88%E4%B8%80%E8%B0%88%E5%90%84%E7%B1%BB%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%9A%84c%2B%2B%E5%AE%9E%E7%8E%B0%E4%BB%A5%E5%8F%8A%E7%9B%B8%E5%85%B3%E6%93%8D%E4%BD%9C%E7%9A%84%E5%A4%8D%E6%9D%82%E5%BA%A6%EF%BC%88%E5%85%AD%EF%BC%89%2F</url>
    <content type="text"><![CDATA[二叉搜索树(又称二叉查找树或二叉排序树) 有了上面二叉树的基础, 我们继续学习二叉搜索树.我们这里也不给他那种晦涩难懂的定义, 感性的认识二叉搜索树.直接看图, 很容易看得出来, 二叉搜索树每个结点的左孩子都小于右孩子.因为具有n个结点的完全二叉树的最大高度为log2n+1而二叉搜索树的查询/增加的时间复杂度都是O(h), h为树的高度,所以复杂度可以看作O(logn), 所以很明显上图中的a树比b树要高效. 查询1234567891011121314151617181920BTN_Ptr search(BTN_Ptr btp, int key)&#123; while (btp != NULL ) &#123; if ( btp-&gt;data != key) &#123; if ( btp-&gt;data &lt; key ) btp = btp-&gt;RightChild; else btp = btp-&gt;LeftChild; &#125; else &#123; printf(&quot;found\n&quot;); return btp; &#125; &#125; printf(&quot;error : not found!\n&quot;); return NULL;&#125; 插入123456789101112131415161718192021222324252627282930313233BTN_Ptr insert(BTN_Ptr &amp;btp, int key)&#123; if (btp == NULL) &#123; btp = new BTN; btp-&gt;data = key; btp-&gt;LeftChild = NULL; btp-&gt;RightChild = NULL; return btp; &#125; else &#123; BTN_Ptr saved_btp = btp; BTN_Ptr temp_btp = NULL; while ( btp != NULL) &#123; temp_btp = btp; if ( key &lt; btp-&gt;data ) btp = btp-&gt;LeftChild; else btp = btp-&gt;RightChild; &#125; btp = new BTN; btp-&gt;data = key; btp-&gt;LeftChild = NULL; btp-&gt;RightChild = NULL; if ( key &lt; temp_btp-&gt;data ) temp_btp-&gt;LeftChild = btp; else temp_btp-&gt;RightChild = btp; return saved_btp; &#125;&#125; 测试程序附上一个测试程序吧12345678910111213141516171819202122232425262728293031#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;iostream&gt;#include &lt;stack&gt;using std::stack;using std::cout;using std::cin;using std::endl;int main(int argc, char **argv)&#123; BTN_Ptr my_btp = NULL; if (create_BT(&amp;my_btp) == -1) return -1; cout &lt;&lt; &quot;==============pre_order:==============&quot; &lt;&lt; endl; pre_order_traverse(&amp;my_btp); cout &lt;&lt; &quot;==============in_order:==============&quot; &lt;&lt; endl; in_order_traverse(&amp;my_btp); cout &lt;&lt; &quot;==============post_order:==============&quot; &lt;&lt; endl; post_order_traverse(&amp;my_btp); cout &lt;&lt; &quot;==============search : 24==============&quot; &lt;&lt; endl; search(my_btp, 24); cout &lt;&lt; &quot;==============search : 14==============&quot; &lt;&lt; endl; search(my_btp, 14); cout &lt;&lt; &quot;==============insert : 25==============&quot; &lt;&lt; endl; my_btp = insert(my_btp, 25); cout &lt;&lt; &quot;==============pre_order2:==============&quot; &lt;&lt; endl; pre_order_traverse(&amp;my_btp); return 0;&#125;]]></content>
      <categories>
        <category>c++</category>
      </categories>
      <tags>
        <tag>二叉树</tag>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[(二叉树)谈一谈各类算法和数据结构的c++实现以及相关操作的复杂度（五）]]></title>
    <url>%2F2014%2F09%2F23%2F(%E4%BA%8C%E5%8F%89%E6%A0%91)%E8%B0%88%E4%B8%80%E8%B0%88%E5%90%84%E7%B1%BB%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%9A%84c%2B%2B%E5%AE%9E%E7%8E%B0%E4%BB%A5%E5%8F%8A%E7%9B%B8%E5%85%B3%E6%93%8D%E4%BD%9C%E7%9A%84%E5%A4%8D%E6%9D%82%E5%BA%A6%EF%BC%88%E4%BA%94%EF%BC%89%2F</url>
    <content type="text"><![CDATA[遍历如上图得到的相应的遍历的序列分别为： 先序遍历 ： ABCDEGF 中序遍历 ： CBEGDFA 后序遍历 ： CGEFDBA 递归遍历123456789101112131415161718192021222324252627282930void pre_order_traverse(const BTN_Ptr *btp)&#123; if ( *btp != NULL) &#123; cout &lt;&lt; (*btp)-&gt;data &lt;&lt; endl; pre_order_traverse( &amp;(*btp)-&gt;LeftChild ); pre_order_traverse( &amp;(*btp)-&gt;RightChild ); &#125;&#125;void in_order_traverse(const BTN_Ptr *btp)&#123; if ( *btp != NULL) &#123; in_order_traverse( &amp;(*btp)-&gt;LeftChild ); cout &lt;&lt; (*btp)-&gt;data &lt;&lt; endl; in_order_traverse( &amp;(*btp)-&gt;RightChild ); &#125;&#125;void post_order_traverse(const BTN_Ptr *btp)&#123; if ( *btp != NULL) &#123; post_order_traverse( &amp;(*btp)-&gt;LeftChild ); post_order_traverse( &amp;(*btp)-&gt;RightChild ); cout &lt;&lt; (*btp)-&gt;data &lt;&lt; endl; &#125;&#125; 非递归遍历 非递归的二叉树三种遍历方式其实思想是统一的 : 都是从左到右的将各个结点依次入栈, 当左边已经走到头了, 就开始走右边, 在适当的条件就出栈, 只是每个遍历方式的出栈条件不一样而已. 先序和中序遍历都很好理解, 着重讲一下后序遍历 :后序遍历的出栈条件有点不一样, 因为后序是先左后右再中的, 比如某个结点p要出栈, 需要遍历完了p的所有右子树之后才能出栈, 而不能第一次就出栈, 所以专门构造了一个结构体F_bt来记录他是否是第一次出栈 (F_bt结构体里有个is_first的数据来记录) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586void pre_order_traverse_non_recursion(const BTN_Ptr *btp)&#123; stack&lt;BTN_Ptr&gt; stack_bt; BTN_Ptr temp_btp = *btp; while ( !stack_bt.empty() || temp_btp != NULL ) &#123; while ( temp_btp != NULL ) &#123; cout &lt;&lt; temp_btp-&gt;data &lt;&lt; endl; stack_bt.push(temp_btp); temp_btp = temp_btp-&gt;LeftChild; &#125; if ( !stack_bt.empty() ) &#123; temp_btp = stack_bt.top()-&gt;RightChild; stack_bt.pop(); &#125; &#125;&#125;void in_order_traverse_non_recursion(const BTN_Ptr *btp)&#123; stack&lt;BTN_Ptr&gt; stack_bt; BTN_Ptr temp_btp = *btp; while ( !stack_bt.empty() || temp_btp != NULL ) &#123; while ( temp_btp != NULL ) &#123; stack_bt.push(temp_btp); temp_btp = temp_btp-&gt;LeftChild; &#125; if ( !stack_bt.empty() ) &#123; cout &lt;&lt; stack_bt.top()-&gt;data &lt;&lt; endl; temp_btp = stack_bt.top()-&gt;RightChild; stack_bt.pop(); &#125; &#125;&#125;typedef struct&#123; BTN_Ptr btnp; int is_first;&#125;F_bt, *F_btp;void post_order_traverse_non_recursion( const BTN_Ptr *btp)&#123; stack&lt;F_btp&gt; stack_F_btp; BTN_Ptr temp_btp = *btp; while ( !stack_F_btp.empty() || temp_btp != NULL ) &#123; while ( temp_btp != NULL ) &#123; F_btp temp_F_btp = new F_bt; temp_F_btp-&gt;btnp = temp_btp; temp_F_btp-&gt;is_first = 1; stack_F_btp.push(temp_F_btp); temp_btp = temp_btp-&gt;LeftChild; &#125; if ( !stack_F_btp.empty() ) &#123; if ( stack_F_btp.top()-&gt;is_first == 1 ) &#123; stack_F_btp.top()-&gt;is_first = 0; temp_btp = stack_F_btp.top()-&gt;btnp-&gt;RightChild; &#125; else &#123; cout &lt;&lt; stack_F_btp.top()-&gt;btnp-&gt;data &lt;&lt; endl; delete stack_F_btp.top(); stack_F_btp.top() = NULL; stack_F_btp.pop(); temp_btp = NULL; &#125; &#125; &#125;&#125;]]></content>
      <categories>
        <category>c++</category>
      </categories>
      <tags>
        <tag>二叉树</tag>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[(二叉树)谈一谈各类算法和数据结构的c++实现以及相关操作的复杂度（四）]]></title>
    <url>%2F2014%2F09%2F22%2F(%E4%BA%8C%E5%8F%89%E6%A0%91)%E8%B0%88%E4%B8%80%E8%B0%88%E5%90%84%E7%B1%BB%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%9A%84c%2B%2B%E5%AE%9E%E7%8E%B0%E4%BB%A5%E5%8F%8A%E7%9B%B8%E5%85%B3%E6%93%8D%E4%BD%9C%E7%9A%84%E5%A4%8D%E6%9D%82%E5%BA%A6%EF%BC%88%E5%9B%9B%EF%BC%89%2F</url>
    <content type="text"><![CDATA[接着上一篇， 上一篇主要说了各种排序算法， 但对几个常用的数据结构还未提及，所以这一篇主要讲二叉树, 二叉树已经包括很多链表的知识了。所有代码都是测试过的, 可以直接撸. 二叉树这里不举太多数字方面的东西， 我们直接看图， 直观感性的认识满二叉树和完全二叉树： 有一点性质需要牢记：具有n个结点的完全二叉树的最大高度为log2n+1 二叉树的二叉链式存储方案的代码表示： 123456typedef struct BinaryTreeNode&#123; int data; BinaryTreeNode *LeftChild, *RightChild; // BTN *LeftChild, *RightChild; // error : BTN doesn&apos;t name a typecat&#125;BTN, *BTN_Ptr; 创建12345678910111213141516171819202122int create_BT(BTN_Ptr *btp)&#123; int temp_data = 0; std::cin &gt;&gt; temp_data; if (temp_data == 0) &#123; *btp = NULL; printf(&quot;leaf\n&quot;); &#125; else &#123; if ( !(*btp = (BTN_Ptr)malloc( sizeof(BTN) ) ) ) &#123; printf(&quot;error : malloc error&quot;); return -1; &#125; (*btp)-&gt;data = temp_data; create_BT(&amp;((*btp)-&gt;LeftChild)); create_BT(&amp;((*btp)-&gt;RightChild)); &#125; return 0;&#125;]]></content>
      <categories>
        <category>c++</category>
      </categories>
      <tags>
        <tag>二叉树</tag>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[(排序算法)谈一谈各类算法和数据结构的c++实现以及相关操作的复杂度（三）]]></title>
    <url>%2F2014%2F08%2F22%2F(%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95)%E8%B0%88%E4%B8%80%E8%B0%88%E5%90%84%E7%B1%BB%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%9A%84c%2B%2B%E5%AE%9E%E7%8E%B0%E4%BB%A5%E5%8F%8A%E7%9B%B8%E5%85%B3%E6%93%8D%E4%BD%9C%E7%9A%84%E5%A4%8D%E6%9D%82%E5%BA%A6%EF%BC%88%E4%B8%89%EF%BC%89%2F</url>
    <content type="text"><![CDATA[快速排序 与归并排序一样， 快排也是用了分治的思想。你可以想象一个两副牌然后随意取出一张牌pivot，其他的所有牌都跟这张pivot牌比较， 大的放右边那一摞A，小的放左边B。接着再从左边这一摞B再随意取出一张牌pivot，其他的所有牌都跟这张pivot牌比较， 大的放右边那一摞，小的放左边，递归下去。A也重复上述步骤递归。递归结束之后， 左边的都比右边的小， 而且是有序的。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546void swap(int *a, int *b)&#123; int temp = 0; temp = *a; *a = *b; *b = temp;&#125;int partition(int *array, int p, int r)&#123; int i = 0, j = 0, pivot = 0; pivot = array[r]; i = p-1; for(j=p; j&lt;=r-1; j++) &#123; if(array[j] &lt;= pivot) &#123; i++; swap(&amp;array[i], &amp;array[j]); &#125; &#125; swap(&amp;array[i+1], &amp;array[r]); return i+1;&#125;/*通常，我们可以向一个算法中加入随机化成分，以便对于所有输入，它均能获得较好的平均情况性能。将这种方法用于快速排序时，不是始终采用A[r]作为主元，而是从子数组A[p..r]中随机选择一个元素，即将A[r]与从A[p..r]中随机选出的一个元素交换。*/ int rand_patition(int test_arr[], int p, int r) &#123; srand(static_cast&lt;unsigned&gt;(time(nullptr))); int rand_index = (rand() % (r - p) ) + p + 1; swap(&amp;test_arr[rand_index], &amp;test_arr[r]); return partition(test_arr, p, r); &#125;void quick_sort(int *array, int p, int r)&#123; int q = 0; if(p &lt; r) &#123; q = rand_patition(array, p, r); quick_sort(array, p, q-1); quick_sort(array, q+1, r); &#125;&#125; 快速排序思想的应用 问题 : 查找数组中第k大的数字算法思想 : 因为快排每次将数组划分为两组加一个枢纽元素，每一趟划分你只需要将k与枢纽元素的下标进行比较，如果比枢纽元素下标大就从右边的子数组中找，如果比枢纽元素下标小从左边的子数组中找，如果一样则就是枢纽元素，找到，如果需要从左边或者右边的子数组中再查找的话，只需要递归一边查找即可，无需像快排一样两边都需要递归，所以复杂度必然降低。 二分查找 二分查找的复杂度计算方法：时间复杂度可以视为while循环的次数。总共有n个元素，渐渐跟下去就是n,n/2,n/4,….n/2^k（接下来操作元素的剩余个数），其中k就是循环的次数由于你n/2^k取整后&gt;=1（接下来操作元素的剩余个数至少为一个）即令n/2^k=1可得k=log2n,（是以2为底，n的对数）所以时间复杂度可以表示O(h)=O(log2n) 递归版本：123456789101112131415int binary_search(int arr[], int low, int high, int key)&#123; if ( low &lt;= high) &#123; int mid = (low + high) / 2; if ( key == arr[mid] ) return mid; else if ( key &lt; arr[mid]) binary_search(arr, low, mid - 1, key); else binary_search(arr, mid + 1, high, key); &#125; else return -1;&#125; 非递归版本：123456789101112131415int non_recursion_bs(int arr[], int low, int high, int key)&#123; int mid = 0; while (low &lt;= high) &#123; mid = ( low + high ) / 2; if ( key == arr[mid] ) return mid; else if ( key &lt; arr[mid] ) high = mid - 1; else low = mid + 1; &#125; return -1;&#125;]]></content>
      <categories>
        <category>c++</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[(排序算法)谈一谈各类算法和数据结构的c++实现以及相关操作的复杂度（二）]]></title>
    <url>%2F2014%2F08%2F20%2F(%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95)%E8%B0%88%E4%B8%80%E8%B0%88%E5%90%84%E7%B1%BB%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%9A%84c%2B%2B%E5%AE%9E%E7%8E%B0%E4%BB%A5%E5%8F%8A%E7%9B%B8%E5%85%B3%E6%93%8D%E4%BD%9C%E7%9A%84%E5%A4%8D%E6%9D%82%E5%BA%A6(%E4%BA%8C)%2F</url>
    <content type="text"><![CDATA[注：以下所有代码皆可以直接运行， 都已经测试过。 冒泡排序 想象就是很多泡泡，最大的泡泡每次浮到那个数组最后面 1234567891011121314void bubble_sort(int a[], int n)&#123; int i, j, temp; for (j = 0; j &lt; n - 1; j++) for (i = 0; i &lt; n - 1 - j; i++) &#123; if(a[i] &gt; a[i + 1]) &#123; temp = a[i]; a[i] = a[i + 1]; a[i + 1] = temp; &#125; &#125;&#125; 插入排序 想象手上有几张牌， 现在你抽了一张牌， 然后需要从手上最右边的牌开始比较，然后插入到相应位置 123456789101112131415161718192021void insertion_sort(int test_array[], size_t length)&#123; int i = 0, key = 0; for (size_t index = 1; index &lt; length; ++index) &#123; i = index - 1, key = test_array[index]; while (i &gt;= 0 &amp;&amp; key &lt; test_array[i]) &#123; test_array[i + 1] = test_array[i]; i = i - 1; &#125; test_array[i + 1] = key; &#125; for (size_t ii = 0; ii &lt; length; ++ii, ++test_array) &#123; cout &lt;&lt; *test_array &lt;&lt; endl; &#125;&#125; 归并排序 归并排序用了分治的思想，有很多算法在结构上是递归的：为了解决一个给定的问题，算法要一次或多次地递归调用其自身来解决相关的子问题。这些算法通常采用分治策略（divide-and-conquier）：将原问题划分成n个规模较小而结构与原问题相似的子问题；递归地解决这些子问题，然后再合并其结果，就得到原问题的解。 分治模式在每一层递归上都有三个步骤： 分解（divide）：将原问题分解成一系列子问题； 解决（conquer）：递归地解各子问题。若子问题足够小，则直接求解； 合并：将子问题的结果合并成原问题的解。 下面是一个比较直白明了的归并c++实现（其实可以写成不用动态分配内存的，但是这里为了直白起见）： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465/* * p: 左数组第一个元素下标 * q: 左数组最后一个元素下标 * r: 右数组最后一个元素下标 */void merge(int *array, int p, int q, int r)&#123; int n1, n2, i, j, k; int *left=NULL, *right=NULL; n1 = q-p+1; n2 = r-q; left = (int *)malloc(sizeof(int)*(n1)); right = (int *)malloc(sizeof(int)*(n2)); for(i=0; i&lt;n1; i++) &#123; left[i] = array[p+i]; &#125; for(j=0; j&lt;n2; j++) &#123; right[j] = array[q+1+j]; &#125; i = j = 0; k = p; while(i&lt;n1 &amp;&amp; j&lt;n2) &#123; if(left[i] &lt;= right[j]) &#123; array[k++] = left[i++]; &#125; else &#123; array[k++] = right[j++]; &#125; &#125; for(; i&lt;n1; i++) &#123; array[k++] = left[i]; &#125; for(; j&lt;n2; j++) &#123; array[k++] = right[j]; &#125; free(left); free(right); left = NULL; right = NULL;&#125; void merge_sort(int *array, int p, int r)&#123; int q; if(p &lt; r) &#123; q = (int)((p+r)/2); merge_sort(array, p, q); merge_sort(array, q+1, r); merge(array, p, q, r); &#125;&#125;]]></content>
      <categories>
        <category>c++</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[(排序算法)谈一谈各类算法和数据结构的c++实现以及相关操作的复杂度（一）]]></title>
    <url>%2F2014%2F08%2F19%2F(%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95)%E8%B0%88%E4%B8%80%E8%B0%88%E5%90%84%E7%B1%BB%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%9A%84c%2B%2B%E5%AE%9E%E7%8E%B0%E4%BB%A5%E5%8F%8A%E7%9B%B8%E5%85%B3%E6%93%8D%E4%BD%9C%E7%9A%84%E5%A4%8D%E6%9D%82%E5%BA%A6%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[因为之前的笔记和书籍相关知识都是零零散散的， 没有一个汇总， 所以写了这篇博客。有些算法很简单，复杂度一眼都能看得出来， 几乎不需要记忆 ， 但是有些算法或者数据结构的操作的复杂度就不是一眼可以看得出来， 推导也是很费时间的， 所谓常识就是应该熟记于心且被认可的知识。 必须掌握的知识 常用算法的复杂度]]></content>
      <categories>
        <category>c++</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>排序</tag>
      </tags>
  </entry>
</search>
